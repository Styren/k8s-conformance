I0921 11:23:32.836296      18 e2e.go:129] Starting e2e run "a59eb591-b1d6-4cde-b395-4ece2ba1430a" on Ginkgo node 1
{"msg":"Test Suite starting","total":356,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1663759412 - Will randomize all specs
Will run 356 of 6971 specs

Sep 21 11:23:34.451: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:23:34.452: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 21 11:23:34.466: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 21 11:23:34.485: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 21 11:23:34.486: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Sep 21 11:23:34.486: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 21 11:23:34.490: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Sep 21 11:23:34.490: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep 21 11:23:34.490: INFO: e2e test version: v1.24.4
Sep 21 11:23:34.491: INFO: kube-apiserver version: v1.24.4
Sep 21 11:23:34.492: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:23:34.495: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:23:34.497: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
W0921 11:23:34.530465      18 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
Sep 21 11:23:34.530: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 21 11:23:34.543: INFO: Waiting up to 5m0s for pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce" in namespace "emptydir-8238" to be "Succeeded or Failed"
Sep 21 11:23:34.547: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.635395ms
Sep 21 11:23:36.554: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010331533s
Sep 21 11:23:38.622: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079004441s
Sep 21 11:23:40.634: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce": Phase="Pending", Reason="", readiness=false. Elapsed: 6.090594612s
Sep 21 11:23:42.640: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce": Phase="Running", Reason="", readiness=false. Elapsed: 8.096886373s
Sep 21 11:23:44.645: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.10161787s
STEP: Saw pod success
Sep 21 11:23:44.645: INFO: Pod "pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce" satisfied condition "Succeeded or Failed"
Sep 21 11:23:44.647: INFO: Trying to get logs from node general-2-xtetrn pod pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce container test-container: <nil>
STEP: delete the pod
Sep 21 11:23:44.687: INFO: Waiting for pod pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce to disappear
Sep 21 11:23:44.690: INFO: Pod pod-91c464c6-e701-4f00-82d5-0ec7585bc3ce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 11:23:44.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8238" for this suite.

• [SLOW TEST:10.199 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":1,"skipped":35,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:23:44.700: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Sep 21 11:23:44.734: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 21 11:23:49.745: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Sep 21 11:23:51.761: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Sep 21 11:23:51.771: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Sep 21 11:23:51.773: INFO: Observed &ReplicaSet event: ADDED
Sep 21 11:23:51.773: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.773: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.774: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.774: INFO: Found replicaset test-rs in namespace replicaset-8175 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Sep 21 11:23:51.774: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Sep 21 11:23:51.774: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Sep 21 11:23:51.779: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Sep 21 11:23:51.782: INFO: Observed &ReplicaSet event: ADDED
Sep 21 11:23:51.782: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.782: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.783: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.783: INFO: Observed replicaset test-rs in namespace replicaset-8175 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Sep 21 11:23:51.783: INFO: Observed &ReplicaSet event: MODIFIED
Sep 21 11:23:51.783: INFO: Found replicaset test-rs in namespace replicaset-8175 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Sep 21 11:23:51.784: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Sep 21 11:23:51.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8175" for this suite.

• [SLOW TEST:7.092 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":356,"completed":2,"skipped":47,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:23:51.799: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Sep 21 11:23:53.850: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7363 PodName:var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 11:23:53.850: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:23:53.851: INFO: ExecWithOptions: Clientset creation
Sep 21 11:23:53.851: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/var-expansion-7363/pods/var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path
Sep 21 11:23:53.931: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7363 PodName:var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 11:23:53.931: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:23:53.932: INFO: ExecWithOptions: Clientset creation
Sep 21 11:23:53.932: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/var-expansion-7363/pods/var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value
Sep 21 11:23:54.520: INFO: Successfully updated pod "var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Sep 21 11:23:54.522: INFO: Deleting pod "var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0" in namespace "var-expansion-7363"
Sep 21 11:23:54.526: INFO: Wait up to 5m0s for pod "var-expansion-6c308937-1776-442c-9ad3-19326c7a8cc0" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 11:24:28.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7363" for this suite.

• [SLOW TEST:36.744 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":356,"completed":3,"skipped":112,"failed":0}
SSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:24:28.547: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-2c446708-5210-40bf-a912-486f32b2f37e in namespace container-probe-7776
Sep 21 11:24:30.583: INFO: Started pod busybox-2c446708-5210-40bf-a912-486f32b2f37e in namespace container-probe-7776
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 11:24:30.586: INFO: Initial restart count of pod busybox-2c446708-5210-40bf-a912-486f32b2f37e is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 11:28:31.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7776" for this suite.

• [SLOW TEST:243.054 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":4,"skipped":119,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:28:31.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 11:28:31.644: INFO: Waiting up to 5m0s for pod "downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09" in namespace "projected-5310" to be "Succeeded or Failed"
Sep 21 11:28:31.647: INFO: Pod "downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.125557ms
Sep 21 11:28:33.651: INFO: Pod "downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006478943s
Sep 21 11:28:35.656: INFO: Pod "downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01097825s
STEP: Saw pod success
Sep 21 11:28:35.656: INFO: Pod "downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09" satisfied condition "Succeeded or Failed"
Sep 21 11:28:35.658: INFO: Trying to get logs from node general-2-xtetrn pod downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09 container client-container: <nil>
STEP: delete the pod
Sep 21 11:28:35.683: INFO: Waiting for pod downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09 to disappear
Sep 21 11:28:35.686: INFO: Pod downwardapi-volume-968d65db-8a52-4dd6-bbbb-b10a57192d09 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 11:28:35.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5310" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":5,"skipped":128,"failed":0}
SSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:28:35.695: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:28:37.745: INFO: Deleting pod "var-expansion-9e5610b6-dda6-4ba5-b63e-d9403e540393" in namespace "var-expansion-2018"
Sep 21 11:28:37.750: INFO: Wait up to 5m0s for pod "var-expansion-9e5610b6-dda6-4ba5-b63e-d9403e540393" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 11:28:41.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2018" for this suite.

• [SLOW TEST:6.080 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":356,"completed":6,"skipped":132,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:28:41.778: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Sep 21 11:28:41.802: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 11:28:41.808: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 11:28:41.811: INFO: 
Logging pods the apiserver thinks is on node general-2-giltle before test
Sep 21 11:28:41.817: INFO: calico-kube-controllers-56cdb7c587-l6wfl from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.817: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 11:28:41.817: INFO: calico-node-qzjzx from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.817: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 11:28:41.817: INFO: calico-typha-6775694657-5m6fr from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.817: INFO: 	Container calico-typha ready: true, restart count 0
Sep 21 11:28:41.817: INFO: coredns-685b6584b-2qb7m from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.817: INFO: 	Container coredns ready: true, restart count 0
Sep 21 11:28:41.817: INFO: coredns-685b6584b-rrbqm from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.817: INFO: 	Container coredns ready: true, restart count 0
Sep 21 11:28:41.818: INFO: kube-proxy-gr4mj from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.818: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 11:28:41.818: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-lv7nl from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 11:28:41.818: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 11:28:41.818: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 11:28:41.818: INFO: csi-symbiosis-node-ldcxc from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (2 container statuses recorded)
Sep 21 11:28:41.818: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 11:28:41.818: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 21 11:28:41.818: INFO: symbiosis-block-csi-controller-0 from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (3 container statuses recorded)
Sep 21 11:28:41.818: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 21 11:28:41.818: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 21 11:28:41.818: INFO: 	Container symbiosis-csi-plugin ready: true, restart count 0
Sep 21 11:28:41.818: INFO: symbiosis-cloud-controller-manager-67cd6bf5b9-tshp2 from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.818: INFO: 	Container symbiosis-cloud-controller-manager ready: true, restart count 0
Sep 21 11:28:41.819: INFO: symbiosis-k8s-controller-676ccb7ff7-2wdvp from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.819: INFO: 	Container symbiosis-k8s-controller ready: true, restart count 0
Sep 21 11:28:41.819: INFO: 
Logging pods the apiserver thinks is on node general-2-xtetrn before test
Sep 21 11:28:41.825: INFO: calico-node-f4g47 from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.825: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 11:28:41.825: INFO: kube-proxy-687zc from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.825: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 11:28:41.825: INFO: sonobuoy from sonobuoy started at 2022-09-21 11:23:09 +0000 UTC (1 container statuses recorded)
Sep 21 11:28:41.825: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 11:28:41.825: INFO: sonobuoy-e2e-job-d15d7ff7630543da from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 11:28:41.825: INFO: 	Container e2e ready: true, restart count 0
Sep 21 11:28:41.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 11:28:41.825: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-xk2rh from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 11:28:41.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 11:28:41.825: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 11:28:41.825: INFO: csi-symbiosis-node-ps6hc from symbiosis-system started at 2022-09-21 11:22:50 +0000 UTC (2 container statuses recorded)
Sep 21 11:28:41.825: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 11:28:41.826: INFO: 	Container driver-registrar ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f84ec826-dec3-4e65-9822-464508a7dacf 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.128.0.3 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-f84ec826-dec3-4e65-9822-464508a7dacf off the node general-2-xtetrn
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f84ec826-dec3-4e65-9822-464508a7dacf
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:33:47.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3752" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:306.161 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":356,"completed":7,"skipped":160,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:33:47.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:33:47.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-6603 version'
Sep 21 11:33:48.041: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Sep 21 11:33:48.041: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.4\", GitCommit:\"95ee5ab382d64cfe6c28967f36b53970b8374491\", GitTreeState:\"clean\", BuildDate:\"2022-08-17T18:54:23Z\", GoVersion:\"go1.18.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.4\nServer Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.4\", GitCommit:\"95ee5ab382d64cfe6c28967f36b53970b8374491\", GitTreeState:\"clean\", BuildDate:\"2022-08-17T18:47:37Z\", GoVersion:\"go1.18.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:33:48.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6603" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":356,"completed":8,"skipped":165,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:33:48.048: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:33:48.509: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:33:51.536: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Sep 21 11:33:51.562: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:33:51.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1688" for this suite.
STEP: Destroying namespace "webhook-1688-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":356,"completed":9,"skipped":166,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:33:51.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 21 11:33:51.685: INFO: Waiting up to 5m0s for pod "pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f" in namespace "emptydir-6763" to be "Succeeded or Failed"
Sep 21 11:33:51.689: INFO: Pod "pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.966927ms
Sep 21 11:33:53.695: INFO: Pod "pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009735174s
Sep 21 11:33:55.701: INFO: Pod "pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015962512s
STEP: Saw pod success
Sep 21 11:33:55.701: INFO: Pod "pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f" satisfied condition "Succeeded or Failed"
Sep 21 11:33:55.704: INFO: Trying to get logs from node general-2-xtetrn pod pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f container test-container: <nil>
STEP: delete the pod
Sep 21 11:33:55.728: INFO: Waiting for pod pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f to disappear
Sep 21 11:33:55.731: INFO: Pod pod-9ec097d3-6ee2-4cd9-9988-ac06bf62dc4f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 11:33:55.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6763" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":10,"skipped":170,"failed":0}
SSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:33:55.739: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's args
Sep 21 11:33:55.772: INFO: Waiting up to 5m0s for pod "var-expansion-82dc0448-b896-4b87-8107-d034b386a193" in namespace "var-expansion-9611" to be "Succeeded or Failed"
Sep 21 11:33:55.776: INFO: Pod "var-expansion-82dc0448-b896-4b87-8107-d034b386a193": Phase="Pending", Reason="", readiness=false. Elapsed: 4.255231ms
Sep 21 11:33:57.787: INFO: Pod "var-expansion-82dc0448-b896-4b87-8107-d034b386a193": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014468397s
Sep 21 11:33:59.798: INFO: Pod "var-expansion-82dc0448-b896-4b87-8107-d034b386a193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026210263s
STEP: Saw pod success
Sep 21 11:33:59.799: INFO: Pod "var-expansion-82dc0448-b896-4b87-8107-d034b386a193" satisfied condition "Succeeded or Failed"
Sep 21 11:33:59.801: INFO: Trying to get logs from node general-2-xtetrn pod var-expansion-82dc0448-b896-4b87-8107-d034b386a193 container dapi-container: <nil>
STEP: delete the pod
Sep 21 11:33:59.816: INFO: Waiting for pod var-expansion-82dc0448-b896-4b87-8107-d034b386a193 to disappear
Sep 21 11:33:59.819: INFO: Pod var-expansion-82dc0448-b896-4b87-8107-d034b386a193 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 11:33:59.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9611" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":356,"completed":11,"skipped":174,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:33:59.827: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 11:33:59.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8235" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":356,"completed":12,"skipped":176,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:33:59.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 21 11:34:00.251: INFO: Pod name wrapped-volume-race-e98e62fe-7259-4bc6-b83f-1f5c03e18e1b: Found 1 pods out of 5
Sep 21 11:34:05.260: INFO: Pod name wrapped-volume-race-e98e62fe-7259-4bc6-b83f-1f5c03e18e1b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e98e62fe-7259-4bc6-b83f-1f5c03e18e1b in namespace emptydir-wrapper-588, will wait for the garbage collector to delete the pods
Sep 21 11:34:17.349: INFO: Deleting ReplicationController wrapped-volume-race-e98e62fe-7259-4bc6-b83f-1f5c03e18e1b took: 3.968666ms
Sep 21 11:34:17.450: INFO: Terminating ReplicationController wrapped-volume-race-e98e62fe-7259-4bc6-b83f-1f5c03e18e1b pods took: 100.589072ms
STEP: Creating RC which spawns configmap-volume pods
Sep 21 11:34:20.281: INFO: Pod name wrapped-volume-race-d9071c9d-4d19-4b54-8e84-4ca39c614c99: Found 0 pods out of 5
Sep 21 11:34:25.290: INFO: Pod name wrapped-volume-race-d9071c9d-4d19-4b54-8e84-4ca39c614c99: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d9071c9d-4d19-4b54-8e84-4ca39c614c99 in namespace emptydir-wrapper-588, will wait for the garbage collector to delete the pods
Sep 21 11:34:37.384: INFO: Deleting ReplicationController wrapped-volume-race-d9071c9d-4d19-4b54-8e84-4ca39c614c99 took: 5.823176ms
Sep 21 11:34:37.485: INFO: Terminating ReplicationController wrapped-volume-race-d9071c9d-4d19-4b54-8e84-4ca39c614c99 pods took: 100.460047ms
STEP: Creating RC which spawns configmap-volume pods
Sep 21 11:34:41.305: INFO: Pod name wrapped-volume-race-33253909-7e63-47db-aa41-3f87327da117: Found 0 pods out of 5
Sep 21 11:34:46.314: INFO: Pod name wrapped-volume-race-33253909-7e63-47db-aa41-3f87327da117: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-33253909-7e63-47db-aa41-3f87327da117 in namespace emptydir-wrapper-588, will wait for the garbage collector to delete the pods
Sep 21 11:34:58.394: INFO: Deleting ReplicationController wrapped-volume-race-33253909-7e63-47db-aa41-3f87327da117 took: 4.072191ms
Sep 21 11:34:58.494: INFO: Terminating ReplicationController wrapped-volume-race-33253909-7e63-47db-aa41-3f87327da117 pods took: 100.195717ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Sep 21 11:35:02.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-588" for this suite.

• [SLOW TEST:62.187 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":356,"completed":13,"skipped":180,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:02.075: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:35:02.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 create -f -'
Sep 21 11:35:03.139: INFO: stderr: ""
Sep 21 11:35:03.139: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Sep 21 11:35:03.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 create -f -'
Sep 21 11:35:03.423: INFO: stderr: ""
Sep 21 11:35:03.423: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Sep 21 11:35:04.427: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 11:35:04.427: INFO: Found 1 / 1
Sep 21 11:35:04.427: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 21 11:35:04.431: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 11:35:04.431: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 21 11:35:04.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 describe pod agnhost-primary-mhcth'
Sep 21 11:35:04.538: INFO: stderr: ""
Sep 21 11:35:04.538: INFO: stdout: "Name:         agnhost-primary-mhcth\nNamespace:    kubectl-8309\nPriority:     0\nNode:         general-2-xtetrn/10.128.0.3\nStart Time:   Wed, 21 Sep 2022 11:35:03 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/containerID: 5907ca96997fbf2e55c8bde13a94f7b65e7cac9917934f8eb35b21243b24e1ee\n              cni.projectcalico.org/podIP: 10.129.53.205/32\n              cni.projectcalico.org/podIPs: 10.129.53.205/32\nStatus:       Running\nIP:           10.129.53.205\nIPs:\n  IP:           10.129.53.205\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://99380823f1134cdb8cbd341b82a755fb0283c837e5f35d1026dc96c4f2a3aa35\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 21 Sep 2022 11:35:03 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rsrv5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-rsrv5:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-8309/agnhost-primary-mhcth to general-2-xtetrn\n  Normal  Pulled     1s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.39\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Sep 21 11:35:04.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 describe rc agnhost-primary'
Sep 21 11:35:04.641: INFO: stderr: ""
Sep 21 11:35:04.641: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8309\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-mhcth\n"
Sep 21 11:35:04.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 describe service agnhost-primary'
Sep 21 11:35:04.724: INFO: stderr: ""
Sep 21 11:35:04.724: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8309\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.127.65.178\nIPs:               10.127.65.178\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.129.53.205:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 21 11:35:04.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 describe node general-2-giltle'
Sep 21 11:35:04.845: INFO: stderr: ""
Sep 21 11:35:04.845: INFO: stdout: "Name:               general-2-giltle\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    k8s.symbiosis.host/node-pool=pool-mpjdft\n                    k8s.symbiosis.host/node-pool-id=9d19257f-54ef-4237-ad94-ba2e0d354e2c\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=general-2-giltle\n                    kubernetes.io/os=linux\n                    region=\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"block.csi.symbiosis.host\":\"general-2-giltle\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.128.0.2/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 21 Sep 2022 11:22:18 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  general-2-giltle\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 21 Sep 2022 11:35:02 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 21 Sep 2022 11:22:53 +0000   Wed, 21 Sep 2022 11:22:53 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 21 Sep 2022 11:34:43 +0000   Wed, 21 Sep 2022 11:22:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 21 Sep 2022 11:34:43 +0000   Wed, 21 Sep 2022 11:22:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 21 Sep 2022 11:34:43 +0000   Wed, 21 Sep 2022 11:22:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 21 Sep 2022 11:34:43 +0000   Wed, 21 Sep 2022 11:22:49 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.128.0.2\n  Hostname:    general-2-giltle\nCapacity:\n  cpu:                2\n  ephemeral-storage:  30308240Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             4026044Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  27932073938\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3923644Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 07ecff5a54954193b2a69550604d39f5\n  System UUID:                07ecff5a-5495-4193-b2a6-9550604d39f5\n  Boot ID:                    fad9c821-ac68-492d-b176-0466972e6abe\n  Kernel Version:             5.4.0-120-generic\n  OS Image:                   Ubuntu 20.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.6\n  Kubelet Version:            v1.24.4\n  Kube-Proxy Version:         v1.24.4\nProviderID:                   symbiosis://0ac2383a-0d7e-48d9-b1ab-93fbea4e645e\nNon-terminated Pods:          (11 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-56cdb7c587-l6wfl                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  kube-system                 calico-node-qzjzx                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         12m\n  kube-system                 calico-typha-6775694657-5m6fr                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  kube-system                 coredns-685b6584b-2qb7m                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     12m\n  kube-system                 coredns-685b6584b-rrbqm                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     12m\n  kube-system                 kube-proxy-gr4mj                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-lv7nl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  symbiosis-system            csi-symbiosis-node-ldcxc                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  symbiosis-system            symbiosis-block-csi-controller-0                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  symbiosis-system            symbiosis-cloud-controller-manager-67cd6bf5b9-tshp2        100m (5%)     0 (0%)      50Mi (1%)        0 (0%)         12m\n  symbiosis-system            symbiosis-k8s-controller-676ccb7ff7-2wdvp                  100m (5%)     100m (5%)   128Mi (3%)       128Mi (3%)     12m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                650m (32%)  100m (5%)\n  memory             318Mi (8%)  468Mi (12%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 12m                kube-proxy       \n  Normal   NodeAllocatableEnforced  12m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      12m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 12m                kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    12m (x7 over 12m)  kubelet          Node general-2-giltle status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     12m (x7 over 12m)  kubelet          Node general-2-giltle status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  12m (x8 over 12m)  kubelet          Node general-2-giltle status is now: NodeHasSufficientMemory\n  Normal   RegisteredNode           12m                node-controller  Node general-2-giltle event: Registered Node general-2-giltle in Controller\n"
Sep 21 11:35:04.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-8309 describe namespace kubectl-8309'
Sep 21 11:35:04.922: INFO: stderr: ""
Sep 21 11:35:04.922: INFO: stdout: "Name:         kubectl-8309\nLabels:       e2e-framework=kubectl\n              e2e-run=a59eb591-b1d6-4cde-b395-4ece2ba1430a\n              kubernetes.io/metadata.name=kubectl-8309\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:35:04.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8309" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":356,"completed":14,"skipped":194,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:04.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 11:35:08.988: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Sep 21 11:35:09.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1797" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":15,"skipped":220,"failed":0}
SSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:09.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Sep 21 11:35:21.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1911" for this suite.

• [SLOW TEST:12.046 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":356,"completed":16,"skipped":223,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:21.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:35:21.083: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-b13f8615-ec9e-4dd7-bb25-ee9efc4f7ff0" in namespace "security-context-test-1864" to be "Succeeded or Failed"
Sep 21 11:35:21.085: INFO: Pod "alpine-nnp-false-b13f8615-ec9e-4dd7-bb25-ee9efc4f7ff0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186253ms
Sep 21 11:35:23.099: INFO: Pod "alpine-nnp-false-b13f8615-ec9e-4dd7-bb25-ee9efc4f7ff0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01619911s
Sep 21 11:35:25.110: INFO: Pod "alpine-nnp-false-b13f8615-ec9e-4dd7-bb25-ee9efc4f7ff0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026499117s
Sep 21 11:35:27.121: INFO: Pod "alpine-nnp-false-b13f8615-ec9e-4dd7-bb25-ee9efc4f7ff0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037990393s
Sep 21 11:35:27.121: INFO: Pod "alpine-nnp-false-b13f8615-ec9e-4dd7-bb25-ee9efc4f7ff0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Sep 21 11:35:27.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1864" for this suite.

• [SLOW TEST:6.080 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:298
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":17,"skipped":229,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:27.138: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Sep 21 11:35:27.181: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.181: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.181: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.181: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.204: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.204: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.222: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:27.223: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Sep 21 11:35:28.449: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Sep 21 11:35:28.449: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Sep 21 11:35:31.344: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Sep 21 11:35:31.376: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Sep 21 11:35:31.380: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.380: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.380: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.380: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.380: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.380: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 0
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.381: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.390: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.390: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.409: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.409: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:31.425: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:31.425: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:31.434: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:31.434: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:32.471: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:32.471: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:32.495: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
STEP: listing Deployments
Sep 21 11:35:32.506: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Sep 21 11:35:32.526: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Sep 21 11:35:32.576: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:32.576: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:32.576: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:32.588: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:32.598: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:33.336: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:33.495: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:33.544: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:33.554: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Sep 21 11:35:38.362: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 1
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 3
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 2
Sep 21 11:35:38.402: INFO: observed Deployment test-deployment in namespace deployment-3046 with ReadyReplicas 3
STEP: deleting the Deployment
Sep 21 11:35:38.411: INFO: observed event type MODIFIED
Sep 21 11:35:38.411: INFO: observed event type MODIFIED
Sep 21 11:35:38.411: INFO: observed event type MODIFIED
Sep 21 11:35:38.411: INFO: observed event type MODIFIED
Sep 21 11:35:38.411: INFO: observed event type MODIFIED
Sep 21 11:35:38.412: INFO: observed event type MODIFIED
Sep 21 11:35:38.412: INFO: observed event type MODIFIED
Sep 21 11:35:38.412: INFO: observed event type MODIFIED
Sep 21 11:35:38.412: INFO: observed event type MODIFIED
Sep 21 11:35:38.412: INFO: observed event type MODIFIED
Sep 21 11:35:38.412: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 11:35:38.416: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 11:35:38.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3046" for this suite.

• [SLOW TEST:11.299 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":356,"completed":18,"skipped":231,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:38.438: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-7691/configmap-test-fd3bb9c7-e8d5-4f44-8ac5-145e46a02461
STEP: Creating a pod to test consume configMaps
Sep 21 11:35:38.472: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb" in namespace "configmap-7691" to be "Succeeded or Failed"
Sep 21 11:35:38.476: INFO: Pod "pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.721995ms
Sep 21 11:35:40.498: INFO: Pod "pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026343217s
Sep 21 11:35:42.506: INFO: Pod "pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034088112s
STEP: Saw pod success
Sep 21 11:35:42.506: INFO: Pod "pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb" satisfied condition "Succeeded or Failed"
Sep 21 11:35:42.509: INFO: Trying to get logs from node general-2-xtetrn pod pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb container env-test: <nil>
STEP: delete the pod
Sep 21 11:35:42.523: INFO: Waiting for pod pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb to disappear
Sep 21 11:35:42.525: INFO: Pod pod-configmaps-a2040a2f-638a-4307-ae01-0220f30ab7eb no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 11:35:42.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7691" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":19,"skipped":293,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:42.532: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Sep 21 11:35:42.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4455" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":356,"completed":20,"skipped":310,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:42.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-cd4be09b-fb9b-4968-9986-98419ef0e823
STEP: Creating a pod to test consume secrets
Sep 21 11:35:42.619: INFO: Waiting up to 5m0s for pod "pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d" in namespace "secrets-6371" to be "Succeeded or Failed"
Sep 21 11:35:42.621: INFO: Pod "pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.389996ms
Sep 21 11:35:44.637: INFO: Pod "pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018050731s
Sep 21 11:35:46.646: INFO: Pod "pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026733179s
STEP: Saw pod success
Sep 21 11:35:46.646: INFO: Pod "pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d" satisfied condition "Succeeded or Failed"
Sep 21 11:35:46.649: INFO: Trying to get logs from node general-2-xtetrn pod pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 11:35:46.661: INFO: Waiting for pod pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d to disappear
Sep 21 11:35:46.664: INFO: Pod pod-secrets-16243b5e-5085-464c-9242-fd1b6d52858d no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 11:35:46.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6371" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":21,"skipped":325,"failed":0}

------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:46.673: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:35:46.755: INFO: Creating deployment "webserver-deployment"
Sep 21 11:35:46.761: INFO: Waiting for observed generation 1
Sep 21 11:35:48.772: INFO: Waiting for all required pods to come up
Sep 21 11:35:48.777: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 21 11:35:50.796: INFO: Waiting for deployment "webserver-deployment" to complete
Sep 21 11:35:50.802: INFO: Updating deployment "webserver-deployment" with a non-existent image
Sep 21 11:35:50.810: INFO: Updating deployment webserver-deployment
Sep 21 11:35:50.811: INFO: Waiting for observed generation 2
Sep 21 11:35:52.815: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 21 11:35:52.818: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 21 11:35:52.820: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 21 11:35:52.827: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 21 11:35:52.827: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 21 11:35:52.829: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 21 11:35:52.832: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Sep 21 11:35:52.832: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Sep 21 11:35:52.842: INFO: Updating deployment webserver-deployment
Sep 21 11:35:52.843: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Sep 21 11:35:52.846: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 21 11:35:52.854: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 11:35:52.893: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-125  4bf0bae3-87bf-47d0-8afa-6eae5b54e13a 4098 3 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a895c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-09-21 11:35:49 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-57ccb67bb8" is progressing.,LastUpdateTime:2022-09-21 11:35:50 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Sep 21 11:35:52.917: INFO: New ReplicaSet "webserver-deployment-57ccb67bb8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-57ccb67bb8  deployment-125  1aeb9203-f7b6-49e7-9c6f-537cf70922bc 4101 3 2022-09-21 11:35:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 4bf0bae3-87bf-47d0-8afa-6eae5b54e13a 0xc003a89af7 0xc003a89af8}] []  [{kube-controller-manager Update apps/v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4bf0bae3-87bf-47d0-8afa-6eae5b54e13a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 57ccb67bb8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a89b98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 11:35:52.917: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Sep 21 11:35:52.918: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-55df494869  deployment-125  20f0ff18-08b5-4b69-87f7-3420804be099 4099 3 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 4bf0bae3-87bf-47d0-8afa-6eae5b54e13a 0xc003a89a07 0xc003a89a08}] []  [{kube-controller-manager Update apps/v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4bf0bae3-87bf-47d0-8afa-6eae5b54e13a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a89a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Sep 21 11:35:52.932: INFO: Pod "webserver-deployment-55df494869-4nb9l" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-4nb9l webserver-deployment-55df494869- deployment-125  cadc333b-6e70-4156-89f1-02afe0b2253c 3962 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:45ebbc667fc6b0ecc6575c7d95fe1fcafb3b701e10501e9badcae3d4130087aa cni.projectcalico.org/podIP:10.129.210.88/32 cni.projectcalico.org/podIPs:10.129.210.88/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c08f60 0xc000c08f61}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.210.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gx44s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gx44s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.210.88,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cc017fff31a1537b6e0339e8c31660b19aed38a48cc16125c37fcfcf88a72775,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.210.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.932: INFO: Pod "webserver-deployment-55df494869-4wzjm" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-4wzjm webserver-deployment-55df494869- deployment-125  61ff6f05-316e-4c9e-bd82-b7fa66a23667 4004 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:22fd42d3b0935d30e71ee0b2d035430dd0ea8a81e7de493703f6b3ce8d708326 cni.projectcalico.org/podIP:10.129.210.91/32 cni.projectcalico.org/podIPs:10.129.210.91/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09320 0xc000c09321}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.210.91\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t872f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t872f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.210.91,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a1bf287e34918751ea23531966ae86e61940cfe4640c25ff362011e841875e65,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.210.91,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.933: INFO: Pod "webserver-deployment-55df494869-9xrkq" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-9xrkq webserver-deployment-55df494869- deployment-125  52de3845-ec8c-49c3-83d4-d9d082e598f5 4120 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09550 0xc000c09551}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jf5vn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jf5vn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2022-09-21 11:35:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.933: INFO: Pod "webserver-deployment-55df494869-b4k6p" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-b4k6p webserver-deployment-55df494869- deployment-125  a03eb13f-7bf4-4f9b-b32f-eb25ef955d38 4116 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09720 0xc000c09721}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k9ddv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k9ddv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.934: INFO: Pod "webserver-deployment-55df494869-bdwcd" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-bdwcd webserver-deployment-55df494869- deployment-125  c74b5c6d-1c2e-4a7c-8132-a4bb0fd4bd8f 4128 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09890 0xc000c09891}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d6rbg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d6rbg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.935: INFO: Pod "webserver-deployment-55df494869-bhxlz" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-bhxlz webserver-deployment-55df494869- deployment-125  0c9ef162-f3f0-4b9e-bc09-bf495ca30b8d 4124 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09a00 0xc000c09a01}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gzwdl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gzwdl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.935: INFO: Pod "webserver-deployment-55df494869-df4zp" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-df4zp webserver-deployment-55df494869- deployment-125  ff0d0ca7-32c2-4b24-b2b7-c612341a39a1 4126 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09b60 0xc000c09b61}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-24g8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-24g8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.936: INFO: Pod "webserver-deployment-55df494869-fncjd" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-fncjd webserver-deployment-55df494869- deployment-125  2d3cf536-4a08-408e-a6de-0d7edbf09be3 4129 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09cf0 0xc000c09cf1}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8rj4m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8rj4m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.936: INFO: Pod "webserver-deployment-55df494869-gk6hj" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-gk6hj webserver-deployment-55df494869- deployment-125  e0793724-d6ab-4113-ad07-a47737e42260 4125 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc000c09e27 0xc000c09e28}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t87jt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t87jt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.936: INFO: Pod "webserver-deployment-55df494869-msldx" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-msldx webserver-deployment-55df494869- deployment-125  a1909c2b-32ac-4cf8-af87-944d74071e8e 3970 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:eb7574f2376bd5491ca549bd1f8be4024712d451700e4d4fd45e098fde003245 cni.projectcalico.org/podIP:10.129.53.217/32 cni.projectcalico.org/podIPs:10.129.53.217/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc00314d200 0xc00314d201}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.53.217\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5tqlf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5tqlf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:10.129.53.217,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f98f965a07749580c94a17c1006739f1d4eb72c447da72e5477b75b0c86e347e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.53.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.938: INFO: Pod "webserver-deployment-55df494869-p8zkr" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-p8zkr webserver-deployment-55df494869- deployment-125  5d2ba5f7-c690-4302-8e92-fb76682caa82 3980 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:9ac94d7d7f205e7257a5b01937cf5ef3161170c47615a9af610b889e512ea731 cni.projectcalico.org/podIP:10.129.53.219/32 cni.projectcalico.org/podIPs:10.129.53.219/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc00316a050 0xc00316a051}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.53.219\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2wpxz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2wpxz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:10.129.53.219,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b07fd588b21918145b4837130cc021166dd1f3c08ae6e392a80e1ff565e0c6d3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.53.219,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.938: INFO: Pod "webserver-deployment-55df494869-sr5x8" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-sr5x8 webserver-deployment-55df494869- deployment-125  10e0b0d8-5595-45a2-a1f7-0ffa11dcf07b 3984 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:7347484a2c3609a3db117b13bfd04f596a144df13393103c14761b933d3deb4d cni.projectcalico.org/podIP:10.129.210.87/32 cni.projectcalico.org/podIPs:10.129.210.87/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc00316b7b0 0xc00316b7b1}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.210.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hvhs8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hvhs8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.210.87,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c6e31896a9b98f9928d4cb58e9d3597c313b290700ea3373ee8e0e1cd8b2718d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.210.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.938: INFO: Pod "webserver-deployment-55df494869-svbw8" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-svbw8 webserver-deployment-55df494869- deployment-125  c12b87ed-bd44-4f59-8183-c2b8d31610cd 3998 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:683450e1ad36db90b7b06b26babfea855c2b004e976481ad7656a469d4d92f07 cni.projectcalico.org/podIP:10.129.210.89/32 cni.projectcalico.org/podIPs:10.129.210.89/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc0033022b0 0xc0033022b1}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.210.89\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cztqz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cztqz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.210.89,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://191ed30617669296ca77d5c91887eb979c675fe441eb6d6838a2e674365892c5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.210.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.939: INFO: Pod "webserver-deployment-55df494869-v2q75" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-v2q75 webserver-deployment-55df494869- deployment-125  d6e02929-c4de-4a3d-9445-13e51eba507b 4113 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc003302a00 0xc003302a01}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m92p8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m92p8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.939: INFO: Pod "webserver-deployment-55df494869-vqk2t" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-vqk2t webserver-deployment-55df494869- deployment-125  dbd69f54-3c86-4daa-abdd-c929e7c5db12 3988 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:8006c3c0a25049665bdc8c29d1702b1f082be29e58dd14b7189cc9611b974e57 cni.projectcalico.org/podIP:10.129.53.218/32 cni.projectcalico.org/podIPs:10.129.53.218/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc003302ec0 0xc003302ec1}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.53.218\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bnv4s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bnv4s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:10.129.53.218,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2e522695b2914e8c542ece689d0bf2b85fc528e5056a079d681618534e6b38a3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.53.218,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.940: INFO: Pod "webserver-deployment-55df494869-wc8vf" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-wc8vf webserver-deployment-55df494869- deployment-125  70dead60-ab21-4f70-a348-f361be02dcd0 3991 0 2022-09-21 11:35:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:5cce9f580cc90f3a54dbe08326e0023c004bc28cee2ad1b6857cfccc6fe499d8 cni.projectcalico.org/podIP:10.129.210.90/32 cni.projectcalico.org/podIPs:10.129.210.90/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 20f0ff18-08b5-4b69-87f7-3420804be099 0xc003303600 0xc003303601}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20f0ff18-08b5-4b69-87f7-3420804be099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:35:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:35:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.210.90\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xkqp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xkqp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.210.90,StartTime:2022-09-21 11:35:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:35:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://306b0a190fa7baf7a0b70a20c354901bafa73cc99dd0a24f41cd2a947c4a400e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.210.90,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.943: INFO: Pod "webserver-deployment-57ccb67bb8-7bh55" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-7bh55 webserver-deployment-57ccb67bb8- deployment-125  1873e846-ac47-452b-b0ec-35115a4fb50c 4059 0 2022-09-21 11:35:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:0021e618bfc34d9b042376cc0cb7b43be1aaac1ccc03366b5eeae76ac77bfe0e cni.projectcalico.org/podIP:10.129.210.92/32 cni.projectcalico.org/podIPs:10.129.210.92/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc003303d70 0xc003303d71}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-09-21 11:35:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqfxn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqfxn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:,StartTime:2022-09-21 11:35:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.944: INFO: Pod "webserver-deployment-57ccb67bb8-8hskt" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-8hskt webserver-deployment-57ccb67bb8- deployment-125  5ae0ef8d-e21b-4426-bd8c-bf767f9584ea 4121 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc003278060 0xc003278061}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7bmcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7bmcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.944: INFO: Pod "webserver-deployment-57ccb67bb8-jj9nh" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-jj9nh webserver-deployment-57ccb67bb8- deployment-125  c5f8bb84-d334-4e64-9cba-43fcbfcbea67 4084 0 2022-09-21 11:35:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:ca8c476fb32dcb7abd7495e1b094c2f477d52ceb08f5840b9783ee472e2fb9b5 cni.projectcalico.org/podIP:10.129.53.223/32 cni.projectcalico.org/podIPs:10.129.53.223/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc0032781c7 0xc0032781c8}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xqt8s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xqt8s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2022-09-21 11:35:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.946: INFO: Pod "webserver-deployment-57ccb67bb8-lhb7j" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-lhb7j webserver-deployment-57ccb67bb8- deployment-125  63c39e00-c486-4b7a-8532-238f3f83a7e5 4085 0 2022-09-21 11:35:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:e0e31d13fe25737fccea60ebb5be8845f1f38c90b0f0271d721fded5e1419f20 cni.projectcalico.org/podIP:10.129.53.224/32 cni.projectcalico.org/podIPs:10.129.53.224/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc0032783f0 0xc0032783f1}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8gv47,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8gv47,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2022-09-21 11:35:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.946: INFO: Pod "webserver-deployment-57ccb67bb8-p9hvs" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-p9hvs webserver-deployment-57ccb67bb8- deployment-125  03e2fe9e-f2ea-4fa7-b0a5-6581cb7bd1ff 4123 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc003278600 0xc003278601}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5zgr9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5zgr9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.946: INFO: Pod "webserver-deployment-57ccb67bb8-qf7lf" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-qf7lf webserver-deployment-57ccb67bb8- deployment-125  55e0a220-f494-4701-beff-b3e0b73b73c7 4069 0 2022-09-21 11:35:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:5f80c67a8a083229a1f804c6217f30f3140c3a2d0bb52f251be4a0b6829c2318 cni.projectcalico.org/podIP:10.129.210.93/32 cni.projectcalico.org/podIPs:10.129.210.93/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc003278790 0xc003278791}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-09-21 11:35:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ntzzh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ntzzh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-giltle,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:,StartTime:2022-09-21 11:35:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.947: INFO: Pod "webserver-deployment-57ccb67bb8-thrtl" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-thrtl webserver-deployment-57ccb67bb8- deployment-125  6df7a37f-a2bb-48b7-b204-bf57ec44ab1e 4127 0 2022-09-21 11:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc0032789a0 0xc0032789a1}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cf7nw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cf7nw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 11:35:52.947: INFO: Pod "webserver-deployment-57ccb67bb8-zvkr8" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-zvkr8 webserver-deployment-57ccb67bb8- deployment-125  56308100-b5aa-435d-828d-611f5d9b9b83 4066 0 2022-09-21 11:35:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:f8e3d202a52fc8093b8e9b7cc4871cca192e7121649f012e1c65f3adcbd1c512 cni.projectcalico.org/podIP:10.129.53.222/32 cni.projectcalico.org/podIPs:10.129.53.222/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 1aeb9203-f7b6-49e7-9c6f-537cf70922bc 0xc003278b17 0xc003278b18}] []  [{kube-controller-manager Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1aeb9203-f7b6-49e7-9c6f-537cf70922bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:35:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-09-21 11:35:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hxtt7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hxtt7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:35:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2022-09-21 11:35:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 11:35:52.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-125" for this suite.

• [SLOW TEST:6.301 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":356,"completed":22,"skipped":325,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:35:52.976: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-9668
STEP: creating service affinity-clusterip in namespace services-9668
STEP: creating replication controller affinity-clusterip in namespace services-9668
I0921 11:35:53.023275      18 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9668, replica count: 3
I0921 11:35:56.094692      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 11:35:59.100479      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 11:36:02.100696      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 11:36:05.100925      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 11:36:08.101803      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 11:36:08.107: INFO: Creating new exec pod
Sep 21 11:36:11.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9668 exec execpod-affinityxmppx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Sep 21 11:36:11.349: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Sep 21 11:36:11.349: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:36:11.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9668 exec execpod-affinityxmppx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.124.37.111 80'
Sep 21 11:36:11.518: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.124.37.111 80\nConnection to 10.124.37.111 80 port [tcp/http] succeeded!\n"
Sep 21 11:36:11.518: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:36:11.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9668 exec execpod-affinityxmppx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.124.37.111:80/ ; done'
Sep 21 11:36:11.787: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.37.111:80/\n"
Sep 21 11:36:11.787: INFO: stdout: "\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t\naffinity-clusterip-k8r8t"
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Received response from host: affinity-clusterip-k8r8t
Sep 21 11:36:11.787: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-9668, will wait for the garbage collector to delete the pods
Sep 21 11:36:11.857: INFO: Deleting ReplicationController affinity-clusterip took: 5.182838ms
Sep 21 11:36:11.958: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.928623ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 11:36:13.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9668" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:20.807 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":23,"skipped":455,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:36:13.785: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-8199ea1a-5816-45a2-a2b7-b4f02f234437
STEP: Creating a pod to test consume configMaps
Sep 21 11:36:13.818: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7" in namespace "projected-268" to be "Succeeded or Failed"
Sep 21 11:36:13.821: INFO: Pod "pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.431556ms
Sep 21 11:36:15.827: INFO: Pod "pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009224687s
Sep 21 11:36:17.830: INFO: Pod "pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012664068s
STEP: Saw pod success
Sep 21 11:36:17.831: INFO: Pod "pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7" satisfied condition "Succeeded or Failed"
Sep 21 11:36:17.833: INFO: Trying to get logs from node general-2-xtetrn pod pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:36:17.845: INFO: Waiting for pod pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7 to disappear
Sep 21 11:36:17.847: INFO: Pod pod-projected-configmaps-b4f732cf-79bf-4ed4-8ef6-79a4514a74a7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 11:36:17.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-268" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":24,"skipped":456,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:36:17.858: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7825
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-7825
Sep 21 11:36:17.900: INFO: Found 0 stateful pods, waiting for 1
Sep 21 11:36:27.905: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Sep 21 11:36:27.928: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Sep 21 11:36:27.934: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Sep 21 11:36:27.937: INFO: Observed &StatefulSet event: ADDED
Sep 21 11:36:27.937: INFO: Found Statefulset ss in namespace statefulset-7825 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Sep 21 11:36:27.937: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Sep 21 11:36:27.937: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Sep 21 11:36:27.943: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Sep 21 11:36:27.946: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 11:36:27.946: INFO: Deleting all statefulset in ns statefulset-7825
Sep 21 11:36:27.949: INFO: Scaling statefulset ss to 0
Sep 21 11:36:37.980: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 11:36:37.982: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 11:36:37.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7825" for this suite.

• [SLOW TEST:20.142 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":356,"completed":25,"skipped":491,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:36:38.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-downwardapi-m7kc
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 11:36:38.038: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-m7kc" in namespace "subpath-2920" to be "Succeeded or Failed"
Sep 21 11:36:38.042: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.765339ms
Sep 21 11:36:40.051: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 2.012974772s
Sep 21 11:36:42.063: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 4.024582423s
Sep 21 11:36:44.072: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 6.034187711s
Sep 21 11:36:46.081: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 8.042982486s
Sep 21 11:36:48.086: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 10.047823749s
Sep 21 11:36:50.097: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 12.058931384s
Sep 21 11:36:52.109: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 14.070514306s
Sep 21 11:36:54.118: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 16.080149603s
Sep 21 11:36:56.125: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 18.086597128s
Sep 21 11:36:58.130: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=true. Elapsed: 20.091949629s
Sep 21 11:37:00.141: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Running", Reason="", readiness=false. Elapsed: 22.102660118s
Sep 21 11:37:02.152: INFO: Pod "pod-subpath-test-downwardapi-m7kc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.113661171s
STEP: Saw pod success
Sep 21 11:37:02.152: INFO: Pod "pod-subpath-test-downwardapi-m7kc" satisfied condition "Succeeded or Failed"
Sep 21 11:37:02.156: INFO: Trying to get logs from node general-2-xtetrn pod pod-subpath-test-downwardapi-m7kc container test-container-subpath-downwardapi-m7kc: <nil>
STEP: delete the pod
Sep 21 11:37:02.167: INFO: Waiting for pod pod-subpath-test-downwardapi-m7kc to disappear
Sep 21 11:37:02.170: INFO: Pod pod-subpath-test-downwardapi-m7kc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-m7kc
Sep 21 11:37:02.170: INFO: Deleting pod "pod-subpath-test-downwardapi-m7kc" in namespace "subpath-2920"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Sep 21 11:37:02.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2920" for this suite.

• [SLOW TEST:24.177 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","total":356,"completed":26,"skipped":540,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:02.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:188
Sep 21 11:37:02.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-3740" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":356,"completed":27,"skipped":558,"failed":0}
SSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:02.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Sep 21 11:37:02.776: INFO: starting watch
STEP: patching
STEP: updating
Sep 21 11:37:02.785: INFO: waiting for watch events with expected annotations
Sep 21 11:37:02.785: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:37:02.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-8813" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":356,"completed":28,"skipped":565,"failed":0}
SSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:02.838: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Sep 21 11:37:02.855: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Sep 21 11:37:07.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5664" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":356,"completed":29,"skipped":568,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:07.546: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:37:08.186: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:37:11.212: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:37:11.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8373" for this suite.
STEP: Destroying namespace "webhook-8373-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":356,"completed":30,"skipped":573,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:11.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Sep 21 11:37:13.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9550" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":356,"completed":31,"skipped":596,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:13.454: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:37:13.487: INFO: Creating deployment "test-recreate-deployment"
Sep 21 11:37:13.490: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 21 11:37:13.513: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 21 11:37:15.520: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 21 11:37:15.522: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 21 11:37:15.532: INFO: Updating deployment test-recreate-deployment
Sep 21 11:37:15.532: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 11:37:15.639: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4795  0a3d4510-8119-4116-8166-100cca7d9f9c 4958 2 2022-09-21 11:37:13 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034117b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-09-21 11:37:15 +0000 UTC,LastTransitionTime:2022-09-21 11:37:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cd8586fc7" is progressing.,LastUpdateTime:2022-09-21 11:37:15 +0000 UTC,LastTransitionTime:2022-09-21 11:37:13 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Sep 21 11:37:15.642: INFO: New ReplicaSet "test-recreate-deployment-cd8586fc7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cd8586fc7  deployment-4795  141ee5b7-35ee-403e-bc63-63b465afc172 4955 1 2022-09-21 11:37:15 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 0a3d4510-8119-4116-8166-100cca7d9f9c 0xc003411c50 0xc003411c51}] []  [{kube-controller-manager Update apps/v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0a3d4510-8119-4116-8166-100cca7d9f9c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cd8586fc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003411ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 11:37:15.642: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 21 11:37:15.642: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-845d658455  deployment-4795  07e87cd7-10ba-488b-8de6-85cf1369d733 4946 2 2022-09-21 11:37:13 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 0a3d4510-8119-4116-8166-100cca7d9f9c 0xc003411b1f 0xc003411b50}] []  [{kube-controller-manager Update apps/v1 2022-09-21 11:37:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0a3d4510-8119-4116-8166-100cca7d9f9c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 845d658455,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003411bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 11:37:15.644: INFO: Pod "test-recreate-deployment-cd8586fc7-t54f9" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cd8586fc7-t54f9 test-recreate-deployment-cd8586fc7- deployment-4795  40986297-2313-4d0d-a244-2029a229123c 4957 0 2022-09-21 11:37:15 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cd8586fc7 141ee5b7-35ee-403e-bc63-63b465afc172 0xc000880200 0xc000880201}] []  [{kube-controller-manager Update v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"141ee5b7-35ee-403e-bc63-63b465afc172\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 11:37:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rb8qw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rb8qw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:37:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:37:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:37:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:37:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2022-09-21 11:37:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 11:37:15.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4795" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":32,"skipped":607,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:15.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Sep 21 11:37:15.681: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:37:17.692: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Sep 21 11:37:17.703: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:37:19.715: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 21 11:37:19.740: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 11:37:19.743: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 21 11:37:21.743: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 11:37:21.755: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 21 11:37:23.743: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 11:37:23.747: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Sep 21 11:37:23.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1134" for this suite.

• [SLOW TEST:8.102 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":356,"completed":33,"skipped":636,"failed":0}
SS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:23.756: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:37:23.789: INFO: The status of Pod server-envvars-2cd9b552-e8a8-4f27-a56b-fe49e7e6855d is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:37:25.795: INFO: The status of Pod server-envvars-2cd9b552-e8a8-4f27-a56b-fe49e7e6855d is Running (Ready = true)
Sep 21 11:37:25.817: INFO: Waiting up to 5m0s for pod "client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26" in namespace "pods-5887" to be "Succeeded or Failed"
Sep 21 11:37:25.824: INFO: Pod "client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26": Phase="Pending", Reason="", readiness=false. Elapsed: 6.495804ms
Sep 21 11:37:27.827: INFO: Pod "client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009612487s
Sep 21 11:37:29.834: INFO: Pod "client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01707286s
STEP: Saw pod success
Sep 21 11:37:29.835: INFO: Pod "client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26" satisfied condition "Succeeded or Failed"
Sep 21 11:37:29.839: INFO: Trying to get logs from node general-2-xtetrn pod client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26 container env3cont: <nil>
STEP: delete the pod
Sep 21 11:37:29.858: INFO: Waiting for pod client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26 to disappear
Sep 21 11:37:29.862: INFO: Pod client-envvars-d577a598-7907-485c-af8e-3d1d1a6bea26 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 11:37:29.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5887" for this suite.

• [SLOW TEST:6.112 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":356,"completed":34,"skipped":638,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:37:29.869: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Sep 21 11:37:29.899: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 11:38:29.925: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Sep 21 11:38:29.945: INFO: Created pod: pod0-0-sched-preemption-low-priority
Sep 21 11:38:29.957: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Sep 21 11:38:29.983: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Sep 21 11:38:29.996: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:38:44.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-9404" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:74.207 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":356,"completed":35,"skipped":645,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:38:44.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Sep 21 11:38:44.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2948" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":36,"skipped":679,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:38:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in volume subpath
Sep 21 11:38:44.134: INFO: Waiting up to 5m0s for pod "var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1" in namespace "var-expansion-9668" to be "Succeeded or Failed"
Sep 21 11:38:44.141: INFO: Pod "var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.998464ms
Sep 21 11:38:46.150: INFO: Pod "var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016111423s
Sep 21 11:38:48.154: INFO: Pod "var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020676426s
STEP: Saw pod success
Sep 21 11:38:48.154: INFO: Pod "var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1" satisfied condition "Succeeded or Failed"
Sep 21 11:38:48.156: INFO: Trying to get logs from node general-2-xtetrn pod var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1 container dapi-container: <nil>
STEP: delete the pod
Sep 21 11:38:48.169: INFO: Waiting for pod var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1 to disappear
Sep 21 11:38:48.171: INFO: Pod var-expansion-7db5fadd-60ce-4f8f-99a1-7077b7db6cc1 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 11:38:48.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9668" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":356,"completed":37,"skipped":681,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:38:48.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 11:38:51.236: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Sep 21 11:38:51.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4406" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":356,"completed":38,"skipped":689,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:38:51.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:38:51.650: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 11:38:53.660: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 11, 38, 51, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 11, 38, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 11, 38, 51, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 11, 38, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:38:56.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:39:08.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8646" for this suite.
STEP: Destroying namespace "webhook-8646-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:17.623 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":356,"completed":39,"skipped":692,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:08.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test service account token: 
Sep 21 11:39:08.949: INFO: Waiting up to 5m0s for pod "test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153" in namespace "svcaccounts-1818" to be "Succeeded or Failed"
Sep 21 11:39:08.957: INFO: Pod "test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153": Phase="Pending", Reason="", readiness=false. Elapsed: 7.73128ms
Sep 21 11:39:10.971: INFO: Pod "test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021361559s
Sep 21 11:39:12.975: INFO: Pod "test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025360607s
STEP: Saw pod success
Sep 21 11:39:12.975: INFO: Pod "test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153" satisfied condition "Succeeded or Failed"
Sep 21 11:39:12.978: INFO: Trying to get logs from node general-2-xtetrn pod test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:39:12.995: INFO: Waiting for pod test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153 to disappear
Sep 21 11:39:12.998: INFO: Pod test-pod-3a3243a9-d8c3-4ddf-b1f3-dce80faba153 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Sep 21 11:39:12.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1818" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":356,"completed":40,"skipped":716,"failed":0}

------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:13.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-7990
STEP: creating service affinity-clusterip-transition in namespace services-7990
STEP: creating replication controller affinity-clusterip-transition in namespace services-7990
I0921 11:39:13.044377      18 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-7990, replica count: 3
I0921 11:39:16.095767      18 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 11:39:16.104: INFO: Creating new exec pod
Sep 21 11:39:19.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7990 exec execpod-affinitylh2n4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Sep 21 11:39:19.300: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Sep 21 11:39:19.300: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:39:19.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7990 exec execpod-affinitylh2n4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.32.79 80'
Sep 21 11:39:19.402: INFO: stderr: "+ nc -v -t -w 2 10.127.32.79 80\nConnection to 10.127.32.79 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Sep 21 11:39:19.402: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:39:19.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7990 exec execpod-affinitylh2n4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.127.32.79:80/ ; done'
Sep 21 11:39:19.578: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n"
Sep 21 11:39:19.578: INFO: stdout: "\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-pxmst\naffinity-clusterip-transition-wp8vh\naffinity-clusterip-transition-wp8vh\naffinity-clusterip-transition-wp8vh\naffinity-clusterip-transition-wp8vh\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-wp8vh\naffinity-clusterip-transition-wp8vh\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-pxmst\naffinity-clusterip-transition-pxmst\naffinity-clusterip-transition-pxmst\naffinity-clusterip-transition-4ct7z"
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-pxmst
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-wp8vh
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-wp8vh
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-wp8vh
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-wp8vh
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-wp8vh
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-wp8vh
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-pxmst
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-pxmst
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-pxmst
Sep 21 11:39:19.579: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7990 exec execpod-affinitylh2n4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.127.32.79:80/ ; done'
Sep 21 11:39:19.763: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.127.32.79:80/\n"
Sep 21 11:39:19.763: INFO: stdout: "\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z\naffinity-clusterip-transition-4ct7z"
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Received response from host: affinity-clusterip-transition-4ct7z
Sep 21 11:39:19.763: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-7990, will wait for the garbage collector to delete the pods
Sep 21 11:39:19.833: INFO: Deleting ReplicationController affinity-clusterip-transition took: 5.617425ms
Sep 21 11:39:19.934: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.031587ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 11:39:22.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7990" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.362 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":41,"skipped":716,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:22.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Sep 21 11:39:22.396: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:39:24.492: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:39:35.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5937" for this suite.

• [SLOW TEST:13.377 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":356,"completed":42,"skipped":745,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:35.748: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:39:35.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties
Sep 21 11:39:38.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 create -f -'
Sep 21 11:39:39.869: INFO: stderr: ""
Sep 21 11:39:39.869: INFO: stdout: "e2e-test-crd-publish-openapi-6110-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 21 11:39:39.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 delete e2e-test-crd-publish-openapi-6110-crds test-foo'
Sep 21 11:39:39.963: INFO: stderr: ""
Sep 21 11:39:39.963: INFO: stdout: "e2e-test-crd-publish-openapi-6110-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Sep 21 11:39:39.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 apply -f -'
Sep 21 11:39:40.229: INFO: stderr: ""
Sep 21 11:39:40.229: INFO: stdout: "e2e-test-crd-publish-openapi-6110-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 21 11:39:40.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 delete e2e-test-crd-publish-openapi-6110-crds test-foo'
Sep 21 11:39:40.320: INFO: stderr: ""
Sep 21 11:39:40.320: INFO: stdout: "e2e-test-crd-publish-openapi-6110-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values
Sep 21 11:39:40.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 create -f -'
Sep 21 11:39:40.582: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Sep 21 11:39:40.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 create -f -'
Sep 21 11:39:40.834: INFO: rc: 1
Sep 21 11:39:40.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 apply -f -'
Sep 21 11:39:41.105: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties
Sep 21 11:39:41.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 create -f -'
Sep 21 11:39:41.370: INFO: rc: 1
Sep 21 11:39:41.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 --namespace=crd-publish-openapi-7796 apply -f -'
Sep 21 11:39:41.604: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Sep 21 11:39:41.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 explain e2e-test-crd-publish-openapi-6110-crds'
Sep 21 11:39:41.868: INFO: stderr: ""
Sep 21 11:39:41.868: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6110-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Sep 21 11:39:41.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 explain e2e-test-crd-publish-openapi-6110-crds.metadata'
Sep 21 11:39:42.137: INFO: stderr: ""
Sep 21 11:39:42.137: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6110-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     Deprecated: ClusterName is a legacy field that was always cleared by the\n     system and never used; it will be removed completely in 1.25.\n\n     The name in the go struct is changed to help clients detect accidental use.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Sep 21 11:39:42.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 explain e2e-test-crd-publish-openapi-6110-crds.spec'
Sep 21 11:39:42.387: INFO: stderr: ""
Sep 21 11:39:42.387: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6110-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Sep 21 11:39:42.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 explain e2e-test-crd-publish-openapi-6110-crds.spec.bars'
Sep 21 11:39:42.652: INFO: stderr: ""
Sep 21 11:39:42.652: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6110-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Sep 21 11:39:42.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-7796 explain e2e-test-crd-publish-openapi-6110-crds.spec.bars2'
Sep 21 11:39:42.904: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:39:45.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7796" for this suite.

• [SLOW TEST:9.293 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":356,"completed":43,"skipped":758,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:45.045: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name secret-emptykey-test-d7f9fe61-9727-48c2-90e5-fdfec2e65c4e
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Sep 21 11:39:45.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5377" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":356,"completed":44,"skipped":781,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:45.074: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:39:45.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Sep 21 11:39:47.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-841 --namespace=crd-publish-openapi-841 create -f -'
Sep 21 11:39:48.176: INFO: stderr: ""
Sep 21 11:39:48.176: INFO: stdout: "e2e-test-crd-publish-openapi-3414-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 21 11:39:48.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-841 --namespace=crd-publish-openapi-841 delete e2e-test-crd-publish-openapi-3414-crds test-cr'
Sep 21 11:39:48.269: INFO: stderr: ""
Sep 21 11:39:48.269: INFO: stdout: "e2e-test-crd-publish-openapi-3414-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Sep 21 11:39:48.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-841 --namespace=crd-publish-openapi-841 apply -f -'
Sep 21 11:39:48.639: INFO: stderr: ""
Sep 21 11:39:48.639: INFO: stdout: "e2e-test-crd-publish-openapi-3414-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 21 11:39:48.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-841 --namespace=crd-publish-openapi-841 delete e2e-test-crd-publish-openapi-3414-crds test-cr'
Sep 21 11:39:48.734: INFO: stderr: ""
Sep 21 11:39:48.734: INFO: stdout: "e2e-test-crd-publish-openapi-3414-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 21 11:39:48.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-841 explain e2e-test-crd-publish-openapi-3414-crds'
Sep 21 11:39:49.034: INFO: stderr: ""
Sep 21 11:39:49.034: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3414-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:39:51.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-841" for this suite.

• [SLOW TEST:6.212 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":356,"completed":45,"skipped":802,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:51.288: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:39:51.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4165" for this suite.
STEP: Destroying namespace "nspatchtest-d9bdbe42-f1ab-456e-9c57-0ebbe5358048-9904" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":356,"completed":46,"skipped":823,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:51.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:39:51.363: INFO: Creating pod...
Sep 21 11:39:53.381: INFO: Creating service...
Sep 21 11:39:53.394: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=DELETE
Sep 21 11:39:53.410: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Sep 21 11:39:53.410: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=OPTIONS
Sep 21 11:39:53.416: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Sep 21 11:39:53.416: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=PATCH
Sep 21 11:39:53.421: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Sep 21 11:39:53.421: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=POST
Sep 21 11:39:53.425: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Sep 21 11:39:53.425: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=PUT
Sep 21 11:39:53.428: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Sep 21 11:39:53.429: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=DELETE
Sep 21 11:39:53.432: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Sep 21 11:39:53.432: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=OPTIONS
Sep 21 11:39:53.437: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Sep 21 11:39:53.437: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=PATCH
Sep 21 11:39:53.441: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Sep 21 11:39:53.441: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=POST
Sep 21 11:39:53.446: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Sep 21 11:39:53.446: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=PUT
Sep 21 11:39:53.449: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Sep 21 11:39:53.449: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=GET
Sep 21 11:39:53.452: INFO: http.Client request:GET StatusCode:301
Sep 21 11:39:53.452: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=GET
Sep 21 11:39:53.454: INFO: http.Client request:GET StatusCode:301
Sep 21 11:39:53.454: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/pods/agnhost/proxy?method=HEAD
Sep 21 11:39:53.457: INFO: http.Client request:HEAD StatusCode:301
Sep 21 11:39:53.457: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-1113/services/e2e-proxy-test-service/proxy?method=HEAD
Sep 21 11:39:53.460: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Sep 21 11:39:53.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1113" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","total":356,"completed":47,"skipped":848,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:39:53.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Sep 21 11:39:53.515: INFO: The status of Pod labelsupdateedd5b882-3a5d-43b4-88c5-4e3a1c23e70d is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:39:55.520: INFO: The status of Pod labelsupdateedd5b882-3a5d-43b4-88c5-4e3a1c23e70d is Running (Ready = true)
Sep 21 11:39:56.043: INFO: Successfully updated pod "labelsupdateedd5b882-3a5d-43b4-88c5-4e3a1c23e70d"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 11:40:00.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9825" for this suite.

• [SLOW TEST:6.605 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":48,"skipped":850,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:40:00.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4586.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4586.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4586.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4586.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 11:40:10.135: INFO: DNS probes using dns-test-025cfd26-dcf8-4a7c-82d7-5afa87214817 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4586.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4586.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4586.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4586.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 11:40:12.203: INFO: File wheezy_udp@dns-test-service-3.dns-4586.svc.cluster.local from pod  dns-4586/dns-test-2fe2550b-824c-48fd-b1a6-92b8bcac53ac contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 11:40:12.206: INFO: File jessie_udp@dns-test-service-3.dns-4586.svc.cluster.local from pod  dns-4586/dns-test-2fe2550b-824c-48fd-b1a6-92b8bcac53ac contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 11:40:12.206: INFO: Lookups using dns-4586/dns-test-2fe2550b-824c-48fd-b1a6-92b8bcac53ac failed for: [wheezy_udp@dns-test-service-3.dns-4586.svc.cluster.local jessie_udp@dns-test-service-3.dns-4586.svc.cluster.local]

Sep 21 11:40:17.217: INFO: DNS probes using dns-test-2fe2550b-824c-48fd-b1a6-92b8bcac53ac succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4586.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4586.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4586.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4586.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 11:40:19.313: INFO: DNS probes using dns-test-7e36c0d0-57ce-422c-a707-12a4c2ef701c succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 11:40:19.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4586" for this suite.

• [SLOW TEST:19.280 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":356,"completed":49,"skipped":865,"failed":0}
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:40:19.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Sep 21 11:40:32.760: INFO: 68 pods remaining
Sep 21 11:40:32.760: INFO: 68 pods has nil DeletionTimestamp
Sep 21 11:40:32.760: INFO: 
STEP: Gathering metrics
Sep 21 11:40:37.642: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0921 11:40:37.642731      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Sep 21 11:40:37.643: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fzhv" in namespace "gc-5355"
Sep 21 11:40:37.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-2j8l8" in namespace "gc-5355"
Sep 21 11:40:37.677: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nfkd" in namespace "gc-5355"
Sep 21 11:40:37.697: INFO: Deleting pod "simpletest-rc-to-be-deleted-46zl8" in namespace "gc-5355"
Sep 21 11:40:37.705: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r642" in namespace "gc-5355"
Sep 21 11:40:37.713: INFO: Deleting pod "simpletest-rc-to-be-deleted-4sm99" in namespace "gc-5355"
Sep 21 11:40:37.735: INFO: Deleting pod "simpletest-rc-to-be-deleted-5stjw" in namespace "gc-5355"
Sep 21 11:40:37.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-5svcv" in namespace "gc-5355"
Sep 21 11:40:37.753: INFO: Deleting pod "simpletest-rc-to-be-deleted-66bf8" in namespace "gc-5355"
Sep 21 11:40:37.793: INFO: Deleting pod "simpletest-rc-to-be-deleted-66lsw" in namespace "gc-5355"
Sep 21 11:40:37.811: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hpdw" in namespace "gc-5355"
Sep 21 11:40:37.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rqb6" in namespace "gc-5355"
Sep 21 11:40:37.906: INFO: Deleting pod "simpletest-rc-to-be-deleted-6z6mx" in namespace "gc-5355"
Sep 21 11:40:37.920: INFO: Deleting pod "simpletest-rc-to-be-deleted-727hl" in namespace "gc-5355"
Sep 21 11:40:37.938: INFO: Deleting pod "simpletest-rc-to-be-deleted-75fzl" in namespace "gc-5355"
Sep 21 11:40:38.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-7b45h" in namespace "gc-5355"
Sep 21 11:40:38.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-7bl84" in namespace "gc-5355"
Sep 21 11:40:38.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ckgj" in namespace "gc-5355"
Sep 21 11:40:38.194: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hm97" in namespace "gc-5355"
Sep 21 11:40:38.223: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ktvr" in namespace "gc-5355"
Sep 21 11:40:38.450: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mdjm" in namespace "gc-5355"
Sep 21 11:40:38.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-7nn5j" in namespace "gc-5355"
Sep 21 11:40:38.568: INFO: Deleting pod "simpletest-rc-to-be-deleted-82vcg" in namespace "gc-5355"
Sep 21 11:40:38.613: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gqlb" in namespace "gc-5355"
Sep 21 11:40:38.628: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hh6k" in namespace "gc-5355"
Sep 21 11:40:38.642: INFO: Deleting pod "simpletest-rc-to-be-deleted-8s26q" in namespace "gc-5355"
Sep 21 11:40:38.718: INFO: Deleting pod "simpletest-rc-to-be-deleted-8xcnt" in namespace "gc-5355"
Sep 21 11:40:38.809: INFO: Deleting pod "simpletest-rc-to-be-deleted-948cb" in namespace "gc-5355"
Sep 21 11:40:38.816: INFO: Deleting pod "simpletest-rc-to-be-deleted-9h9j6" in namespace "gc-5355"
Sep 21 11:40:38.829: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qxr4" in namespace "gc-5355"
Sep 21 11:40:38.919: INFO: Deleting pod "simpletest-rc-to-be-deleted-9szjg" in namespace "gc-5355"
Sep 21 11:40:38.968: INFO: Deleting pod "simpletest-rc-to-be-deleted-9vdlp" in namespace "gc-5355"
Sep 21 11:40:38.978: INFO: Deleting pod "simpletest-rc-to-be-deleted-b2mlm" in namespace "gc-5355"
Sep 21 11:40:39.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-c5fkz" in namespace "gc-5355"
Sep 21 11:40:39.065: INFO: Deleting pod "simpletest-rc-to-be-deleted-c72gs" in namespace "gc-5355"
Sep 21 11:40:39.073: INFO: Deleting pod "simpletest-rc-to-be-deleted-cfk49" in namespace "gc-5355"
Sep 21 11:40:39.113: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5pgj" in namespace "gc-5355"
Sep 21 11:40:39.134: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7t5x" in namespace "gc-5355"
Sep 21 11:40:39.142: INFO: Deleting pod "simpletest-rc-to-be-deleted-dphcn" in namespace "gc-5355"
Sep 21 11:40:39.151: INFO: Deleting pod "simpletest-rc-to-be-deleted-drgff" in namespace "gc-5355"
Sep 21 11:40:39.189: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsw75" in namespace "gc-5355"
Sep 21 11:40:39.200: INFO: Deleting pod "simpletest-rc-to-be-deleted-dtp58" in namespace "gc-5355"
Sep 21 11:40:39.232: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9pcz" in namespace "gc-5355"
Sep 21 11:40:39.420: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9vkv" in namespace "gc-5355"
Sep 21 11:40:39.697: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbd8v" in namespace "gc-5355"
Sep 21 11:40:39.722: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjlmn" in namespace "gc-5355"
Sep 21 11:40:40.221: INFO: Deleting pod "simpletest-rc-to-be-deleted-hmkfs" in namespace "gc-5355"
Sep 21 11:40:40.479: INFO: Deleting pod "simpletest-rc-to-be-deleted-hzmgk" in namespace "gc-5355"
Sep 21 11:40:40.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-j7psw" in namespace "gc-5355"
Sep 21 11:40:40.668: INFO: Deleting pod "simpletest-rc-to-be-deleted-jsnrn" in namespace "gc-5355"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Sep 21 11:40:40.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5355" for this suite.

• [SLOW TEST:21.439 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":356,"completed":50,"skipped":865,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:40:40.798: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:40:40.875: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Sep 21 11:40:44.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-2965 --namespace=crd-publish-openapi-2965 create -f -'
Sep 21 11:40:44.851: INFO: stderr: ""
Sep 21 11:40:44.851: INFO: stdout: "e2e-test-crd-publish-openapi-879-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 21 11:40:44.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-2965 --namespace=crd-publish-openapi-2965 delete e2e-test-crd-publish-openapi-879-crds test-cr'
Sep 21 11:40:44.930: INFO: stderr: ""
Sep 21 11:40:44.930: INFO: stdout: "e2e-test-crd-publish-openapi-879-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Sep 21 11:40:44.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-2965 --namespace=crd-publish-openapi-2965 apply -f -'
Sep 21 11:40:45.155: INFO: stderr: ""
Sep 21 11:40:45.155: INFO: stdout: "e2e-test-crd-publish-openapi-879-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 21 11:40:45.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-2965 --namespace=crd-publish-openapi-2965 delete e2e-test-crd-publish-openapi-879-crds test-cr'
Sep 21 11:40:45.250: INFO: stderr: ""
Sep 21 11:40:45.250: INFO: stdout: "e2e-test-crd-publish-openapi-879-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 21 11:40:45.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-2965 explain e2e-test-crd-publish-openapi-879-crds'
Sep 21 11:40:45.459: INFO: stderr: ""
Sep 21 11:40:45.459: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-879-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:40:47.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2965" for this suite.

• [SLOW TEST:6.828 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":356,"completed":51,"skipped":880,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:40:47.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-32e66ebb-ceec-4914-adab-635b3592f3d7
STEP: Creating a pod to test consume secrets
Sep 21 11:40:47.658: INFO: Waiting up to 5m0s for pod "pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3" in namespace "secrets-326" to be "Succeeded or Failed"
Sep 21 11:40:47.661: INFO: Pod "pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.680659ms
Sep 21 11:40:49.670: INFO: Pod "pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012139375s
Sep 21 11:40:51.676: INFO: Pod "pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017960814s
STEP: Saw pod success
Sep 21 11:40:51.676: INFO: Pod "pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3" satisfied condition "Succeeded or Failed"
Sep 21 11:40:51.678: INFO: Trying to get logs from node general-2-xtetrn pod pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 11:40:51.688: INFO: Waiting for pod pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3 to disappear
Sep 21 11:40:51.689: INFO: Pod pod-secrets-0f302577-8544-4edb-b413-a09635d4f7e3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 11:40:51.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-326" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":52,"skipped":907,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:40:51.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2379.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2379.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2379.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2379.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 241.15.127.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.127.15.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.15.127.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.127.15.241_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2379.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2379.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2379.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2379.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2379.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 241.15.127.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.127.15.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.15.127.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.127.15.241_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 11:40:53.783: INFO: Unable to read wheezy_udp@dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.785: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.789: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.793: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.805: INFO: Unable to read jessie_udp@dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.810: INFO: Unable to read jessie_tcp@dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.816: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.819: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local from pod dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b: the server could not find the requested resource (get pods dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b)
Sep 21 11:40:53.830: INFO: Lookups using dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b failed for: [wheezy_udp@dns-test-service.dns-2379.svc.cluster.local wheezy_tcp@dns-test-service.dns-2379.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local jessie_udp@dns-test-service.dns-2379.svc.cluster.local jessie_tcp@dns-test-service.dns-2379.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2379.svc.cluster.local]

Sep 21 11:40:58.867: INFO: DNS probes using dns-2379/dns-test-a4c7e822-8a1f-4baa-9845-33baf7e5766b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 11:40:58.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2379" for this suite.

• [SLOW TEST:7.275 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":356,"completed":53,"skipped":915,"failed":0}
SSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:40:58.974: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Sep 21 11:40:58.998: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 11:41:59.019: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:41:59.022: INFO: Starting informer...
STEP: Starting pod...
Sep 21 11:41:59.041: INFO: Pod is running on general-2-xtetrn. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Sep 21 11:41:59.102: INFO: Pod wasn't evicted. Proceeding
Sep 21 11:41:59.102: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Sep 21 11:43:14.126: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:43:14.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4619" for this suite.

• [SLOW TEST:135.165 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":356,"completed":54,"skipped":921,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:14.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Sep 21 11:43:14.165: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Sep 21 11:43:18.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4726" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":356,"completed":55,"skipped":933,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:18.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:43:19.098: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:43:22.122: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:43:22.129: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:43:25.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5770" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:6.798 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":356,"completed":56,"skipped":936,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:25.456: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 21 11:43:25.532: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9976  9d06f141-d9b2-4e8e-b207-d142bdc0c662 8546 0 2022-09-21 11:43:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-09-21 11:43:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 11:43:25.532: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9976  9d06f141-d9b2-4e8e-b207-d142bdc0c662 8547 0 2022-09-21 11:43:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-09-21 11:43:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Sep 21 11:43:25.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9976" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":356,"completed":57,"skipped":938,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:25.562: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 11:43:25.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-795" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":356,"completed":58,"skipped":952,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:25.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 11:43:25.636: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c" in namespace "projected-458" to be "Succeeded or Failed"
Sep 21 11:43:25.670: INFO: Pod "downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c": Phase="Pending", Reason="", readiness=false. Elapsed: 33.570952ms
Sep 21 11:43:27.678: INFO: Pod "downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04166536s
Sep 21 11:43:29.692: INFO: Pod "downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055048472s
STEP: Saw pod success
Sep 21 11:43:29.692: INFO: Pod "downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c" satisfied condition "Succeeded or Failed"
Sep 21 11:43:29.695: INFO: Trying to get logs from node general-2-xtetrn pod downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c container client-container: <nil>
STEP: delete the pod
Sep 21 11:43:29.715: INFO: Waiting for pod downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c to disappear
Sep 21 11:43:29.717: INFO: Pod downwardapi-volume-5503dd92-06ee-4008-a258-10d5fedbef8c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 11:43:29.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-458" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":59,"skipped":975,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:29.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 21 11:43:29.768: INFO: Waiting up to 5m0s for pod "pod-777a2042-0c12-4952-b515-64aba12475f7" in namespace "emptydir-1729" to be "Succeeded or Failed"
Sep 21 11:43:29.771: INFO: Pod "pod-777a2042-0c12-4952-b515-64aba12475f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.843313ms
Sep 21 11:43:31.795: INFO: Pod "pod-777a2042-0c12-4952-b515-64aba12475f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027403996s
Sep 21 11:43:33.812: INFO: Pod "pod-777a2042-0c12-4952-b515-64aba12475f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044385523s
STEP: Saw pod success
Sep 21 11:43:33.812: INFO: Pod "pod-777a2042-0c12-4952-b515-64aba12475f7" satisfied condition "Succeeded or Failed"
Sep 21 11:43:33.815: INFO: Trying to get logs from node general-2-xtetrn pod pod-777a2042-0c12-4952-b515-64aba12475f7 container test-container: <nil>
STEP: delete the pod
Sep 21 11:43:33.965: INFO: Waiting for pod pod-777a2042-0c12-4952-b515-64aba12475f7 to disappear
Sep 21 11:43:33.968: INFO: Pod pod-777a2042-0c12-4952-b515-64aba12475f7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 11:43:33.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1729" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":60,"skipped":1014,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:33.976: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:43:40.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8041" for this suite.
STEP: Destroying namespace "nsdeletetest-5516" for this suite.
Sep 21 11:43:40.070: INFO: Namespace nsdeletetest-5516 was already deleted
STEP: Destroying namespace "nsdeletetest-6856" for this suite.

• [SLOW TEST:6.098 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":356,"completed":61,"skipped":1015,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:40.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:43:40.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:43:46.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8937" for this suite.

• [SLOW TEST:6.309 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":356,"completed":62,"skipped":1028,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:46.390: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 21 11:43:46.420: INFO: Waiting up to 5m0s for pod "pod-9e0e2674-2c87-4738-888a-a4dccce39eb1" in namespace "emptydir-3481" to be "Succeeded or Failed"
Sep 21 11:43:46.428: INFO: Pod "pod-9e0e2674-2c87-4738-888a-a4dccce39eb1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.551437ms
Sep 21 11:43:48.435: INFO: Pod "pod-9e0e2674-2c87-4738-888a-a4dccce39eb1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014617388s
Sep 21 11:43:50.446: INFO: Pod "pod-9e0e2674-2c87-4738-888a-a4dccce39eb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025278281s
STEP: Saw pod success
Sep 21 11:43:50.446: INFO: Pod "pod-9e0e2674-2c87-4738-888a-a4dccce39eb1" satisfied condition "Succeeded or Failed"
Sep 21 11:43:50.449: INFO: Trying to get logs from node general-2-xtetrn pod pod-9e0e2674-2c87-4738-888a-a4dccce39eb1 container test-container: <nil>
STEP: delete the pod
Sep 21 11:43:50.460: INFO: Waiting for pod pod-9e0e2674-2c87-4738-888a-a4dccce39eb1 to disappear
Sep 21 11:43:50.463: INFO: Pod pod-9e0e2674-2c87-4738-888a-a4dccce39eb1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 11:43:50.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3481" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":63,"skipped":1043,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:50.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Sep 21 11:43:50.496: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Sep 21 11:43:53.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6761" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":356,"completed":64,"skipped":1058,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:53.797: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating api versions
Sep 21 11:43:53.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2573 api-versions'
Sep 21 11:43:53.918: INFO: stderr: ""
Sep 21 11:43:53.918: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninternal.apiserver.k8s.io/v1alpha1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:43:53.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2573" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":356,"completed":65,"skipped":1079,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:53.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Sep 21 11:43:53.956: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 21 11:43:58.972: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Sep 21 11:43:59.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2700" for this suite.

• [SLOW TEST:5.097 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":356,"completed":66,"skipped":1092,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:43:59.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Sep 21 11:43:59.069: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 11:44:59.094: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:44:59.096: INFO: Starting informer...
STEP: Starting pods...
Sep 21 11:44:59.314: INFO: Pod1 is running on general-2-xtetrn. Tainting Node
Sep 21 11:45:01.542: INFO: Pod2 is running on general-2-xtetrn. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Sep 21 11:45:07.255: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Sep 21 11:45:27.002: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:45:27.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4706" for this suite.

• [SLOW TEST:87.994 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":356,"completed":67,"skipped":1110,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:45:27.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9316.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9316.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9316.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9316.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 11:45:29.116: INFO: DNS probes using dns-9316/dns-test-742f7bbc-b2d9-4c71-bda2-53ea2929adf7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 11:45:29.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9316" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","total":356,"completed":68,"skipped":1149,"failed":0}
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:45:29.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-4334
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 11:45:29.236: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 21 11:45:29.264: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:45:31.275: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:45:33.269: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:45:35.275: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:45:37.272: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:45:39.270: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:45:41.276: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 21 11:45:41.289: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 21 11:45:43.294: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 21 11:45:45.301: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 21 11:45:47.299: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 21 11:45:49.297: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 21 11:45:51.300: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 21 11:45:53.319: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Sep 21 11:45:53.319: INFO: Breadth first check of 10.129.210.93 on host 10.128.0.2...
Sep 21 11:45:53.321: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.129.53.195:9080/dial?request=hostname&protocol=udp&host=10.129.210.93&port=8081&tries=1'] Namespace:pod-network-test-4334 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 11:45:53.321: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:45:53.322: INFO: ExecWithOptions: Clientset creation
Sep 21 11:45:53.322: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-4334/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.129.53.195%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.129.210.93%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Sep 21 11:45:53.411: INFO: Waiting for responses: map[]
Sep 21 11:45:53.411: INFO: reached 10.129.210.93 after 0/1 tries
Sep 21 11:45:53.411: INFO: Breadth first check of 10.129.53.206 on host 10.128.0.3...
Sep 21 11:45:53.414: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.129.53.195:9080/dial?request=hostname&protocol=udp&host=10.129.53.206&port=8081&tries=1'] Namespace:pod-network-test-4334 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 11:45:53.414: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:45:53.415: INFO: ExecWithOptions: Clientset creation
Sep 21 11:45:53.415: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-4334/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.129.53.195%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.129.53.206%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Sep 21 11:45:53.489: INFO: Waiting for responses: map[]
Sep 21 11:45:53.489: INFO: reached 10.129.53.206 after 0/1 tries
Sep 21 11:45:53.489: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Sep 21 11:45:53.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4334" for this suite.

• [SLOW TEST:24.290 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":356,"completed":69,"skipped":1155,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:45:53.516: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3042 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3042;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3042 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3042;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3042.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3042.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3042.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3042.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3042.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3042.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3042.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3042.svc;check="$$(dig +notcp +noall +answer +search 170.62.125.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.125.62.170_udp@PTR;check="$$(dig +tcp +noall +answer +search 170.62.125.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.125.62.170_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3042 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3042;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3042 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3042;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3042.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3042.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3042.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3042.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3042.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3042.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3042.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3042.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3042.svc;check="$$(dig +notcp +noall +answer +search 170.62.125.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.125.62.170_udp@PTR;check="$$(dig +tcp +noall +answer +search 170.62.125.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.125.62.170_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 11:45:55.620: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.631: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.638: INFO: Unable to read wheezy_udp@dns-test-service.dns-3042 from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.642: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3042 from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.646: INFO: Unable to read wheezy_udp@dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.649: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.652: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.655: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.666: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.668: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.671: INFO: Unable to read jessie_udp@dns-test-service.dns-3042 from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.677: INFO: Unable to read jessie_tcp@dns-test-service.dns-3042 from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.681: INFO: Unable to read jessie_udp@dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.689: INFO: Unable to read jessie_tcp@dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.696: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.699: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3042.svc from pod dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db: the server could not find the requested resource (get pods dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db)
Sep 21 11:45:55.711: INFO: Lookups using dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3042 wheezy_tcp@dns-test-service.dns-3042 wheezy_udp@dns-test-service.dns-3042.svc wheezy_tcp@dns-test-service.dns-3042.svc wheezy_udp@_http._tcp.dns-test-service.dns-3042.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3042.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3042 jessie_tcp@dns-test-service.dns-3042 jessie_udp@dns-test-service.dns-3042.svc jessie_tcp@dns-test-service.dns-3042.svc jessie_udp@_http._tcp.dns-test-service.dns-3042.svc jessie_tcp@_http._tcp.dns-test-service.dns-3042.svc]

Sep 21 11:46:00.765: INFO: DNS probes using dns-3042/dns-test-4856d492-fdaa-48a1-a75c-bef6ecbd23db succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 11:46:00.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3042" for this suite.

• [SLOW TEST:7.335 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":356,"completed":70,"skipped":1187,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:00.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6815
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6815
I0921 11:46:00.886482      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6815, replica count: 2
I0921 11:46:03.937742      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 11:46:03.938: INFO: Creating new exec pod
Sep 21 11:46:06.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-6815 exec execpodwfgnp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Sep 21 11:46:07.119: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 21 11:46:07.119: INFO: stdout: "externalname-service-w8d6z"
Sep 21 11:46:07.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-6815 exec execpodwfgnp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.55.157 80'
Sep 21 11:46:07.281: INFO: stderr: "+ nc -v -t -w 2 10.127.55.157 80\n+ echo hostName\nConnection to 10.127.55.157 80 port [tcp/http] succeeded!\n"
Sep 21 11:46:07.281: INFO: stdout: "externalname-service-w8d6z"
Sep 21 11:46:07.281: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 11:46:07.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6815" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:6.473 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":356,"completed":71,"skipped":1200,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:07.327: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 21 11:46:07.365: INFO: Waiting up to 5m0s for pod "pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06" in namespace "emptydir-4152" to be "Succeeded or Failed"
Sep 21 11:46:07.368: INFO: Pod "pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646965ms
Sep 21 11:46:09.377: INFO: Pod "pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06": Phase="Running", Reason="", readiness=false. Elapsed: 2.011706699s
Sep 21 11:46:11.384: INFO: Pod "pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01917802s
STEP: Saw pod success
Sep 21 11:46:11.384: INFO: Pod "pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06" satisfied condition "Succeeded or Failed"
Sep 21 11:46:11.386: INFO: Trying to get logs from node general-2-xtetrn pod pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06 container test-container: <nil>
STEP: delete the pod
Sep 21 11:46:11.406: INFO: Waiting for pod pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06 to disappear
Sep 21 11:46:11.408: INFO: Pod pod-ff9c9974-73d1-4d62-bfa9-6f8e3ab0ed06 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 11:46:11.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4152" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":72,"skipped":1216,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:11.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:46:11.895: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:46:14.908: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:46:14.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9612" for this suite.
STEP: Destroying namespace "webhook-9612-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":356,"completed":73,"skipped":1224,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:15.058: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:46:15.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: creating the pod
STEP: submitting the pod to kubernetes
Sep 21 11:46:15.083: INFO: The status of Pod pod-exec-websocket-8cffd985-90c0-49ac-9486-39131ab41b9a is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:46:17.089: INFO: The status of Pod pod-exec-websocket-8cffd985-90c0-49ac-9486-39131ab41b9a is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 11:46:17.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5213" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":356,"completed":74,"skipped":1237,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:17.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:46:17.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:46:20.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1869" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":356,"completed":75,"skipped":1239,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:20.477: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
Sep 21 11:46:20.498: INFO: Creating simple deployment test-deployment-26tnq
Sep 21 11:46:20.508: INFO: deployment "test-deployment-26tnq" doesn't have the required revision set
STEP: Getting /status
Sep 21 11:46:22.529: INFO: Deployment test-deployment-26tnq has Conditions: [{Available True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-26tnq-688c4d6789" has successfully progressed.}]
STEP: updating Deployment Status
Sep 21 11:46:22.538: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 11, 46, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 11, 46, 22, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 11, 46, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 11, 46, 20, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-26tnq-688c4d6789\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Sep 21 11:46:22.540: INFO: Observed &Deployment event: ADDED
Sep 21 11:46:22.540: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-26tnq-688c4d6789"}
Sep 21 11:46:22.541: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.541: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-26tnq-688c4d6789"}
Sep 21 11:46:22.541: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Sep 21 11:46:22.542: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.542: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Sep 21 11:46:22.542: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-26tnq-688c4d6789" is progressing.}
Sep 21 11:46:22.542: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.542: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Sep 21 11:46:22.542: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-26tnq-688c4d6789" has successfully progressed.}
Sep 21 11:46:22.543: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.543: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Sep 21 11:46:22.543: INFO: Observed Deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-26tnq-688c4d6789" has successfully progressed.}
Sep 21 11:46:22.543: INFO: Found Deployment test-deployment-26tnq in namespace deployment-5994 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Sep 21 11:46:22.543: INFO: Deployment test-deployment-26tnq has an updated status
STEP: patching the Statefulset Status
Sep 21 11:46:22.544: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Sep 21 11:46:22.550: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Sep 21 11:46:22.557: INFO: Observed &Deployment event: ADDED
Sep 21 11:46:22.557: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-26tnq-688c4d6789"}
Sep 21 11:46:22.557: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.557: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-26tnq-688c4d6789"}
Sep 21 11:46:22.557: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Sep 21 11:46:22.558: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.558: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Sep 21 11:46:22.558: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:20 +0000 UTC 2022-09-21 11:46:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-26tnq-688c4d6789" is progressing.}
Sep 21 11:46:22.558: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.558: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Sep 21 11:46:22.558: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-26tnq-688c4d6789" has successfully progressed.}
Sep 21 11:46:22.559: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.559: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Sep 21 11:46:22.559: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-09-21 11:46:22 +0000 UTC 2022-09-21 11:46:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-26tnq-688c4d6789" has successfully progressed.}
Sep 21 11:46:22.559: INFO: Observed deployment test-deployment-26tnq in namespace deployment-5994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Sep 21 11:46:22.559: INFO: Observed &Deployment event: MODIFIED
Sep 21 11:46:22.559: INFO: Found deployment test-deployment-26tnq in namespace deployment-5994 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Sep 21 11:46:22.559: INFO: Deployment test-deployment-26tnq has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 11:46:22.563: INFO: Deployment "test-deployment-26tnq":
&Deployment{ObjectMeta:{test-deployment-26tnq  deployment-5994  3fd720ed-ee83-4626-8f16-666620569716 9675 1 2022-09-21 11:46:20 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-09-21 11:46:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-09-21 11:46:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-09-21 11:46:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00450bc88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-26tnq-688c4d6789",LastUpdateTime:2022-09-21 11:46:22 +0000 UTC,LastTransitionTime:2022-09-21 11:46:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 21 11:46:22.565: INFO: New ReplicaSet "test-deployment-26tnq-688c4d6789" of Deployment "test-deployment-26tnq":
&ReplicaSet{ObjectMeta:{test-deployment-26tnq-688c4d6789  deployment-5994  68c2fcc5-d094-4cd8-bce9-c010814eb276 9664 1 2022-09-21 11:46:20 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-26tnq 3fd720ed-ee83-4626-8f16-666620569716 0xc003fc6750 0xc003fc6751}] []  [{kube-controller-manager Update apps/v1 2022-09-21 11:46:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3fd720ed-ee83-4626-8f16-666620569716\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 11:46:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 688c4d6789,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fc67f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 11:46:22.569: INFO: Pod "test-deployment-26tnq-688c4d6789-fmx4x" is available:
&Pod{ObjectMeta:{test-deployment-26tnq-688c4d6789-fmx4x test-deployment-26tnq-688c4d6789- deployment-5994  c1471c11-dc93-44ae-a8c7-d5e81608cd4c 9663 0 2022-09-21 11:46:20 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[cni.projectcalico.org/containerID:9922884bbcc167f1a93381842e104691953903f6d4237ae1927eb3057a9c10bc cni.projectcalico.org/podIP:10.129.53.209/32 cni.projectcalico.org/podIPs:10.129.53.209/32] [{apps/v1 ReplicaSet test-deployment-26tnq-688c4d6789 68c2fcc5-d094-4cd8-bce9-c010814eb276 0xc004538077 0xc004538078}] []  [{kube-controller-manager Update v1 2022-09-21 11:46:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68c2fcc5-d094-4cd8-bce9-c010814eb276\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 11:46:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 11:46:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.53.209\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nnnfj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nnnfj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:46:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:46:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:46:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 11:46:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.3,PodIP:10.129.53.209,StartTime:2022-09-21 11:46:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 11:46:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3c01d06a0b3eae348e8954ceff6a98c44d5dea7cdfa6c844a1c725cd63b91862,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.53.209,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 11:46:22.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5994" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":356,"completed":76,"skipped":1263,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:22.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 11:46:22.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7747" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":356,"completed":77,"skipped":1282,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:22.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 11:46:22.635: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98" in namespace "projected-8672" to be "Succeeded or Failed"
Sep 21 11:46:22.638: INFO: Pod "downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.051662ms
Sep 21 11:46:24.648: INFO: Pod "downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013010359s
Sep 21 11:46:26.656: INFO: Pod "downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020251632s
STEP: Saw pod success
Sep 21 11:46:26.656: INFO: Pod "downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98" satisfied condition "Succeeded or Failed"
Sep 21 11:46:26.658: INFO: Trying to get logs from node general-2-xtetrn pod downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98 container client-container: <nil>
STEP: delete the pod
Sep 21 11:46:26.671: INFO: Waiting for pod downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98 to disappear
Sep 21 11:46:26.673: INFO: Pod downwardapi-volume-6c67f50c-f623-4c77-87b4-c0a1dcec5d98 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 11:46:26.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8672" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":78,"skipped":1286,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:26.682: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-3a317a00-bca1-40c3-a0c6-d0d05b1113fd
STEP: Creating a pod to test consume secrets
Sep 21 11:46:26.717: INFO: Waiting up to 5m0s for pod "pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6" in namespace "secrets-6708" to be "Succeeded or Failed"
Sep 21 11:46:26.725: INFO: Pod "pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.638595ms
Sep 21 11:46:28.731: INFO: Pod "pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01373776s
Sep 21 11:46:30.741: INFO: Pod "pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024086681s
STEP: Saw pod success
Sep 21 11:46:30.742: INFO: Pod "pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6" satisfied condition "Succeeded or Failed"
Sep 21 11:46:30.744: INFO: Trying to get logs from node general-2-xtetrn pod pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6 container secret-env-test: <nil>
STEP: delete the pod
Sep 21 11:46:30.755: INFO: Waiting for pod pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6 to disappear
Sep 21 11:46:30.757: INFO: Pod pod-secrets-d98e3685-ce10-4cc6-9a10-ca934b74acd6 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Sep 21 11:46:30.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6708" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":356,"completed":79,"skipped":1307,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:30.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:46:31.405: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:46:34.425: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:46:34.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7102-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:46:37.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6778" for this suite.
STEP: Destroying namespace "webhook-6778-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.921 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":356,"completed":80,"skipped":1327,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:37.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:46:37.759: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 21 11:46:42.787: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Sep 21 11:46:42.795: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Sep 21 11:46:42.870: INFO: observed ReplicaSet test-rs in namespace replicaset-9738 with ReadyReplicas 1, AvailableReplicas 1
Sep 21 11:46:42.876: INFO: observed ReplicaSet test-rs in namespace replicaset-9738 with ReadyReplicas 1, AvailableReplicas 1
Sep 21 11:46:42.898: INFO: observed ReplicaSet test-rs in namespace replicaset-9738 with ReadyReplicas 1, AvailableReplicas 1
Sep 21 11:46:42.902: INFO: observed ReplicaSet test-rs in namespace replicaset-9738 with ReadyReplicas 1, AvailableReplicas 1
Sep 21 11:46:43.967: INFO: observed ReplicaSet test-rs in namespace replicaset-9738 with ReadyReplicas 2, AvailableReplicas 2
Sep 21 11:46:44.283: INFO: observed Replicaset test-rs in namespace replicaset-9738 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Sep 21 11:46:44.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9738" for this suite.

• [SLOW TEST:6.604 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":356,"completed":81,"skipped":1344,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:44.295: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Sep 21 11:46:44.323: INFO: Waiting up to 5m0s for pod "downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a" in namespace "downward-api-794" to be "Succeeded or Failed"
Sep 21 11:46:44.334: INFO: Pod "downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.62929ms
Sep 21 11:46:46.341: INFO: Pod "downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018052296s
Sep 21 11:46:48.347: INFO: Pod "downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023715776s
STEP: Saw pod success
Sep 21 11:46:48.347: INFO: Pod "downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a" satisfied condition "Succeeded or Failed"
Sep 21 11:46:48.348: INFO: Trying to get logs from node general-2-xtetrn pod downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a container dapi-container: <nil>
STEP: delete the pod
Sep 21 11:46:48.356: INFO: Waiting for pod downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a to disappear
Sep 21 11:46:48.358: INFO: Pod downward-api-de96e551-21a0-4796-aba5-071ff7ca1b3a no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Sep 21 11:46:48.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-794" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":356,"completed":82,"skipped":1357,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:48.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Sep 21 11:46:48.381: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 11:46:48.385: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 11:46:48.386: INFO: 
Logging pods the apiserver thinks is on node general-2-giltle before test
Sep 21 11:46:48.391: INFO: calico-kube-controllers-56cdb7c587-l6wfl from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.391: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 11:46:48.391: INFO: calico-node-qzjzx from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.391: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 11:46:48.391: INFO: calico-typha-6775694657-5m6fr from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.392: INFO: 	Container calico-typha ready: true, restart count 0
Sep 21 11:46:48.392: INFO: coredns-685b6584b-2qb7m from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.392: INFO: 	Container coredns ready: true, restart count 0
Sep 21 11:46:48.392: INFO: coredns-685b6584b-rrbqm from kube-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.392: INFO: 	Container coredns ready: true, restart count 0
Sep 21 11:46:48.392: INFO: kube-proxy-gr4mj from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.392: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 11:46:48.392: INFO: test-rs-m5bdw from replicaset-9738 started at 2022-09-21 11:46:42 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.393: INFO: 	Container httpd ready: true, restart count 0
Sep 21 11:46:48.393: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-lv7nl from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 11:46:48.393: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 11:46:48.393: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 11:46:48.393: INFO: csi-symbiosis-node-ldcxc from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (2 container statuses recorded)
Sep 21 11:46:48.393: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 11:46:48.393: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 21 11:46:48.394: INFO: symbiosis-block-csi-controller-0 from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (3 container statuses recorded)
Sep 21 11:46:48.394: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 21 11:46:48.394: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 21 11:46:48.394: INFO: 	Container symbiosis-csi-plugin ready: true, restart count 0
Sep 21 11:46:48.394: INFO: symbiosis-cloud-controller-manager-67cd6bf5b9-tshp2 from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.394: INFO: 	Container symbiosis-cloud-controller-manager ready: true, restart count 0
Sep 21 11:46:48.394: INFO: symbiosis-k8s-controller-676ccb7ff7-2wdvp from symbiosis-system started at 2022-09-21 11:22:49 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.394: INFO: 	Container symbiosis-k8s-controller ready: true, restart count 0
Sep 21 11:46:48.395: INFO: 
Logging pods the apiserver thinks is on node general-2-xtetrn before test
Sep 21 11:46:48.399: INFO: calico-node-f4g47 from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.399: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 11:46:48.399: INFO: kube-proxy-687zc from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.399: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 11:46:48.400: INFO: pod-exec-websocket-8cffd985-90c0-49ac-9486-39131ab41b9a from pods-5213 started at 2022-09-21 11:46:15 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.400: INFO: 	Container main ready: true, restart count 0
Sep 21 11:46:48.400: INFO: test-rs-6zclg from replicaset-9738 started at 2022-09-21 11:46:37 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.400: INFO: 	Container httpd ready: true, restart count 0
Sep 21 11:46:48.400: INFO: test-rs-rbnj8 from replicaset-9738 started at 2022-09-21 11:46:42 +0000 UTC (2 container statuses recorded)
Sep 21 11:46:48.400: INFO: 	Container httpd ready: true, restart count 0
Sep 21 11:46:48.400: INFO: 	Container test-rs ready: true, restart count 0
Sep 21 11:46:48.400: INFO: sonobuoy from sonobuoy started at 2022-09-21 11:23:09 +0000 UTC (1 container statuses recorded)
Sep 21 11:46:48.401: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 11:46:48.401: INFO: sonobuoy-e2e-job-d15d7ff7630543da from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 11:46:48.401: INFO: 	Container e2e ready: true, restart count 0
Sep 21 11:46:48.401: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 11:46:48.401: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-xk2rh from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 11:46:48.401: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 11:46:48.401: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 11:46:48.401: INFO: csi-symbiosis-node-lkfrb from symbiosis-system started at 2022-09-21 11:45:27 +0000 UTC (2 container statuses recorded)
Sep 21 11:46:48.401: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 11:46:48.402: INFO: 	Container driver-registrar ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
STEP: verifying the node has the label node general-2-giltle
STEP: verifying the node has the label node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod calico-kube-controllers-56cdb7c587-l6wfl requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod calico-node-f4g47 requesting resource cpu=250m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod calico-node-qzjzx requesting resource cpu=250m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod calico-typha-6775694657-5m6fr requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod coredns-685b6584b-2qb7m requesting resource cpu=100m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod coredns-685b6584b-rrbqm requesting resource cpu=100m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod kube-proxy-687zc requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod kube-proxy-gr4mj requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod pod-exec-websocket-8cffd985-90c0-49ac-9486-39131ab41b9a requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod test-rs-6zclg requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod test-rs-m5bdw requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod test-rs-rbnj8 requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod sonobuoy requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod sonobuoy-e2e-job-d15d7ff7630543da requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-lv7nl requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-xk2rh requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod csi-symbiosis-node-ldcxc requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod csi-symbiosis-node-lkfrb requesting resource cpu=0m on Node general-2-xtetrn
Sep 21 11:46:48.430: INFO: Pod symbiosis-block-csi-controller-0 requesting resource cpu=0m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod symbiosis-cloud-controller-manager-67cd6bf5b9-tshp2 requesting resource cpu=100m on Node general-2-giltle
Sep 21 11:46:48.430: INFO: Pod symbiosis-k8s-controller-676ccb7ff7-2wdvp requesting resource cpu=100m on Node general-2-giltle
STEP: Starting Pods to consume most of the cluster CPU.
Sep 21 11:46:48.430: INFO: Creating a pod which consumes cpu=1225m on Node general-2-xtetrn
Sep 21 11:46:48.435: INFO: Creating a pod which consumes cpu=945m on Node general-2-giltle
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6.1716dda3eb293b43], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8131/filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6 to general-2-giltle]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6.1716dda411b0fe9c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6.1716dda4126b5cb4], Reason = [Created], Message = [Created container filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6.1716dda416327515], Reason = [Started], Message = [Started container filler-pod-39cfca2b-f4c4-44d5-ba17-475a3986c7a6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf.1716dda3ea74da79], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8131/filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf to general-2-xtetrn]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf.1716dda4143712bf], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf.1716dda415233208], Reason = [Created], Message = [Created container filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf.1716dda418a822d0], Reason = [Started], Message = [Started container filler-pod-3e1a2da9-08b3-4108-86ac-3e4b849877cf]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1716dda463caf730], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.]
STEP: removing the label node off the node general-2-giltle
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node general-2-xtetrn
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:46:51.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8131" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":356,"completed":83,"skipped":1360,"failed":0}
S
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:51.530: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Sep 21 11:46:51.566: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Sep 21 11:46:51.569: INFO: starting watch
STEP: patching
STEP: updating
Sep 21 11:46:51.585: INFO: waiting for watch events with expected annotations
Sep 21 11:46:51.585: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Sep 21 11:46:51.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9589" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":356,"completed":84,"skipped":1361,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:51.632: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Sep 21 11:46:51.675: INFO: The status of Pod labelsupdate7f389077-2795-406d-967b-815b81751f47 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:46:53.679: INFO: The status of Pod labelsupdate7f389077-2795-406d-967b-815b81751f47 is Running (Ready = true)
Sep 21 11:46:54.199: INFO: Successfully updated pod "labelsupdate7f389077-2795-406d-967b-815b81751f47"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 11:46:58.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4780" for this suite.

• [SLOW TEST:6.599 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":85,"skipped":1379,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:46:58.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-8475
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 11:46:58.261: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 21 11:46:58.297: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:47:00.313: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:02.310: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:04.304: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:06.303: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:08.302: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:10.307: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:12.308: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:14.305: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:16.303: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:18.303: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 11:47:20.305: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 21 11:47:20.309: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 21 11:47:22.332: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Sep 21 11:47:22.332: INFO: Breadth first check of 10.129.210.91 on host 10.128.0.2...
Sep 21 11:47:22.334: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.129.53.219:9080/dial?request=hostname&protocol=http&host=10.129.210.91&port=8083&tries=1'] Namespace:pod-network-test-8475 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 11:47:22.334: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:47:22.335: INFO: ExecWithOptions: Clientset creation
Sep 21 11:47:22.335: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-8475/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.129.53.219%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.129.210.91%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Sep 21 11:47:22.420: INFO: Waiting for responses: map[]
Sep 21 11:47:22.420: INFO: reached 10.129.210.91 after 0/1 tries
Sep 21 11:47:22.420: INFO: Breadth first check of 10.129.53.214 on host 10.128.0.3...
Sep 21 11:47:22.422: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.129.53.219:9080/dial?request=hostname&protocol=http&host=10.129.53.214&port=8083&tries=1'] Namespace:pod-network-test-8475 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 11:47:22.422: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 11:47:22.423: INFO: ExecWithOptions: Clientset creation
Sep 21 11:47:22.424: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-8475/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.129.53.219%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.129.53.214%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Sep 21 11:47:22.510: INFO: Waiting for responses: map[]
Sep 21 11:47:22.510: INFO: reached 10.129.53.214 after 0/1 tries
Sep 21 11:47:22.510: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Sep 21 11:47:22.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8475" for this suite.

• [SLOW TEST:24.279 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":356,"completed":86,"skipped":1407,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:22.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-64d969e9-9bcc-4668-8b06-95b7a695b1c7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 11:47:24.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-217" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":87,"skipped":1477,"failed":0}
S
------------------------------
[sig-node] Containers 
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:24.580: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override command
Sep 21 11:47:24.609: INFO: Waiting up to 5m0s for pod "client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb" in namespace "containers-8530" to be "Succeeded or Failed"
Sep 21 11:47:24.611: INFO: Pod "client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.368862ms
Sep 21 11:47:26.617: INFO: Pod "client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008558872s
Sep 21 11:47:28.625: INFO: Pod "client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016292799s
STEP: Saw pod success
Sep 21 11:47:28.629: INFO: Pod "client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb" satisfied condition "Succeeded or Failed"
Sep 21 11:47:28.632: INFO: Trying to get logs from node general-2-xtetrn pod client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:47:28.649: INFO: Waiting for pod client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb to disappear
Sep 21 11:47:28.662: INFO: Pod client-containers-cb57726f-934f-45a2-8226-c8b12fa645bb no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Sep 21 11:47:28.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8530" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","total":356,"completed":88,"skipped":1478,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:28.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Sep 21 11:47:28.741: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:47:30.753: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Sep 21 11:47:30.764: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:47:32.788: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Sep 21 11:47:32.795: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 21 11:47:32.799: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 21 11:47:34.799: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 21 11:47:34.813: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 21 11:47:36.800: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 21 11:47:36.803: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Sep 21 11:47:36.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5612" for this suite.

• [SLOW TEST:8.151 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":356,"completed":89,"skipped":1503,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:36.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 21 11:47:36.876: INFO: Waiting up to 5m0s for pod "pod-035109c4-d082-44fa-94f2-acec92967c04" in namespace "emptydir-9077" to be "Succeeded or Failed"
Sep 21 11:47:36.886: INFO: Pod "pod-035109c4-d082-44fa-94f2-acec92967c04": Phase="Pending", Reason="", readiness=false. Elapsed: 9.854519ms
Sep 21 11:47:38.896: INFO: Pod "pod-035109c4-d082-44fa-94f2-acec92967c04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019746399s
Sep 21 11:47:40.906: INFO: Pod "pod-035109c4-d082-44fa-94f2-acec92967c04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02998203s
STEP: Saw pod success
Sep 21 11:47:40.906: INFO: Pod "pod-035109c4-d082-44fa-94f2-acec92967c04" satisfied condition "Succeeded or Failed"
Sep 21 11:47:40.909: INFO: Trying to get logs from node general-2-xtetrn pod pod-035109c4-d082-44fa-94f2-acec92967c04 container test-container: <nil>
STEP: delete the pod
Sep 21 11:47:40.921: INFO: Waiting for pod pod-035109c4-d082-44fa-94f2-acec92967c04 to disappear
Sep 21 11:47:40.924: INFO: Pod pod-035109c4-d082-44fa-94f2-acec92967c04 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 11:47:40.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9077" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":90,"skipped":1510,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:40.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 11:47:40.975: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54" in namespace "projected-8354" to be "Succeeded or Failed"
Sep 21 11:47:40.979: INFO: Pod "downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54": Phase="Pending", Reason="", readiness=false. Elapsed: 4.382539ms
Sep 21 11:47:42.984: INFO: Pod "downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008892589s
Sep 21 11:47:44.993: INFO: Pod "downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018149482s
STEP: Saw pod success
Sep 21 11:47:44.993: INFO: Pod "downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54" satisfied condition "Succeeded or Failed"
Sep 21 11:47:44.995: INFO: Trying to get logs from node general-2-xtetrn pod downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54 container client-container: <nil>
STEP: delete the pod
Sep 21 11:47:45.008: INFO: Waiting for pod downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54 to disappear
Sep 21 11:47:45.010: INFO: Pod downwardapi-volume-8d89ff94-a02b-4a2b-9ada-3b067498ce54 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 11:47:45.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8354" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":91,"skipped":1517,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:45.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Sep 21 11:47:45.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5464 create -f -'
Sep 21 11:47:46.025: INFO: stderr: ""
Sep 21 11:47:46.025: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Sep 21 11:47:47.034: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 11:47:47.034: INFO: Found 0 / 1
Sep 21 11:47:48.030: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 11:47:48.030: INFO: Found 1 / 1
Sep 21 11:47:48.030: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 21 11:47:48.036: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 11:47:48.036: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 21 11:47:48.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5464 patch pod agnhost-primary-2r52l -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 21 11:47:48.132: INFO: stderr: ""
Sep 21 11:47:48.132: INFO: stdout: "pod/agnhost-primary-2r52l patched\n"
STEP: checking annotations
Sep 21 11:47:48.136: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 11:47:48.136: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:47:48.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5464" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":356,"completed":92,"skipped":1521,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:48.142: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Sep 21 11:47:48.186: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Sep 21 11:47:48.190: INFO: starting watch
STEP: patching
STEP: updating
Sep 21 11:47:48.204: INFO: waiting for watch events with expected annotations
Sep 21 11:47:48.205: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:188
Sep 21 11:47:48.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-7696" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":356,"completed":93,"skipped":1533,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:48.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:47:48.626: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:47:51.652: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Sep 21 11:47:53.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=webhook-1435 attach --namespace=webhook-1435 to-be-attached-pod -i -c=container1'
Sep 21 11:47:53.808: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:47:53.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1435" for this suite.
STEP: Destroying namespace "webhook-1435-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:5.633 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":356,"completed":94,"skipped":1630,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:47:53.874: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Sep 21 11:47:53.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 create -f -'
Sep 21 11:47:54.219: INFO: stderr: ""
Sep 21 11:47:54.219: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 11:47:54.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 11:47:54.278: INFO: stderr: ""
Sep 21 11:47:54.278: INFO: stdout: "update-demo-nautilus-lj6ls update-demo-nautilus-wqmqt "
Sep 21 11:47:54.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods update-demo-nautilus-lj6ls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 11:47:54.325: INFO: stderr: ""
Sep 21 11:47:54.325: INFO: stdout: ""
Sep 21 11:47:54.326: INFO: update-demo-nautilus-lj6ls is created but not running
Sep 21 11:47:59.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 11:47:59.427: INFO: stderr: ""
Sep 21 11:47:59.427: INFO: stdout: "update-demo-nautilus-lj6ls update-demo-nautilus-wqmqt "
Sep 21 11:47:59.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods update-demo-nautilus-lj6ls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 11:47:59.519: INFO: stderr: ""
Sep 21 11:47:59.519: INFO: stdout: "true"
Sep 21 11:47:59.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods update-demo-nautilus-lj6ls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 11:47:59.605: INFO: stderr: ""
Sep 21 11:47:59.605: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 11:47:59.605: INFO: validating pod update-demo-nautilus-lj6ls
Sep 21 11:47:59.608: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 11:47:59.608: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 11:47:59.608: INFO: update-demo-nautilus-lj6ls is verified up and running
Sep 21 11:47:59.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods update-demo-nautilus-wqmqt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 11:47:59.684: INFO: stderr: ""
Sep 21 11:47:59.684: INFO: stdout: "true"
Sep 21 11:47:59.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods update-demo-nautilus-wqmqt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 11:47:59.756: INFO: stderr: ""
Sep 21 11:47:59.756: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 11:47:59.756: INFO: validating pod update-demo-nautilus-wqmqt
Sep 21 11:47:59.760: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 11:47:59.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 11:47:59.760: INFO: update-demo-nautilus-wqmqt is verified up and running
STEP: using delete to clean up resources
Sep 21 11:47:59.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 delete --grace-period=0 --force -f -'
Sep 21 11:48:02.112: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 11:48:02.112: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 21 11:48:02.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get rc,svc -l name=update-demo --no-headers'
Sep 21 11:48:02.243: INFO: stderr: "No resources found in kubectl-2699 namespace.\n"
Sep 21 11:48:02.243: INFO: stdout: ""
Sep 21 11:48:02.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2699 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 11:48:02.456: INFO: stderr: ""
Sep 21 11:48:02.467: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:48:02.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2699" for this suite.

• [SLOW TEST:8.640 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should create and stop a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":356,"completed":95,"skipped":1699,"failed":0}
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:02.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Sep 21 11:48:02.593: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:48:04.600: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Sep 21 11:48:04.610: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:48:06.615: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 21 11:48:06.623: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 21 11:48:06.627: INFO: Pod pod-with-poststart-http-hook still exists
Sep 21 11:48:08.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 21 11:48:08.635: INFO: Pod pod-with-poststart-http-hook still exists
Sep 21 11:48:10.627: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 21 11:48:10.639: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Sep 21 11:48:10.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2957" for this suite.

• [SLOW TEST:8.134 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":356,"completed":96,"skipped":1705,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:10.649: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Sep 21 11:48:13.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5115" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":356,"completed":97,"skipped":1708,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:13.320: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-981b23e1-6b40-4777-afcb-25f5a9cbd1ad
STEP: Creating a pod to test consume configMaps
Sep 21 11:48:13.376: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b" in namespace "projected-478" to be "Succeeded or Failed"
Sep 21 11:48:13.386: INFO: Pod "pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18515ms
Sep 21 11:48:15.397: INFO: Pod "pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021717939s
Sep 21 11:48:17.408: INFO: Pod "pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03220341s
STEP: Saw pod success
Sep 21 11:48:17.408: INFO: Pod "pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b" satisfied condition "Succeeded or Failed"
Sep 21 11:48:17.410: INFO: Trying to get logs from node general-2-xtetrn pod pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 11:48:17.422: INFO: Waiting for pod pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b to disappear
Sep 21 11:48:17.426: INFO: Pod pod-projected-configmaps-bda32827-5a97-4245-b2ef-1a8beaf12a7b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 11:48:17.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-478" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":98,"skipped":1713,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:17.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-cfc45304-ef3c-4d59-a9b3-20e51f590911
STEP: Creating a pod to test consume configMaps
Sep 21 11:48:17.463: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d" in namespace "configmap-6531" to be "Succeeded or Failed"
Sep 21 11:48:17.465: INFO: Pod "pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.295953ms
Sep 21 11:48:19.469: INFO: Pod "pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006465805s
Sep 21 11:48:21.480: INFO: Pod "pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017495391s
STEP: Saw pod success
Sep 21 11:48:21.480: INFO: Pod "pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d" satisfied condition "Succeeded or Failed"
Sep 21 11:48:21.483: INFO: Trying to get logs from node general-2-xtetrn pod pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:48:21.507: INFO: Waiting for pod pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d to disappear
Sep 21 11:48:21.510: INFO: Pod pod-configmaps-3a13ee3b-3999-4269-bdbf-cb6d5ac03b6d no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 11:48:21.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6531" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":99,"skipped":1715,"failed":0}
SSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:21.519: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override all
Sep 21 11:48:21.557: INFO: Waiting up to 5m0s for pod "client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7" in namespace "containers-7707" to be "Succeeded or Failed"
Sep 21 11:48:21.566: INFO: Pod "client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.661667ms
Sep 21 11:48:23.575: INFO: Pod "client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017356024s
Sep 21 11:48:25.586: INFO: Pod "client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028909011s
STEP: Saw pod success
Sep 21 11:48:25.587: INFO: Pod "client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7" satisfied condition "Succeeded or Failed"
Sep 21 11:48:25.589: INFO: Trying to get logs from node general-2-xtetrn pod client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:48:25.602: INFO: Waiting for pod client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7 to disappear
Sep 21 11:48:25.605: INFO: Pod client-containers-832625ed-9004-4761-91ab-5bbf36ff97f7 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Sep 21 11:48:25.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7707" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":356,"completed":100,"skipped":1719,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:25.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Sep 21 11:48:25.670: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:48:27.675: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 21 11:48:28.698: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Sep 21 11:48:28.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1586" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":356,"completed":101,"skipped":1755,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:28.765: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name projected-secret-test-e2eac222-8588-43f0-81bd-8e49efd6996c
STEP: Creating a pod to test consume secrets
Sep 21 11:48:28.791: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa" in namespace "projected-9967" to be "Succeeded or Failed"
Sep 21 11:48:28.793: INFO: Pod "pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.254589ms
Sep 21 11:48:30.803: INFO: Pod "pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01143339s
Sep 21 11:48:32.815: INFO: Pod "pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023328682s
STEP: Saw pod success
Sep 21 11:48:32.815: INFO: Pod "pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa" satisfied condition "Succeeded or Failed"
Sep 21 11:48:32.817: INFO: Trying to get logs from node general-2-xtetrn pod pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 11:48:32.836: INFO: Waiting for pod pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa to disappear
Sep 21 11:48:32.839: INFO: Pod pod-projected-secrets-92c1de50-2784-4f9c-b929-021de2e2faaa no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 11:48:32.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9967" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":102,"skipped":1759,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:32.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-0cf09b02-f262-41f2-b5f8-260ad8b33ff8
STEP: Creating a pod to test consume configMaps
Sep 21 11:48:32.884: INFO: Waiting up to 5m0s for pod "pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d" in namespace "configmap-225" to be "Succeeded or Failed"
Sep 21 11:48:32.888: INFO: Pod "pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441295ms
Sep 21 11:48:34.896: INFO: Pod "pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d": Phase="Running", Reason="", readiness=false. Elapsed: 2.011786816s
Sep 21 11:48:36.902: INFO: Pod "pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017488143s
STEP: Saw pod success
Sep 21 11:48:36.902: INFO: Pod "pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d" satisfied condition "Succeeded or Failed"
Sep 21 11:48:36.904: INFO: Trying to get logs from node general-2-xtetrn pod pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:48:36.916: INFO: Waiting for pod pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d to disappear
Sep 21 11:48:36.919: INFO: Pod pod-configmaps-19895c1f-69d8-4979-94b7-a07d0119541d no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 11:48:36.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-225" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":103,"skipped":1808,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:36.927: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:48:37.266: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:48:40.294: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:48:40.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5370" for this suite.
STEP: Destroying namespace "webhook-5370-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":356,"completed":104,"skipped":1809,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:40.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 11:48:40.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a" in namespace "downward-api-8556" to be "Succeeded or Failed"
Sep 21 11:48:40.510: INFO: Pod "downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.272992ms
Sep 21 11:48:42.521: INFO: Pod "downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015004533s
Sep 21 11:48:44.530: INFO: Pod "downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024677814s
STEP: Saw pod success
Sep 21 11:48:44.530: INFO: Pod "downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a" satisfied condition "Succeeded or Failed"
Sep 21 11:48:44.533: INFO: Trying to get logs from node general-2-xtetrn pod downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a container client-container: <nil>
STEP: delete the pod
Sep 21 11:48:44.544: INFO: Waiting for pod downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a to disappear
Sep 21 11:48:44.547: INFO: Pod downwardapi-volume-edcd6cc2-f33c-4754-8c24-d07e1c45ba6a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 11:48:44.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8556" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":105,"skipped":1824,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:48:44.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 11:49:44.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9593" for this suite.

• [SLOW TEST:60.035 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":356,"completed":106,"skipped":1845,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:49:44.591: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override arguments
Sep 21 11:49:44.624: INFO: Waiting up to 5m0s for pod "client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e" in namespace "containers-5804" to be "Succeeded or Failed"
Sep 21 11:49:44.632: INFO: Pod "client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.688123ms
Sep 21 11:49:46.638: INFO: Pod "client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013449593s
Sep 21 11:49:48.643: INFO: Pod "client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018920764s
STEP: Saw pod success
Sep 21 11:49:48.643: INFO: Pod "client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e" satisfied condition "Succeeded or Failed"
Sep 21 11:49:48.646: INFO: Trying to get logs from node general-2-xtetrn pod client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e container agnhost-container: <nil>
STEP: delete the pod
Sep 21 11:49:48.658: INFO: Waiting for pod client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e to disappear
Sep 21 11:49:48.661: INFO: Pod client-containers-cd1eceef-e200-4bf0-8ebf-46bc0be7120e no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Sep 21 11:49:48.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5804" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","total":356,"completed":107,"skipped":1876,"failed":0}
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:49:48.668: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-g7wh
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 11:49:48.712: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-g7wh" in namespace "subpath-831" to be "Succeeded or Failed"
Sep 21 11:49:48.716: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.515691ms
Sep 21 11:49:50.725: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 2.012732504s
Sep 21 11:49:52.738: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 4.025546051s
Sep 21 11:49:54.752: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 6.039302008s
Sep 21 11:49:56.758: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 8.045643012s
Sep 21 11:49:58.766: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 10.053352403s
Sep 21 11:50:00.775: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 12.062353652s
Sep 21 11:50:02.787: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 14.074144924s
Sep 21 11:50:04.801: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 16.088842197s
Sep 21 11:50:06.808: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 18.095700145s
Sep 21 11:50:08.816: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=true. Elapsed: 20.103061176s
Sep 21 11:50:10.828: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Running", Reason="", readiness=false. Elapsed: 22.115481813s
Sep 21 11:50:12.831: INFO: Pod "pod-subpath-test-configmap-g7wh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.118218484s
STEP: Saw pod success
Sep 21 11:50:12.831: INFO: Pod "pod-subpath-test-configmap-g7wh" satisfied condition "Succeeded or Failed"
Sep 21 11:50:12.832: INFO: Trying to get logs from node general-2-xtetrn pod pod-subpath-test-configmap-g7wh container test-container-subpath-configmap-g7wh: <nil>
STEP: delete the pod
Sep 21 11:50:12.848: INFO: Waiting for pod pod-subpath-test-configmap-g7wh to disappear
Sep 21 11:50:12.850: INFO: Pod pod-subpath-test-configmap-g7wh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-g7wh
Sep 21 11:50:12.850: INFO: Deleting pod "pod-subpath-test-configmap-g7wh" in namespace "subpath-831"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Sep 21 11:50:12.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-831" for this suite.

• [SLOW TEST:24.190 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","total":356,"completed":108,"skipped":1881,"failed":0}
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:12.860: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replication controller my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a
Sep 21 11:50:12.888: INFO: Pod name my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a: Found 0 pods out of 1
Sep 21 11:50:17.895: INFO: Pod name my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a: Found 1 pods out of 1
Sep 21 11:50:17.895: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a" are running
Sep 21 11:50:17.898: INFO: Pod "my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a-cckj4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 11:50:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 11:50:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 11:50:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 11:50:12 +0000 UTC Reason: Message:}])
Sep 21 11:50:17.898: INFO: Trying to dial the pod
Sep 21 11:50:22.906: INFO: Controller my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a: Got expected result from replica 1 [my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a-cckj4]: "my-hostname-basic-88b167a2-8cfe-4a28-8f17-5eedffb1004a-cckj4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Sep 21 11:50:22.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8946" for this suite.

• [SLOW TEST:10.056 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":109,"skipped":1881,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:22.917: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 11:50:29.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2296" for this suite.

• [SLOW TEST:7.068 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":356,"completed":110,"skipped":1905,"failed":0}
SS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:29.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:50:30.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: creating the pod
STEP: submitting the pod to kubernetes
Sep 21 11:50:30.033: INFO: The status of Pod pod-logs-websocket-401a620f-1f4d-41de-9754-1f48726a6b41 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:50:32.043: INFO: The status of Pod pod-logs-websocket-401a620f-1f4d-41de-9754-1f48726a6b41 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 11:50:32.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7321" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":356,"completed":111,"skipped":1907,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:32.070: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:188
Sep 21 11:50:32.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4648" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":356,"completed":112,"skipped":1915,"failed":0}
SS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:32.150: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Sep 21 11:50:32.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6315" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":113,"skipped":1917,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:32.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:50:32.273: INFO: The status of Pod pod-secrets-304178e7-b73b-408c-ae6d-82c0a3a7338e is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:50:34.282: INFO: The status of Pod pod-secrets-304178e7-b73b-408c-ae6d-82c0a3a7338e is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Sep 21 11:50:34.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-130" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":356,"completed":114,"skipped":1937,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:34.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Sep 21 11:50:37.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6263" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":356,"completed":115,"skipped":1959,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:37.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1574
[It] should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Sep 21 11:50:37.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-6913 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Sep 21 11:50:37.342: INFO: stderr: ""
Sep 21 11:50:37.342: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Sep 21 11:50:42.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-6913 get pod e2e-test-httpd-pod -o json'
Sep 21 11:50:42.467: INFO: stderr: ""
Sep 21 11:50:42.467: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"c53539658c23487ff9a2fe9bab512e740dff7cbe185af5b95f2da513ce410df4\",\n            \"cni.projectcalico.org/podIP\": \"10.129.53.251/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.129.53.251/32\"\n        },\n        \"creationTimestamp\": \"2022-09-21T11:50:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6913\",\n        \"resourceVersion\": \"11743\",\n        \"uid\": \"4a67334c-7840-4c31-b400-5adb85833589\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-zs872\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"general-2-xtetrn\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-zs872\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-09-21T11:50:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-09-21T11:50:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-09-21T11:50:38Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-09-21T11:50:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://76e523295453739c43652da251e3fe2af99a38f2cb842b642a6e86a6bb8c546a\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-09-21T11:50:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.128.0.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.129.53.251\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.129.53.251\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-09-21T11:50:37Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 21 11:50:42.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-6913 replace -f -'
Sep 21 11:50:42.718: INFO: stderr: ""
Sep 21 11:50:42.718: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1578
Sep 21 11:50:42.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-6913 delete pods e2e-test-httpd-pod'
Sep 21 11:50:44.089: INFO: stderr: ""
Sep 21 11:50:44.089: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:50:44.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6913" for this suite.

• [SLOW TEST:6.858 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1571
    should update a single-container pod's image  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":356,"completed":116,"skipped":1991,"failed":0}
SSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:50:44.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-bb383259-2d58-4b09-a11a-8b52c84fb173 in namespace container-probe-8146
Sep 21 11:50:46.151: INFO: Started pod busybox-bb383259-2d58-4b09-a11a-8b52c84fb173 in namespace container-probe-8146
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 11:50:46.154: INFO: Initial restart count of pod busybox-bb383259-2d58-4b09-a11a-8b52c84fb173 is 0
Sep 21 11:51:36.337: INFO: Restart count of pod container-probe-8146/busybox-bb383259-2d58-4b09-a11a-8b52c84fb173 is now 1 (50.183727951s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 11:51:36.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8146" for this suite.

• [SLOW TEST:52.251 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":117,"skipped":1997,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:51:36.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:51:36.926: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:51:39.947: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:51:40.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3796" for this suite.
STEP: Destroying namespace "webhook-3796-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":356,"completed":118,"skipped":2011,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:51:40.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-projected-all-test-volume-ebea3015-568b-4451-8ed4-eaf2c47ff4da
STEP: Creating secret with name secret-projected-all-test-volume-3f8115c7-09df-4adb-aee3-797b415e856e
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 21 11:51:40.135: INFO: Waiting up to 5m0s for pod "projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301" in namespace "projected-7951" to be "Succeeded or Failed"
Sep 21 11:51:40.137: INFO: Pod "projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301": Phase="Pending", Reason="", readiness=false. Elapsed: 1.880921ms
Sep 21 11:51:42.148: INFO: Pod "projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012187058s
Sep 21 11:51:44.158: INFO: Pod "projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021977437s
STEP: Saw pod success
Sep 21 11:51:44.158: INFO: Pod "projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301" satisfied condition "Succeeded or Failed"
Sep 21 11:51:44.160: INFO: Trying to get logs from node general-2-xtetrn pod projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 21 11:51:44.178: INFO: Waiting for pod projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301 to disappear
Sep 21 11:51:44.181: INFO: Pod projected-volume-e8292b48-3fd6-47ca-9c90-27ac6783c301 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:188
Sep 21 11:51:44.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7951" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":356,"completed":119,"skipped":2026,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:51:44.198: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-9233
STEP: creating service affinity-nodeport in namespace services-9233
STEP: creating replication controller affinity-nodeport in namespace services-9233
I0921 11:51:44.259661      18 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-9233, replica count: 3
I0921 11:51:47.310840      18 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 11:51:47.323: INFO: Creating new exec pod
Sep 21 11:51:50.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9233 exec execpod-affinitylx8bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Sep 21 11:51:50.503: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Sep 21 11:51:50.503: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:51:50.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9233 exec execpod-affinitylx8bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.105.249 80'
Sep 21 11:51:50.650: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.127.105.249 80\nConnection to 10.127.105.249 80 port [tcp/http] succeeded!\n"
Sep 21 11:51:50.650: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:51:50.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9233 exec execpod-affinitylx8bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.2 30364'
Sep 21 11:51:50.787: INFO: stderr: "+ nc -v -t -w 2 10.128.0.2 30364\n+ echo hostName\nConnection to 10.128.0.2 30364 port [tcp/*] succeeded!\n"
Sep 21 11:51:50.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:51:50.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9233 exec execpod-affinitylx8bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.3 30364'
Sep 21 11:51:50.906: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.0.3 30364\nConnection to 10.128.0.3 30364 port [tcp/*] succeeded!\n"
Sep 21 11:51:50.906: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 11:51:50.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-9233 exec execpod-affinitylx8bh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.2:30364/ ; done'
Sep 21 11:51:51.162: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30364/\n"
Sep 21 11:51:51.162: INFO: stdout: "\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r\naffinity-nodeport-qcp8r"
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Received response from host: affinity-nodeport-qcp8r
Sep 21 11:51:51.162: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-9233, will wait for the garbage collector to delete the pods
Sep 21 11:51:51.238: INFO: Deleting ReplicationController affinity-nodeport took: 8.297784ms
Sep 21 11:51:51.339: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.514415ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 11:51:53.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9233" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.178 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":120,"skipped":2047,"failed":0}
SSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:51:53.378: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Sep 21 11:57:01.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-760" for this suite.

• [SLOW TEST:308.067 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":356,"completed":121,"skipped":2054,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:01.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 11:57:29.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4068" for this suite.

• [SLOW TEST:28.131 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":356,"completed":122,"skipped":2082,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:29.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a collection of services
Sep 21 11:57:29.599: INFO: Creating e2e-svc-a-2fmjs
Sep 21 11:57:29.605: INFO: Creating e2e-svc-b-r97hb
Sep 21 11:57:29.612: INFO: Creating e2e-svc-c-kskdm
STEP: deleting service collection
Sep 21 11:57:29.636: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 11:57:29.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3878" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":356,"completed":123,"skipped":2091,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:29.646: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Sep 21 11:57:29.684: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Sep 21 11:57:29.687: INFO: starting watch
STEP: patching
STEP: updating
Sep 21 11:57:29.699: INFO: waiting for watch events with expected annotations
Sep 21 11:57:29.699: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Sep 21 11:57:29.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6343" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":356,"completed":124,"skipped":2108,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:29.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 11:57:29.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f" in namespace "downward-api-7154" to be "Succeeded or Failed"
Sep 21 11:57:29.735: INFO: Pod "downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.083599ms
Sep 21 11:57:31.748: INFO: Pod "downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013985529s
Sep 21 11:57:33.756: INFO: Pod "downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022243316s
STEP: Saw pod success
Sep 21 11:57:33.756: INFO: Pod "downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f" satisfied condition "Succeeded or Failed"
Sep 21 11:57:33.759: INFO: Trying to get logs from node general-2-xtetrn pod downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f container client-container: <nil>
STEP: delete the pod
Sep 21 11:57:33.786: INFO: Waiting for pod downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f to disappear
Sep 21 11:57:33.791: INFO: Pod downwardapi-volume-66c51f90-fc5a-4366-97a4-165e3e2c963f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 11:57:33.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7154" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":356,"completed":125,"skipped":2114,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:33.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Sep 21 11:57:33.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-9421 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Sep 21 11:57:33.923: INFO: stderr: ""
Sep 21 11:57:33.923: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Sep 21 11:57:33.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-9421 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Sep 21 11:57:34.225: INFO: stderr: ""
Sep 21 11:57:34.225: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Sep 21 11:57:34.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-9421 delete pods e2e-test-httpd-pod'
Sep 21 11:57:36.172: INFO: stderr: ""
Sep 21 11:57:36.172: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 11:57:36.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9421" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":356,"completed":126,"skipped":2123,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:36.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-df82fa94-77df-4f66-968c-1dd01dc1487f
STEP: Creating a pod to test consume secrets
Sep 21 11:57:36.215: INFO: Waiting up to 5m0s for pod "pod-secrets-389e261b-582a-498d-85e1-e984efc9959e" in namespace "secrets-4288" to be "Succeeded or Failed"
Sep 21 11:57:36.224: INFO: Pod "pod-secrets-389e261b-582a-498d-85e1-e984efc9959e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.159808ms
Sep 21 11:57:38.233: INFO: Pod "pod-secrets-389e261b-582a-498d-85e1-e984efc9959e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017794755s
Sep 21 11:57:40.241: INFO: Pod "pod-secrets-389e261b-582a-498d-85e1-e984efc9959e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02580062s
STEP: Saw pod success
Sep 21 11:57:40.241: INFO: Pod "pod-secrets-389e261b-582a-498d-85e1-e984efc9959e" satisfied condition "Succeeded or Failed"
Sep 21 11:57:40.244: INFO: Trying to get logs from node general-2-xtetrn pod pod-secrets-389e261b-582a-498d-85e1-e984efc9959e container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 11:57:40.258: INFO: Waiting for pod pod-secrets-389e261b-582a-498d-85e1-e984efc9959e to disappear
Sep 21 11:57:40.261: INFO: Pod pod-secrets-389e261b-582a-498d-85e1-e984efc9959e no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 11:57:40.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4288" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":127,"skipped":2135,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:40.267: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 11:57:40.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 11:57:40.313: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 11:57:41.324: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 11:57:41.325: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 21 11:57:41.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 11:57:41.336: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 11:57:42.346: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 11:57:42.346: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 11:57:43.349: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 11:57:43.349: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 11:57:44.346: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 11:57:44.346: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 11:57:45.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 11:57:45.347: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-142, will wait for the garbage collector to delete the pods
Sep 21 11:57:45.404: INFO: Deleting DaemonSet.extensions daemon-set took: 2.235653ms
Sep 21 11:57:45.505: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.225879ms
Sep 21 11:57:48.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 11:57:48.310: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Sep 21 11:57:48.313: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13182"},"items":null}

Sep 21 11:57:48.316: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13182"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 11:57:48.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-142" for this suite.

• [SLOW TEST:8.062 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":356,"completed":128,"skipped":2154,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:48.332: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 21 11:57:48.631: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 11:57:51.664: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:57:51.672: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 11:57:54.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2637" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:6.492 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":356,"completed":129,"skipped":2156,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:57:54.833: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:57:54.914: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:57:56.920: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:57:58.922: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:00.923: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:02.919: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:04.925: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:06.920: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:08.922: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:10.925: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:12.919: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:14.925: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = false)
Sep 21 11:58:16.919: INFO: The status of Pod test-webserver-aece4aaf-0d44-4991-bce1-6f158ae11f67 is Running (Ready = true)
Sep 21 11:58:16.921: INFO: Container started at 2022-09-21 11:57:55 +0000 UTC, pod became ready at 2022-09-21 11:58:15 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 11:58:16.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2820" for this suite.

• [SLOW TEST:22.095 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":356,"completed":130,"skipped":2192,"failed":0}
SSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:58:16.931: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Sep 21 11:58:16.965: INFO: The status of Pod pod-update-3e437647-ff47-4a8c-9480-273420db63a6 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 11:58:18.974: INFO: The status of Pod pod-update-3e437647-ff47-4a8c-9480-273420db63a6 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 21 11:58:19.502: INFO: Successfully updated pod "pod-update-3e437647-ff47-4a8c-9480-273420db63a6"
STEP: verifying the updated pod is in kubernetes
Sep 21 11:58:19.515: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 11:58:19.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5043" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":356,"completed":131,"skipped":2195,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:58:19.524: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 11:58:19.930: INFO: Checking APIGroup: apiregistration.k8s.io
Sep 21 11:58:19.932: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Sep 21 11:58:19.932: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Sep 21 11:58:19.932: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Sep 21 11:58:19.932: INFO: Checking APIGroup: apps
Sep 21 11:58:19.932: INFO: PreferredVersion.GroupVersion: apps/v1
Sep 21 11:58:19.932: INFO: Versions found [{apps/v1 v1}]
Sep 21 11:58:19.932: INFO: apps/v1 matches apps/v1
Sep 21 11:58:19.932: INFO: Checking APIGroup: events.k8s.io
Sep 21 11:58:19.933: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Sep 21 11:58:19.933: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Sep 21 11:58:19.933: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Sep 21 11:58:19.933: INFO: Checking APIGroup: authentication.k8s.io
Sep 21 11:58:19.934: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Sep 21 11:58:19.934: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Sep 21 11:58:19.934: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Sep 21 11:58:19.934: INFO: Checking APIGroup: authorization.k8s.io
Sep 21 11:58:19.935: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Sep 21 11:58:19.935: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Sep 21 11:58:19.935: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Sep 21 11:58:19.935: INFO: Checking APIGroup: autoscaling
Sep 21 11:58:19.936: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Sep 21 11:58:19.936: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Sep 21 11:58:19.936: INFO: autoscaling/v2 matches autoscaling/v2
Sep 21 11:58:19.936: INFO: Checking APIGroup: batch
Sep 21 11:58:19.937: INFO: PreferredVersion.GroupVersion: batch/v1
Sep 21 11:58:19.937: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Sep 21 11:58:19.937: INFO: batch/v1 matches batch/v1
Sep 21 11:58:19.937: INFO: Checking APIGroup: certificates.k8s.io
Sep 21 11:58:19.939: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Sep 21 11:58:19.939: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Sep 21 11:58:19.939: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Sep 21 11:58:19.939: INFO: Checking APIGroup: networking.k8s.io
Sep 21 11:58:19.940: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Sep 21 11:58:19.940: INFO: Versions found [{networking.k8s.io/v1 v1}]
Sep 21 11:58:19.940: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Sep 21 11:58:19.940: INFO: Checking APIGroup: policy
Sep 21 11:58:19.941: INFO: PreferredVersion.GroupVersion: policy/v1
Sep 21 11:58:19.941: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Sep 21 11:58:19.941: INFO: policy/v1 matches policy/v1
Sep 21 11:58:19.941: INFO: Checking APIGroup: rbac.authorization.k8s.io
Sep 21 11:58:19.942: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Sep 21 11:58:19.942: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Sep 21 11:58:19.942: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Sep 21 11:58:19.942: INFO: Checking APIGroup: storage.k8s.io
Sep 21 11:58:19.943: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Sep 21 11:58:19.943: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Sep 21 11:58:19.943: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Sep 21 11:58:19.943: INFO: Checking APIGroup: admissionregistration.k8s.io
Sep 21 11:58:19.944: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Sep 21 11:58:19.944: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Sep 21 11:58:19.944: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Sep 21 11:58:19.944: INFO: Checking APIGroup: apiextensions.k8s.io
Sep 21 11:58:19.945: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Sep 21 11:58:19.945: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Sep 21 11:58:19.945: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Sep 21 11:58:19.946: INFO: Checking APIGroup: scheduling.k8s.io
Sep 21 11:58:19.947: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Sep 21 11:58:19.947: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Sep 21 11:58:19.947: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Sep 21 11:58:19.947: INFO: Checking APIGroup: coordination.k8s.io
Sep 21 11:58:19.948: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Sep 21 11:58:19.948: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Sep 21 11:58:19.948: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Sep 21 11:58:19.948: INFO: Checking APIGroup: node.k8s.io
Sep 21 11:58:19.948: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Sep 21 11:58:19.948: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Sep 21 11:58:19.948: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Sep 21 11:58:19.948: INFO: Checking APIGroup: discovery.k8s.io
Sep 21 11:58:19.950: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Sep 21 11:58:19.950: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Sep 21 11:58:19.950: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Sep 21 11:58:19.950: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Sep 21 11:58:19.951: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Sep 21 11:58:19.951: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Sep 21 11:58:19.951: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Sep 21 11:58:19.951: INFO: Checking APIGroup: internal.apiserver.k8s.io
Sep 21 11:58:19.952: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
Sep 21 11:58:19.952: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
Sep 21 11:58:19.952: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
Sep 21 11:58:19.952: INFO: Checking APIGroup: crd.projectcalico.org
Sep 21 11:58:19.953: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Sep 21 11:58:19.953: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Sep 21 11:58:19.953: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:188
Sep 21 11:58:19.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-1357" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":356,"completed":132,"skipped":2201,"failed":0}
S
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:58:19.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Sep 21 11:58:22.048: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Sep 21 11:58:26.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8404" for this suite.

• [SLOW TEST:6.204 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":356,"completed":133,"skipped":2202,"failed":0}
S
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 11:58:26.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-b0ab2580-c975-43c0-a2e7-5f07a14690a3 in namespace container-probe-2935
Sep 21 11:58:30.220: INFO: Started pod liveness-b0ab2580-c975-43c0-a2e7-5f07a14690a3 in namespace container-probe-2935
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 11:58:30.222: INFO: Initial restart count of pod liveness-b0ab2580-c975-43c0-a2e7-5f07a14690a3 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 12:02:31.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2935" for this suite.

• [SLOW TEST:245.162 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":356,"completed":134,"skipped":2203,"failed":0}
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:02:31.330: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:02:31.382: INFO: The status of Pod busybox-readonly-fs83567620-2268-4ca6-9714-ffe78817c37b is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:02:33.390: INFO: The status of Pod busybox-readonly-fs83567620-2268-4ca6-9714-ffe78817c37b is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:02:35.391: INFO: The status of Pod busybox-readonly-fs83567620-2268-4ca6-9714-ffe78817c37b is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Sep 21 12:02:35.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7159" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":135,"skipped":2204,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:02:35.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 21 12:02:45.472: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
W0921 12:02:45.472609      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Sep 21 12:02:45.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6783" for this suite.

• [SLOW TEST:10.059 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":356,"completed":136,"skipped":2212,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:02:45.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Sep 21 12:02:48.028: INFO: Successfully updated pod "adopt-release-dq275"
STEP: Checking that the Job readopts the Pod
Sep 21 12:02:48.029: INFO: Waiting up to 15m0s for pod "adopt-release-dq275" in namespace "job-2001" to be "adopted"
Sep 21 12:02:48.032: INFO: Pod "adopt-release-dq275": Phase="Running", Reason="", readiness=true. Elapsed: 2.976523ms
Sep 21 12:02:50.043: INFO: Pod "adopt-release-dq275": Phase="Running", Reason="", readiness=true. Elapsed: 2.014366442s
Sep 21 12:02:50.043: INFO: Pod "adopt-release-dq275" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Sep 21 12:02:50.561: INFO: Successfully updated pod "adopt-release-dq275"
STEP: Checking that the Job releases the Pod
Sep 21 12:02:50.561: INFO: Waiting up to 15m0s for pod "adopt-release-dq275" in namespace "job-2001" to be "released"
Sep 21 12:02:50.563: INFO: Pod "adopt-release-dq275": Phase="Running", Reason="", readiness=true. Elapsed: 1.846804ms
Sep 21 12:02:52.575: INFO: Pod "adopt-release-dq275": Phase="Running", Reason="", readiness=true. Elapsed: 2.013717914s
Sep 21 12:02:52.575: INFO: Pod "adopt-release-dq275" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Sep 21 12:02:52.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2001" for this suite.

• [SLOW TEST:7.104 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":356,"completed":137,"skipped":2218,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:02:52.585: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:02:52.615: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0" in namespace "projected-634" to be "Succeeded or Failed"
Sep 21 12:02:52.624: INFO: Pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.216259ms
Sep 21 12:02:54.630: INFO: Pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015006683s
Sep 21 12:02:56.640: INFO: Pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024871485s
Sep 21 12:02:58.647: INFO: Pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032224827s
Sep 21 12:03:00.659: INFO: Pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044043665s
STEP: Saw pod success
Sep 21 12:03:00.660: INFO: Pod "downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0" satisfied condition "Succeeded or Failed"
Sep 21 12:03:00.662: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0 container client-container: <nil>
STEP: delete the pod
Sep 21 12:03:00.676: INFO: Waiting for pod downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0 to disappear
Sep 21 12:03:00.678: INFO: Pod downwardapi-volume-18c0380a-7f7c-468b-a666-8db51a22a9d0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 12:03:00.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-634" for this suite.

• [SLOW TEST:8.100 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":138,"skipped":2235,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:03:00.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Sep 21 12:03:00.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8259" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":139,"skipped":2252,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:03:00.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Sep 21 12:03:00.773: INFO: Waiting up to 5m0s for pod "downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6" in namespace "downward-api-3413" to be "Succeeded or Failed"
Sep 21 12:03:00.776: INFO: Pod "downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.332923ms
Sep 21 12:03:02.791: INFO: Pod "downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018710652s
Sep 21 12:03:04.794: INFO: Pod "downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021580576s
STEP: Saw pod success
Sep 21 12:03:04.794: INFO: Pod "downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6" satisfied condition "Succeeded or Failed"
Sep 21 12:03:04.796: INFO: Trying to get logs from node general-2-kofawi pod downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6 container dapi-container: <nil>
STEP: delete the pod
Sep 21 12:03:04.825: INFO: Waiting for pod downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6 to disappear
Sep 21 12:03:04.827: INFO: Pod downward-api-9221719b-5425-4d8d-bf95-feae7e05b1d6 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Sep 21 12:03:04.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3413" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":356,"completed":140,"skipped":2267,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:03:04.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-2267
Sep 21 12:03:04.855: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:03:06.863: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Sep 21 12:03:06.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Sep 21 12:03:07.073: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Sep 21 12:03:07.073: INFO: stdout: "iptables"
Sep 21 12:03:07.073: INFO: proxyMode: iptables
Sep 21 12:03:07.083: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Sep 21 12:03:07.086: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-2267
STEP: creating replication controller affinity-nodeport-timeout in namespace services-2267
I0921 12:03:07.109097      18 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-2267, replica count: 3
I0921 12:03:10.160983      18 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:03:10.169: INFO: Creating new exec pod
Sep 21 12:03:13.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Sep 21 12:03:13.383: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Sep 21 12:03:13.383: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:03:13.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.99.13 80'
Sep 21 12:03:13.546: INFO: stderr: "+ nc -v -t -w 2 10.127.99.13 80\n+ echo hostName\nConnection to 10.127.99.13 80 port [tcp/http] succeeded!\n"
Sep 21 12:03:13.546: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:03:13.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.2 31884'
Sep 21 12:03:13.708: INFO: stderr: "+ nc -v -t -w 2 10.128.0.2 31884\n+ echo hostName\nConnection to 10.128.0.2 31884 port [tcp/*] succeeded!\n"
Sep 21 12:03:13.708: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:03:13.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.3 31884'
Sep 21 12:03:13.877: INFO: stderr: "+ nc -v -t -w 2 10.128.0.3 31884\n+ echo hostName\nConnection to 10.128.0.3 31884 port [tcp/*] succeeded!\n"
Sep 21 12:03:13.877: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:03:13.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.2:31884/ ; done'
Sep 21 12:03:14.107: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n"
Sep 21 12:03:14.107: INFO: stdout: "\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt\naffinity-nodeport-timeout-s5tzt"
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.107: INFO: Received response from host: affinity-nodeport-timeout-s5tzt
Sep 21 12:03:14.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.128.0.2:31884/'
Sep 21 12:03:14.277: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n"
Sep 21 12:03:14.277: INFO: stdout: "affinity-nodeport-timeout-s5tzt"
Sep 21 12:03:34.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.128.0.2:31884/'
Sep 21 12:03:34.464: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n"
Sep 21 12:03:34.464: INFO: stdout: "affinity-nodeport-timeout-s5tzt"
Sep 21 12:03:54.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-2267 exec execpod-affinity445tg -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.128.0.2:31884/'
Sep 21 12:03:54.664: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.128.0.2:31884/\n"
Sep 21 12:03:54.664: INFO: stdout: "affinity-nodeport-timeout-67j9f"
Sep 21 12:03:54.664: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-2267, will wait for the garbage collector to delete the pods
Sep 21 12:03:54.734: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 4.553508ms
Sep 21 12:03:54.834: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.468349ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:03:57.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2267" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:52.322 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":141,"skipped":2271,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:03:57.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:03:57.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-6141
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:188
Sep 21 12:03:59.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1714" for this suite.
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Sep 21 12:03:59.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6141" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":356,"completed":142,"skipped":2300,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:03:59.276: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption is created
Sep 21 12:03:59.311: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:04:01.319: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:04:03.317: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:04:05.314: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Sep 21 12:04:06.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7185" for this suite.

• [SLOW TEST:7.062 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":356,"completed":143,"skipped":2313,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:04:06.338: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating all guestbook components
Sep 21 12:04:06.368: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Sep 21 12:04:06.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 create -f -'
Sep 21 12:04:07.212: INFO: stderr: ""
Sep 21 12:04:07.212: INFO: stdout: "service/agnhost-replica created\n"
Sep 21 12:04:07.212: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Sep 21 12:04:07.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 create -f -'
Sep 21 12:04:07.444: INFO: stderr: ""
Sep 21 12:04:07.444: INFO: stdout: "service/agnhost-primary created\n"
Sep 21 12:04:07.444: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 21 12:04:07.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 create -f -'
Sep 21 12:04:07.694: INFO: stderr: ""
Sep 21 12:04:07.694: INFO: stdout: "service/frontend created\n"
Sep 21 12:04:07.694: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Sep 21 12:04:07.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 create -f -'
Sep 21 12:04:07.945: INFO: stderr: ""
Sep 21 12:04:07.945: INFO: stdout: "deployment.apps/frontend created\n"
Sep 21 12:04:07.945: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 21 12:04:07.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 create -f -'
Sep 21 12:04:08.204: INFO: stderr: ""
Sep 21 12:04:08.204: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Sep 21 12:04:08.204: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 21 12:04:08.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 create -f -'
Sep 21 12:04:08.448: INFO: stderr: ""
Sep 21 12:04:08.448: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Sep 21 12:04:08.448: INFO: Waiting for all frontend pods to be Running.
Sep 21 12:04:13.499: INFO: Waiting for frontend to serve content.
Sep 21 12:04:13.510: INFO: Trying to add a new entry to the guestbook.
Sep 21 12:04:13.521: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 21 12:04:13.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 delete --grace-period=0 --force -f -'
Sep 21 12:04:13.645: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:04:13.645: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 12:04:13.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 delete --grace-period=0 --force -f -'
Sep 21 12:04:13.762: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:04:13.762: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 12:04:13.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 delete --grace-period=0 --force -f -'
Sep 21 12:04:13.817: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:04:13.817: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 12:04:13.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 delete --grace-period=0 --force -f -'
Sep 21 12:04:13.870: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:04:13.870: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 12:04:13.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 delete --grace-period=0 --force -f -'
Sep 21 12:04:13.951: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:04:13.951: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 12:04:13.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-1744 delete --grace-period=0 --force -f -'
Sep 21 12:04:14.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:04:14.025: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:04:14.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1744" for this suite.

• [SLOW TEST:7.702 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:340
    should create and stop a working application  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":356,"completed":144,"skipped":2318,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:04:14.040: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:04:14.471: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 12:04:16.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:04:18.490: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 4, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:04:21.507: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:04:21.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2506-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:04:24.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2107" for this suite.
STEP: Destroying namespace "webhook-2107-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:10.660 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":356,"completed":145,"skipped":2333,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:04:24.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Sep 21 12:04:24.756: INFO: namespace kubectl-3606
Sep 21 12:04:24.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-3606 create -f -'
Sep 21 12:04:25.696: INFO: stderr: ""
Sep 21 12:04:25.696: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Sep 21 12:04:26.702: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 12:04:26.702: INFO: Found 0 / 1
Sep 21 12:04:27.704: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 12:04:27.704: INFO: Found 1 / 1
Sep 21 12:04:27.704: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 21 12:04:27.706: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 21 12:04:27.706: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 21 12:04:27.706: INFO: wait on agnhost-primary startup in kubectl-3606 
Sep 21 12:04:27.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-3606 logs agnhost-primary-lrjcc agnhost-primary'
Sep 21 12:04:27.800: INFO: stderr: ""
Sep 21 12:04:27.800: INFO: stdout: "Paused\n"
STEP: exposing RC
Sep 21 12:04:27.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-3606 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Sep 21 12:04:27.905: INFO: stderr: ""
Sep 21 12:04:27.905: INFO: stdout: "service/rm2 exposed\n"
Sep 21 12:04:27.910: INFO: Service rm2 in namespace kubectl-3606 found.
STEP: exposing service
Sep 21 12:04:29.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-3606 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Sep 21 12:04:30.030: INFO: stderr: ""
Sep 21 12:04:30.030: INFO: stdout: "service/rm3 exposed\n"
Sep 21 12:04:30.036: INFO: Service rm3 in namespace kubectl-3606 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:04:32.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3606" for this suite.

• [SLOW TEST:7.350 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1249
    should create services for rc  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":356,"completed":146,"skipped":2362,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:04:32.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:04:32.104: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126" in namespace "downward-api-8623" to be "Succeeded or Failed"
Sep 21 12:04:32.107: INFO: Pod "downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126": Phase="Pending", Reason="", readiness=false. Elapsed: 2.640706ms
Sep 21 12:04:34.115: INFO: Pod "downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010628626s
Sep 21 12:04:36.123: INFO: Pod "downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018259449s
STEP: Saw pod success
Sep 21 12:04:36.123: INFO: Pod "downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126" satisfied condition "Succeeded or Failed"
Sep 21 12:04:36.126: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126 container client-container: <nil>
STEP: delete the pod
Sep 21 12:04:36.137: INFO: Waiting for pod downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126 to disappear
Sep 21 12:04:36.140: INFO: Pod downwardapi-volume-67eefc61-410b-4a0b-8619-02a7ee376126 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:04:36.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8623" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":147,"skipped":2406,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:04:36.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:04:36.182: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c" in namespace "projected-2619" to be "Succeeded or Failed"
Sep 21 12:04:36.191: INFO: Pod "downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.514414ms
Sep 21 12:04:38.195: INFO: Pod "downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012867601s
Sep 21 12:04:40.202: INFO: Pod "downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019677309s
STEP: Saw pod success
Sep 21 12:04:40.202: INFO: Pod "downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c" satisfied condition "Succeeded or Failed"
Sep 21 12:04:40.205: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c container client-container: <nil>
STEP: delete the pod
Sep 21 12:04:40.217: INFO: Waiting for pod downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c to disappear
Sep 21 12:04:40.220: INFO: Pod downwardapi-volume-f4dd25e9-28b2-475e-88df-96fa3449863c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 12:04:40.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2619" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":148,"skipped":2425,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:04:40.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7141
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating stateful set ss in namespace statefulset-7141
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7141
Sep 21 12:04:40.268: INFO: Found 0 stateful pods, waiting for 1
Sep 21 12:04:50.274: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 21 12:04:50.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:04:50.453: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:04:50.453: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:04:50.453: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:04:50.459: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 21 12:05:00.465: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:05:00.465: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:05:00.483: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Sep 21 12:05:00.483: INFO: ss-0  general-2-kofawi  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:04:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:04:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:04:40 +0000 UTC  }]
Sep 21 12:05:00.483: INFO: 
Sep 21 12:05:00.483: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 21 12:05:01.490: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991832059s
Sep 21 12:05:02.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984944913s
Sep 21 12:05:03.510: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972033226s
Sep 21 12:05:04.518: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.964594304s
Sep 21 12:05:05.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.956908511s
Sep 21 12:05:06.534: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.948193768s
Sep 21 12:05:07.541: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.94132368s
Sep 21 12:05:08.548: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.933669364s
Sep 21 12:05:09.557: INFO: Verifying statefulset ss doesn't scale past 3 for another 926.19756ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7141
Sep 21 12:05:10.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:05:10.745: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:05:10.745: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:05:10.745: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:05:10.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:05:10.917: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 21 12:05:10.917: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:05:10.917: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:05:10.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:05:11.088: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 21 12:05:11.088: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:05:11.088: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:05:11.092: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 21 12:05:21.108: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:05:21.108: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:05:21.108: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 21 12:05:21.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:05:21.296: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:05:21.296: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:05:21.296: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:05:21.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:05:21.474: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:05:21.474: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:05:21.474: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:05:21.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-7141 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:05:21.662: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:05:21.662: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:05:21.662: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:05:21.662: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:05:21.669: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 21 12:05:31.685: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:05:31.685: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:05:31.685: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:05:31.693: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Sep 21 12:05:31.693: INFO: ss-0  general-2-kofawi  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:04:40 +0000 UTC  }]
Sep 21 12:05:31.693: INFO: ss-1  general-2-xtetrn  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:00 +0000 UTC  }]
Sep 21 12:05:31.693: INFO: ss-2  general-2-kofawi  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:05:00 +0000 UTC  }]
Sep 21 12:05:31.693: INFO: 
Sep 21 12:05:31.693: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 21 12:05:32.701: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.99745755s
Sep 21 12:05:33.707: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.989749617s
Sep 21 12:05:34.715: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.982693356s
Sep 21 12:05:35.722: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.975285106s
Sep 21 12:05:36.729: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.967487044s
Sep 21 12:05:37.735: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.961397264s
Sep 21 12:05:38.742: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.95514603s
Sep 21 12:05:39.750: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.948720066s
Sep 21 12:05:40.757: INFO: Verifying statefulset ss doesn't scale past 0 for another 940.61117ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7141
Sep 21 12:05:41.765: INFO: Scaling statefulset ss to 0
Sep 21 12:05:41.776: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:05:41.778: INFO: Deleting all statefulset in ns statefulset-7141
Sep 21 12:05:41.779: INFO: Scaling statefulset ss to 0
Sep 21 12:05:41.787: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:05:41.789: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:05:41.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7141" for this suite.

• [SLOW TEST:61.600 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":356,"completed":149,"skipped":2484,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:05:41.831: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5fcfe9af-4fdb-44fa-b102-525e9904fe32
STEP: Creating the pod
Sep 21 12:05:41.862: INFO: The status of Pod pod-projected-configmaps-de6ee550-d05d-493a-a3fa-62c7e6abb8c5 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:05:43.871: INFO: The status of Pod pod-projected-configmaps-de6ee550-d05d-493a-a3fa-62c7e6abb8c5 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-5fcfe9af-4fdb-44fa-b102-525e9904fe32
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:05:45.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7788" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":150,"skipped":2549,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:05:45.915: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1540
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Sep 21 12:05:45.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-4809 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Sep 21 12:05:46.038: INFO: stderr: ""
Sep 21 12:05:46.038: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1544
Sep 21 12:05:46.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-4809 delete pods e2e-test-httpd-pod'
Sep 21 12:05:48.402: INFO: stderr: ""
Sep 21 12:05:48.402: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:05:48.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4809" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":356,"completed":151,"skipped":2602,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:05:48.412: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:05:48.472: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f5b68d16-af87-4fd3-b4ac-89864df28069", Controller:(*bool)(0xc004949206), BlockOwnerDeletion:(*bool)(0xc004949207)}}
Sep 21 12:05:48.490: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"27ff3e87-9a99-4660-b4fe-5ee1fd4809b6", Controller:(*bool)(0xc0049494a6), BlockOwnerDeletion:(*bool)(0xc0049494a7)}}
Sep 21 12:05:48.495: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"32b78ca4-3d7a-4a33-9b28-470f97fc2d5b", Controller:(*bool)(0xc00494977e), BlockOwnerDeletion:(*bool)(0xc00494977f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Sep 21 12:05:53.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3928" for this suite.

• [SLOW TEST:5.105 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":356,"completed":152,"skipped":2607,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:05:53.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:05:53.551: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 21 12:05:53.559: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:05:53.559: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Sep 21 12:05:53.576: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:05:53.576: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:05:54.582: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:05:54.582: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 21 12:05:54.597: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:05:54.597: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Sep 21 12:05:55.606: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:05:55.606: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 21 12:05:55.625: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:05:55.625: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:05:56.634: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:05:56.634: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:05:57.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:05:57.631: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:05:58.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:05:58.631: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9682, will wait for the garbage collector to delete the pods
Sep 21 12:05:58.692: INFO: Deleting DaemonSet.extensions daemon-set took: 2.3671ms
Sep 21 12:05:58.793: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.854537ms
Sep 21 12:06:01.507: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:06:01.507: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Sep 21 12:06:01.510: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15678"},"items":null}

Sep 21 12:06:01.512: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15678"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:06:01.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9682" for this suite.

• [SLOW TEST:8.026 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":356,"completed":153,"skipped":2612,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:01.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Sep 21 12:06:01.580: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Sep 21 12:06:01.585: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 21 12:06:01.585: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Sep 21 12:06:01.595: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 21 12:06:01.595: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Sep 21 12:06:01.604: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Sep 21 12:06:01.604: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Sep 21 12:06:08.648: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:188
Sep 21 12:06:08.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-16" for this suite.

• [SLOW TEST:7.125 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":356,"completed":154,"skipped":2626,"failed":0}
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:08.672: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 21 12:06:08.710: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-41  dc99efaa-42f0-4886-8a24-52ac9b9c550b 15731 0 2022-09-21 12:06:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-09-21 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:06:08.711: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-41  dc99efaa-42f0-4886-8a24-52ac9b9c550b 15732 0 2022-09-21 12:06:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-09-21 12:06:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:06:08.711: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-41  dc99efaa-42f0-4886-8a24-52ac9b9c550b 15733 0 2022-09-21 12:06:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-09-21 12:06:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 21 12:06:18.745: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-41  dc99efaa-42f0-4886-8a24-52ac9b9c550b 15763 0 2022-09-21 12:06:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-09-21 12:06:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:06:18.746: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-41  dc99efaa-42f0-4886-8a24-52ac9b9c550b 15764 0 2022-09-21 12:06:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-09-21 12:06:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:06:18.746: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-41  dc99efaa-42f0-4886-8a24-52ac9b9c550b 15767 0 2022-09-21 12:06:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-09-21 12:06:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Sep 21 12:06:18.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-41" for this suite.

• [SLOW TEST:10.082 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":356,"completed":155,"skipped":2629,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:18.755: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap that has name configmap-test-emptyKey-96f62ac5-a2a4-49a2-b5a3-ed081b52bc1f
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:06:18.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6898" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":356,"completed":156,"skipped":2647,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:18.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:06:18.805: INFO: Creating ReplicaSet my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d
Sep 21 12:06:18.812: INFO: Pod name my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d: Found 0 pods out of 1
Sep 21 12:06:23.827: INFO: Pod name my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d: Found 1 pods out of 1
Sep 21 12:06:23.827: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d" is running
Sep 21 12:06:23.830: INFO: Pod "my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d-55jjk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 12:06:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 12:06:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 12:06:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-09-21 12:06:18 +0000 UTC Reason: Message:}])
Sep 21 12:06:23.830: INFO: Trying to dial the pod
Sep 21 12:06:28.843: INFO: Controller my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d: Got expected result from replica 1 [my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d-55jjk]: "my-hostname-basic-51bd3017-da4f-42c4-939b-c9b550fb6b6d-55jjk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Sep 21 12:06:28.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5737" for this suite.

• [SLOW TEST:10.060 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":157,"skipped":2653,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:28.851: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:06:28.889: INFO: Create a RollingUpdate DaemonSet
Sep 21 12:06:28.893: INFO: Check that daemon pods launch on every node of the cluster
Sep 21 12:06:28.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:06:28.899: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:06:29.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:06:29.910: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:06:30.909: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:06:30.909: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Sep 21 12:06:30.909: INFO: Update the DaemonSet to trigger a rollout
Sep 21 12:06:30.917: INFO: Updating DaemonSet daemon-set
Sep 21 12:06:33.940: INFO: Roll back the DaemonSet before rollout is complete
Sep 21 12:06:33.951: INFO: Updating DaemonSet daemon-set
Sep 21 12:06:33.951: INFO: Make sure DaemonSet rollback is complete
Sep 21 12:06:33.956: INFO: Wrong image for pod: daemon-set-nxhc7. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Sep 21 12:06:33.956: INFO: Pod daemon-set-nxhc7 is not available
Sep 21 12:06:36.970: INFO: Pod daemon-set-5w9l8 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9711, will wait for the garbage collector to delete the pods
Sep 21 12:06:37.052: INFO: Deleting DaemonSet.extensions daemon-set took: 8.88956ms
Sep 21 12:06:37.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.102189ms
Sep 21 12:06:38.759: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:06:38.759: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Sep 21 12:06:38.761: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15947"},"items":null}

Sep 21 12:06:38.764: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15947"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:06:38.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9711" for this suite.

• [SLOW TEST:9.931 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":356,"completed":158,"skipped":2702,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:38.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:06:54.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8963" for this suite.

• [SLOW TEST:16.166 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":356,"completed":159,"skipped":2715,"failed":0}
SSSSSSSS
------------------------------
[sig-architecture] Conformance Tests 
  should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:54.954: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename conformance-tests
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
STEP: Getting node addresses
Sep 21 12:06:54.973: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:188
Sep 21 12:06:54.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-8558" for this suite.
•{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","total":356,"completed":160,"skipped":2723,"failed":0}
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:54.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-1765/configmap-test-9f28be38-fca3-4852-9714-71359a4b723d
STEP: Creating a pod to test consume configMaps
Sep 21 12:06:55.014: INFO: Waiting up to 5m0s for pod "pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d" in namespace "configmap-1765" to be "Succeeded or Failed"
Sep 21 12:06:55.017: INFO: Pod "pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.936565ms
Sep 21 12:06:57.022: INFO: Pod "pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00853196s
Sep 21 12:06:59.031: INFO: Pod "pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017649529s
STEP: Saw pod success
Sep 21 12:06:59.031: INFO: Pod "pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d" satisfied condition "Succeeded or Failed"
Sep 21 12:06:59.034: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d container env-test: <nil>
STEP: delete the pod
Sep 21 12:06:59.054: INFO: Waiting for pod pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d to disappear
Sep 21 12:06:59.056: INFO: Pod pod-configmaps-f41454bf-d2f5-410d-b0de-360e93be5c0d no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:06:59.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1765" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":356,"completed":161,"skipped":2730,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:06:59.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:79
Sep 21 12:06:59.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the sample API server.
Sep 21 12:06:59.662: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Sep 21 12:07:01.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:07:03.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:07:05.723: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:07:07.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:07:09.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:07:12.058: INFO: Waited 324.575206ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Sep 21 12:07:12.131: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:69
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:188
Sep 21 12:07:12.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3573" for this suite.

• [SLOW TEST:13.631 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":356,"completed":162,"skipped":2759,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:12.704: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service multi-endpoint-test in namespace services-7071
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7071 to expose endpoints map[]
Sep 21 12:07:12.750: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Sep 21 12:07:13.760: INFO: successfully validated that service multi-endpoint-test in namespace services-7071 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-7071
Sep 21 12:07:13.771: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:07:15.778: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7071 to expose endpoints map[pod1:[100]]
Sep 21 12:07:15.789: INFO: successfully validated that service multi-endpoint-test in namespace services-7071 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-7071
Sep 21 12:07:15.803: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:07:17.808: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7071 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 21 12:07:17.821: INFO: successfully validated that service multi-endpoint-test in namespace services-7071 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Sep 21 12:07:17.821: INFO: Creating new exec pod
Sep 21 12:07:20.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7071 exec execpodw98qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Sep 21 12:07:20.991: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Sep 21 12:07:20.991: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:07:20.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7071 exec execpodw98qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.11.99 80'
Sep 21 12:07:21.160: INFO: stderr: "+ nc -v -t -w 2 10.127.11.99 80\n+ echo hostName\nConnection to 10.127.11.99 80 port [tcp/http] succeeded!\n"
Sep 21 12:07:21.160: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:07:21.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7071 exec execpodw98qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Sep 21 12:07:21.352: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Sep 21 12:07:21.352: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:07:21.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7071 exec execpodw98qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.11.99 81'
Sep 21 12:07:21.512: INFO: stderr: "+ nc -v -t -w 2 10.127.11.99 81\n+ echo hostName\nConnection to 10.127.11.99 81 port [tcp/*] succeeded!\n"
Sep 21 12:07:21.512: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-7071
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7071 to expose endpoints map[pod2:[101]]
Sep 21 12:07:21.556: INFO: successfully validated that service multi-endpoint-test in namespace services-7071 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-7071
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7071 to expose endpoints map[]
Sep 21 12:07:22.588: INFO: successfully validated that service multi-endpoint-test in namespace services-7071 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:07:22.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7071" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.916 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":356,"completed":163,"skipped":2814,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:22.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 12:07:30.711: INFO: DNS probes using dns-5181/dns-test-c5e9309b-260c-4aab-9c1d-0da1f309e7c9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 12:07:30.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5181" for this suite.

• [SLOW TEST:8.107 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":356,"completed":164,"skipped":2829,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:30.734: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:07:30.771: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f" in namespace "projected-4157" to be "Succeeded or Failed"
Sep 21 12:07:30.775: INFO: Pod "downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.327732ms
Sep 21 12:07:32.785: INFO: Pod "downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f": Phase="Running", Reason="", readiness=false. Elapsed: 2.014549169s
Sep 21 12:07:34.791: INFO: Pod "downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020271132s
STEP: Saw pod success
Sep 21 12:07:34.791: INFO: Pod "downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f" satisfied condition "Succeeded or Failed"
Sep 21 12:07:34.794: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f container client-container: <nil>
STEP: delete the pod
Sep 21 12:07:34.809: INFO: Waiting for pod downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f to disappear
Sep 21 12:07:34.811: INFO: Pod downwardapi-volume-77e503d6-b19a-40f5-8504-0524013af11f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 12:07:34.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4157" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":165,"skipped":2848,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:34.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8692
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8692
STEP: creating replication controller externalsvc in namespace services-8692
I0921 12:07:34.880539      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8692, replica count: 2
I0921 12:07:37.933188      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Sep 21 12:07:37.949: INFO: Creating new exec pod
Sep 21 12:07:39.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8692 exec execpod99hb4 -- /bin/sh -x -c nslookup clusterip-service.services-8692.svc.cluster.local'
Sep 21 12:07:40.186: INFO: stderr: "+ nslookup clusterip-service.services-8692.svc.cluster.local\n"
Sep 21 12:07:40.186: INFO: stdout: "Server:\t\t10.124.0.10\nAddress:\t10.124.0.10#53\n\nclusterip-service.services-8692.svc.cluster.local\tcanonical name = externalsvc.services-8692.svc.cluster.local.\nName:\texternalsvc.services-8692.svc.cluster.local\nAddress: 10.124.234.173\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8692, will wait for the garbage collector to delete the pods
Sep 21 12:07:40.246: INFO: Deleting ReplicationController externalsvc took: 6.287452ms
Sep 21 12:07:40.346: INFO: Terminating ReplicationController externalsvc pods took: 100.255273ms
Sep 21 12:07:42.166: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:07:42.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8692" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.370 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":356,"completed":166,"skipped":2857,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:42.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-bffa2dfb-b2fd-4164-b906-3fb4c6aa3aaa
STEP: Creating a pod to test consume secrets
Sep 21 12:07:42.224: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546" in namespace "projected-8101" to be "Succeeded or Failed"
Sep 21 12:07:42.227: INFO: Pod "pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546": Phase="Pending", Reason="", readiness=false. Elapsed: 2.865439ms
Sep 21 12:07:44.235: INFO: Pod "pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010978793s
Sep 21 12:07:46.246: INFO: Pod "pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022275905s
STEP: Saw pod success
Sep 21 12:07:46.246: INFO: Pod "pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546" satisfied condition "Succeeded or Failed"
Sep 21 12:07:46.249: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:07:46.267: INFO: Waiting for pod pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546 to disappear
Sep 21 12:07:46.270: INFO: Pod pod-projected-secrets-4af0c4b9-5648-45a5-a88d-f66802811546 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 12:07:46.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8101" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":167,"skipped":2859,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:46.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-9b72644e-7904-492f-be44-c87570990df4
STEP: Creating a pod to test consume configMaps
Sep 21 12:07:46.318: INFO: Waiting up to 5m0s for pod "pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e" in namespace "configmap-7964" to be "Succeeded or Failed"
Sep 21 12:07:46.326: INFO: Pod "pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.665116ms
Sep 21 12:07:48.333: INFO: Pod "pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014826221s
Sep 21 12:07:50.344: INFO: Pod "pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02585172s
STEP: Saw pod success
Sep 21 12:07:50.344: INFO: Pod "pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e" satisfied condition "Succeeded or Failed"
Sep 21 12:07:50.346: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:07:50.359: INFO: Waiting for pod pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e to disappear
Sep 21 12:07:50.362: INFO: Pod pod-configmaps-7de0d236-a9fc-49ad-ac6f-4c27d029968e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:07:50.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7964" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":168,"skipped":2879,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:50.369: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:07:50.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6690" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":356,"completed":169,"skipped":2880,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:50.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Sep 21 12:07:52.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3757" for this suite.
•{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":356,"completed":170,"skipped":2914,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:52.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating pod
Sep 21 12:07:52.512: INFO: The status of Pod pod-hostip-a2ca465a-b2ca-49a1-93ec-40e84df9a124 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:07:54.519: INFO: The status of Pod pod-hostip-a2ca465a-b2ca-49a1-93ec-40e84df9a124 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:07:56.523: INFO: The status of Pod pod-hostip-a2ca465a-b2ca-49a1-93ec-40e84df9a124 is Running (Ready = true)
Sep 21 12:07:56.528: INFO: Pod pod-hostip-a2ca465a-b2ca-49a1-93ec-40e84df9a124 has hostIP: 10.128.0.2
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 12:07:56.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6992" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":356,"completed":171,"skipped":2948,"failed":0}
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:56.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:07:56.569: INFO: Got root ca configmap in namespace "svcaccounts-4928"
Sep 21 12:07:56.572: INFO: Deleted root ca configmap in namespace "svcaccounts-4928"
STEP: waiting for a new root ca configmap created
Sep 21 12:07:57.077: INFO: Recreated root ca configmap in namespace "svcaccounts-4928"
Sep 21 12:07:57.081: INFO: Updated root ca configmap in namespace "svcaccounts-4928"
STEP: waiting for the root ca configmap reconciled
Sep 21 12:07:57.586: INFO: Reconciled root ca configmap in namespace "svcaccounts-4928"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Sep 21 12:07:57.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4928" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":356,"completed":172,"skipped":2957,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:07:57.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod test-webserver-e82c566f-3a6e-4209-9cba-dc5c1af932d9 in namespace container-probe-2070
Sep 21 12:07:59.643: INFO: Started pod test-webserver-e82c566f-3a6e-4209-9cba-dc5c1af932d9 in namespace container-probe-2070
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 12:07:59.646: INFO: Initial restart count of pod test-webserver-e82c566f-3a6e-4209-9cba-dc5c1af932d9 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 12:12:00.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2070" for this suite.

• [SLOW TEST:243.190 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":173,"skipped":2976,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:00.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pods
Sep 21 12:12:00.843: INFO: created test-pod-1
Sep 21 12:12:00.850: INFO: created test-pod-2
Sep 21 12:12:00.860: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
Sep 21 12:12:00.860: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5691' to be running and ready
Sep 21 12:12:00.873: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Sep 21 12:12:00.873: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Sep 21 12:12:00.873: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Sep 21 12:12:00.873: INFO: 0 / 3 pods in namespace 'pods-5691' are running and ready (0 seconds elapsed)
Sep 21 12:12:00.873: INFO: expected 0 pod replicas in namespace 'pods-5691', 0 are Running and Ready.
Sep 21 12:12:00.873: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
Sep 21 12:12:00.873: INFO: test-pod-1  general-2-kofawi  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:12:00 +0000 UTC  }]
Sep 21 12:12:00.873: INFO: test-pod-2  general-2-kofawi  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:12:00 +0000 UTC  }]
Sep 21 12:12:00.873: INFO: test-pod-3  general-2-kofawi  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:12:00 +0000 UTC  }]
Sep 21 12:12:00.873: INFO: 
Sep 21 12:12:02.882: INFO: 3 / 3 pods in namespace 'pods-5691' are running and ready (2 seconds elapsed)
Sep 21 12:12:02.882: INFO: expected 0 pod replicas in namespace 'pods-5691', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
Sep 21 12:12:02.900: INFO: Pod quantity 3 is different from expected quantity 0
Sep 21 12:12:03.908: INFO: Pod quantity 3 is different from expected quantity 0
Sep 21 12:12:04.907: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 12:12:05.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5691" for this suite.

• [SLOW TEST:5.121 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":356,"completed":174,"skipped":2985,"failed":0}
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:05.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:12:05.944: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99" in namespace "downward-api-4760" to be "Succeeded or Failed"
Sep 21 12:12:05.946: INFO: Pod "downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.223867ms
Sep 21 12:12:07.951: INFO: Pod "downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00687442s
Sep 21 12:12:09.960: INFO: Pod "downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015874224s
STEP: Saw pod success
Sep 21 12:12:09.960: INFO: Pod "downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99" satisfied condition "Succeeded or Failed"
Sep 21 12:12:09.963: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99 container client-container: <nil>
STEP: delete the pod
Sep 21 12:12:09.986: INFO: Waiting for pod downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99 to disappear
Sep 21 12:12:09.989: INFO: Pod downwardapi-volume-50c1d648-e15c-46c7-bd30-5f9098361a99 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:12:09.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4760" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":175,"skipped":2985,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:09.996: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9354.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9354.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9354.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9354.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9354.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 12:12:12.070: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.073: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.076: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.078: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.080: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.083: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.085: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.087: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9354.svc.cluster.local from pod dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415: the server could not find the requested resource (get pods dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415)
Sep 21 12:12:12.087: INFO: Lookups using dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9354.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9354.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9354.svc.cluster.local jessie_udp@dns-test-service-2.dns-9354.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9354.svc.cluster.local]

Sep 21 12:12:17.109: INFO: DNS probes using dns-9354/dns-test-02025d3c-b5e7-4dad-a6d9-67da1eecb415 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 12:12:17.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9354" for this suite.

• [SLOW TEST:7.193 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":356,"completed":176,"skipped":3042,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:17.190: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-e89cd1b2-ee44-48a1-906a-6d7b8c5ad0e0
STEP: Creating a pod to test consume configMaps
Sep 21 12:12:17.225: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7" in namespace "projected-5708" to be "Succeeded or Failed"
Sep 21 12:12:17.229: INFO: Pod "pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.897337ms
Sep 21 12:12:19.234: INFO: Pod "pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009419758s
Sep 21 12:12:21.239: INFO: Pod "pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014048134s
STEP: Saw pod success
Sep 21 12:12:21.239: INFO: Pod "pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7" satisfied condition "Succeeded or Failed"
Sep 21 12:12:21.242: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:12:21.256: INFO: Waiting for pod pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7 to disappear
Sep 21 12:12:21.260: INFO: Pod pod-projected-configmaps-c748742b-a8c3-45c9-98ce-6edd4c6200e7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:12:21.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5708" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":177,"skipped":3043,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:21.267: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:12:21.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6026" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":356,"completed":178,"skipped":3066,"failed":0}

------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:21.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-zb7rs in namespace proxy-2583
I0921 12:12:21.374609      18 runners.go:193] Created replication controller with name: proxy-service-zb7rs, namespace: proxy-2583, replica count: 1
I0921 12:12:22.426211      18 runners.go:193] proxy-service-zb7rs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 12:12:23.427255      18 runners.go:193] proxy-service-zb7rs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0921 12:12:24.427745      18 runners.go:193] proxy-service-zb7rs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:12:24.437: INFO: setup took 3.079404872s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 21 12:12:24.445: INFO: (0) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 7.711737ms)
Sep 21 12:12:24.445: INFO: (0) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.574214ms)
Sep 21 12:12:24.446: INFO: (0) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 8.055016ms)
Sep 21 12:12:24.446: INFO: (0) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 7.823338ms)
Sep 21 12:12:24.446: INFO: (0) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 8.573752ms)
Sep 21 12:12:24.446: INFO: (0) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 8.64438ms)
Sep 21 12:12:24.452: INFO: (0) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 14.69767ms)
Sep 21 12:12:24.457: INFO: (0) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 18.574594ms)
Sep 21 12:12:24.457: INFO: (0) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 19.476028ms)
Sep 21 12:12:24.457: INFO: (0) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 19.291973ms)
Sep 21 12:12:24.458: INFO: (0) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 20.232984ms)
Sep 21 12:12:24.458: INFO: (0) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 20.583346ms)
Sep 21 12:12:24.458: INFO: (0) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 19.864055ms)
Sep 21 12:12:24.665: INFO: (0) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 226.800149ms)
Sep 21 12:12:24.665: INFO: (0) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 227.416719ms)
Sep 21 12:12:24.669: INFO: (0) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 230.775148ms)
Sep 21 12:12:24.675: INFO: (1) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 5.78101ms)
Sep 21 12:12:24.676: INFO: (1) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 7.03042ms)
Sep 21 12:12:24.676: INFO: (1) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 7.271878ms)
Sep 21 12:12:24.677: INFO: (1) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 7.908387ms)
Sep 21 12:12:24.678: INFO: (1) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 8.361421ms)
Sep 21 12:12:24.678: INFO: (1) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 8.516538ms)
Sep 21 12:12:24.678: INFO: (1) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 8.535146ms)
Sep 21 12:12:24.678: INFO: (1) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 8.75007ms)
Sep 21 12:12:24.678: INFO: (1) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 8.669892ms)
Sep 21 12:12:24.678: INFO: (1) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 8.926749ms)
Sep 21 12:12:24.679: INFO: (1) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 9.221883ms)
Sep 21 12:12:24.679: INFO: (1) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 9.489743ms)
Sep 21 12:12:24.679: INFO: (1) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 9.602837ms)
Sep 21 12:12:24.680: INFO: (1) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 9.853442ms)
Sep 21 12:12:24.680: INFO: (1) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 9.950434ms)
Sep 21 12:12:24.680: INFO: (1) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 10.536152ms)
Sep 21 12:12:24.688: INFO: (2) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.909411ms)
Sep 21 12:12:24.688: INFO: (2) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.811898ms)
Sep 21 12:12:24.688: INFO: (2) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.881414ms)
Sep 21 12:12:24.689: INFO: (2) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 8.157017ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 8.940135ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 8.885979ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 9.072227ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 9.479312ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 9.237443ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 8.883093ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 8.963451ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 9.344796ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 8.819988ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 9.002629ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 9.083499ms)
Sep 21 12:12:24.690: INFO: (2) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 9.206683ms)
Sep 21 12:12:24.696: INFO: (3) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 4.746896ms)
Sep 21 12:12:24.696: INFO: (3) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 4.752958ms)
Sep 21 12:12:24.696: INFO: (3) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 5.226714ms)
Sep 21 12:12:24.696: INFO: (3) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 5.041728ms)
Sep 21 12:12:24.699: INFO: (3) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.869994ms)
Sep 21 12:12:24.700: INFO: (3) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 7.803609ms)
Sep 21 12:12:24.700: INFO: (3) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 8.489165ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 8.317075ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 8.361953ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 8.794188ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 8.721032ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 8.894666ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 9.792612ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 9.340969ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 9.139009ms)
Sep 21 12:12:24.701: INFO: (3) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 8.85684ms)
Sep 21 12:12:24.705: INFO: (4) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 3.478487ms)
Sep 21 12:12:24.706: INFO: (4) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.538013ms)
Sep 21 12:12:24.709: INFO: (4) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 6.855394ms)
Sep 21 12:12:24.709: INFO: (4) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.402256ms)
Sep 21 12:12:24.710: INFO: (4) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 8.355169ms)
Sep 21 12:12:24.711: INFO: (4) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 8.521469ms)
Sep 21 12:12:24.711: INFO: (4) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 9.560723ms)
Sep 21 12:12:24.711: INFO: (4) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 10.141131ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 10.098715ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 9.454973ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 9.758033ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 10.115319ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 10.943827ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 10.657021ms)
Sep 21 12:12:24.712: INFO: (4) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 10.39355ms)
Sep 21 12:12:24.713: INFO: (4) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 10.672089ms)
Sep 21 12:12:24.719: INFO: (5) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.101554ms)
Sep 21 12:12:24.719: INFO: (5) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 6.33263ms)
Sep 21 12:12:24.719: INFO: (5) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 6.446827ms)
Sep 21 12:12:24.719: INFO: (5) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.715658ms)
Sep 21 12:12:24.720: INFO: (5) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.006263ms)
Sep 21 12:12:24.720: INFO: (5) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 7.146369ms)
Sep 21 12:12:24.724: INFO: (5) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 11.129694ms)
Sep 21 12:12:24.724: INFO: (5) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 11.377225ms)
Sep 21 12:12:24.724: INFO: (5) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 11.525457ms)
Sep 21 12:12:24.725: INFO: (5) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 11.695653ms)
Sep 21 12:12:24.725: INFO: (5) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 11.818347ms)
Sep 21 12:12:24.725: INFO: (5) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 12.267926ms)
Sep 21 12:12:24.725: INFO: (5) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 11.995076ms)
Sep 21 12:12:24.725: INFO: (5) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 12.289899ms)
Sep 21 12:12:24.725: INFO: (5) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 12.263196ms)
Sep 21 12:12:24.726: INFO: (5) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 12.981627ms)
Sep 21 12:12:24.732: INFO: (6) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 6.33198ms)
Sep 21 12:12:24.733: INFO: (6) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 6.862208ms)
Sep 21 12:12:24.733: INFO: (6) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 6.83803ms)
Sep 21 12:12:24.733: INFO: (6) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 7.021072ms)
Sep 21 12:12:24.733: INFO: (6) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.244945ms)
Sep 21 12:12:24.733: INFO: (6) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 7.195588ms)
Sep 21 12:12:24.736: INFO: (6) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 10.1053ms)
Sep 21 12:12:24.736: INFO: (6) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 10.173233ms)
Sep 21 12:12:24.736: INFO: (6) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 10.450302ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 10.494058ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 10.483337ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 10.85877ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 11.111228ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 11.018367ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 11.479137ms)
Sep 21 12:12:24.737: INFO: (6) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 11.287046ms)
Sep 21 12:12:24.746: INFO: (7) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 8.306274ms)
Sep 21 12:12:24.747: INFO: (7) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 8.832792ms)
Sep 21 12:12:24.747: INFO: (7) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 9.079802ms)
Sep 21 12:12:24.747: INFO: (7) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 9.0088ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 9.567977ms)
Sep 21 12:12:24.747: INFO: (7) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 9.061486ms)
Sep 21 12:12:24.747: INFO: (7) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 9.34215ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 10.066453ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 10.063116ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 10.237972ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 10.094688ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 10.204105ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 10.420743ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 10.376766ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 10.403238ms)
Sep 21 12:12:24.748: INFO: (7) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 10.136781ms)
Sep 21 12:12:24.753: INFO: (8) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 2.320708ms)
Sep 21 12:12:24.756: INFO: (8) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.274369ms)
Sep 21 12:12:24.757: INFO: (8) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.575681ms)
Sep 21 12:12:24.757: INFO: (8) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.462577ms)
Sep 21 12:12:24.758: INFO: (8) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.806568ms)
Sep 21 12:12:24.758: INFO: (8) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.66286ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 7.578813ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 8.336722ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 8.480347ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 8.33499ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 8.446048ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 8.943833ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 8.777695ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 8.49751ms)
Sep 21 12:12:24.759: INFO: (8) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 8.388305ms)
Sep 21 12:12:24.760: INFO: (8) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 8.734359ms)
Sep 21 12:12:24.764: INFO: (9) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 4.060629ms)
Sep 21 12:12:24.768: INFO: (9) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 7.831726ms)
Sep 21 12:12:24.768: INFO: (9) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 7.950789ms)
Sep 21 12:12:24.768: INFO: (9) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 8.158541ms)
Sep 21 12:12:24.769: INFO: (9) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 8.596156ms)
Sep 21 12:12:24.769: INFO: (9) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 8.572479ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 9.222966ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 9.013441ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 9.076646ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 9.324476ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 10.213213ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 9.661112ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 9.613748ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 9.430045ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 9.802963ms)
Sep 21 12:12:24.770: INFO: (9) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 9.815397ms)
Sep 21 12:12:24.774: INFO: (10) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 2.846838ms)
Sep 21 12:12:24.774: INFO: (10) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 3.26726ms)
Sep 21 12:12:24.776: INFO: (10) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 5.031207ms)
Sep 21 12:12:24.776: INFO: (10) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 5.054765ms)
Sep 21 12:12:24.777: INFO: (10) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 5.378564ms)
Sep 21 12:12:24.777: INFO: (10) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.630743ms)
Sep 21 12:12:24.777: INFO: (10) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 5.76116ms)
Sep 21 12:12:24.779: INFO: (10) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 6.462417ms)
Sep 21 12:12:24.779: INFO: (10) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 6.930663ms)
Sep 21 12:12:24.779: INFO: (10) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 7.089417ms)
Sep 21 12:12:24.779: INFO: (10) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 7.332959ms)
Sep 21 12:12:24.779: INFO: (10) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 7.601258ms)
Sep 21 12:12:24.779: INFO: (10) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 7.49529ms)
Sep 21 12:12:24.780: INFO: (10) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 7.440472ms)
Sep 21 12:12:24.780: INFO: (10) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 7.381525ms)
Sep 21 12:12:24.781: INFO: (10) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 7.961612ms)
Sep 21 12:12:24.784: INFO: (11) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 3.381476ms)
Sep 21 12:12:24.784: INFO: (11) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 3.222111ms)
Sep 21 12:12:24.786: INFO: (11) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.94674ms)
Sep 21 12:12:24.786: INFO: (11) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.885869ms)
Sep 21 12:12:24.787: INFO: (11) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.76105ms)
Sep 21 12:12:24.788: INFO: (11) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 6.462087ms)
Sep 21 12:12:24.788: INFO: (11) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 6.343352ms)
Sep 21 12:12:24.788: INFO: (11) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 6.407619ms)
Sep 21 12:12:24.788: INFO: (11) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 7.284382ms)
Sep 21 12:12:24.789: INFO: (11) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.956525ms)
Sep 21 12:12:24.789: INFO: (11) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 7.400482ms)
Sep 21 12:12:24.789: INFO: (11) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 8.081118ms)
Sep 21 12:12:24.789: INFO: (11) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 7.836203ms)
Sep 21 12:12:24.790: INFO: (11) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 7.725724ms)
Sep 21 12:12:24.790: INFO: (11) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 7.664735ms)
Sep 21 12:12:24.790: INFO: (11) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 7.797126ms)
Sep 21 12:12:24.794: INFO: (12) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 3.846033ms)
Sep 21 12:12:24.795: INFO: (12) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 5.324145ms)
Sep 21 12:12:24.796: INFO: (12) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 5.671783ms)
Sep 21 12:12:24.796: INFO: (12) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 5.673227ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 6.502946ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 7.09634ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.642925ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 6.530642ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.607694ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 6.46329ms)
Sep 21 12:12:24.797: INFO: (12) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 7.322528ms)
Sep 21 12:12:24.798: INFO: (12) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 7.010311ms)
Sep 21 12:12:24.798: INFO: (12) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.508599ms)
Sep 21 12:12:24.798: INFO: (12) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 6.596473ms)
Sep 21 12:12:24.798: INFO: (12) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 7.662129ms)
Sep 21 12:12:24.798: INFO: (12) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.926876ms)
Sep 21 12:12:24.803: INFO: (13) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 3.316978ms)
Sep 21 12:12:24.803: INFO: (13) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 3.74245ms)
Sep 21 12:12:24.803: INFO: (13) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 3.114788ms)
Sep 21 12:12:24.804: INFO: (13) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.650384ms)
Sep 21 12:12:24.804: INFO: (13) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.140014ms)
Sep 21 12:12:24.804: INFO: (13) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 4.094877ms)
Sep 21 12:12:24.804: INFO: (13) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 3.833229ms)
Sep 21 12:12:24.805: INFO: (13) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 4.758949ms)
Sep 21 12:12:24.805: INFO: (13) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 4.728549ms)
Sep 21 12:12:24.805: INFO: (13) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 5.645151ms)
Sep 21 12:12:24.805: INFO: (13) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 6.050223ms)
Sep 21 12:12:24.805: INFO: (13) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 5.285019ms)
Sep 21 12:12:24.806: INFO: (13) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 5.317313ms)
Sep 21 12:12:24.806: INFO: (13) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 5.77599ms)
Sep 21 12:12:24.806: INFO: (13) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 5.979112ms)
Sep 21 12:12:24.806: INFO: (13) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.288824ms)
Sep 21 12:12:24.809: INFO: (14) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 2.578026ms)
Sep 21 12:12:24.811: INFO: (14) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 5.440085ms)
Sep 21 12:12:24.811: INFO: (14) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 5.173379ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.476124ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 5.755331ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.830024ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 6.145772ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 6.320968ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 6.293554ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 6.740376ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.283072ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.859602ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.962225ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 6.706951ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 7.117212ms)
Sep 21 12:12:24.813: INFO: (14) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 7.534938ms)
Sep 21 12:12:24.818: INFO: (15) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 3.733431ms)
Sep 21 12:12:24.819: INFO: (15) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 4.088283ms)
Sep 21 12:12:24.819: INFO: (15) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 4.174343ms)
Sep 21 12:12:24.820: INFO: (15) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 5.130123ms)
Sep 21 12:12:24.820: INFO: (15) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.325391ms)
Sep 21 12:12:24.821: INFO: (15) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.728237ms)
Sep 21 12:12:24.821: INFO: (15) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 5.44749ms)
Sep 21 12:12:24.821: INFO: (15) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 6.109719ms)
Sep 21 12:12:24.821: INFO: (15) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 6.16001ms)
Sep 21 12:12:24.821: INFO: (15) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 6.953567ms)
Sep 21 12:12:24.822: INFO: (15) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 7.17207ms)
Sep 21 12:12:24.822: INFO: (15) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 6.517695ms)
Sep 21 12:12:24.822: INFO: (15) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 6.684246ms)
Sep 21 12:12:24.822: INFO: (15) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 6.242823ms)
Sep 21 12:12:24.822: INFO: (15) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 6.397288ms)
Sep 21 12:12:24.822: INFO: (15) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 6.700317ms)
Sep 21 12:12:24.826: INFO: (16) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 3.190919ms)
Sep 21 12:12:24.827: INFO: (16) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 4.679783ms)
Sep 21 12:12:24.828: INFO: (16) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 5.082319ms)
Sep 21 12:12:24.828: INFO: (16) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 5.207525ms)
Sep 21 12:12:24.828: INFO: (16) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.408203ms)
Sep 21 12:12:24.828: INFO: (16) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 5.392643ms)
Sep 21 12:12:24.829: INFO: (16) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 5.818663ms)
Sep 21 12:12:24.829: INFO: (16) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 6.103839ms)
Sep 21 12:12:24.829: INFO: (16) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 6.433659ms)
Sep 21 12:12:24.829: INFO: (16) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.710006ms)
Sep 21 12:12:24.829: INFO: (16) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.45864ms)
Sep 21 12:12:24.829: INFO: (16) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 6.721399ms)
Sep 21 12:12:24.830: INFO: (16) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 6.706529ms)
Sep 21 12:12:24.830: INFO: (16) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 7.420242ms)
Sep 21 12:12:24.830: INFO: (16) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.560529ms)
Sep 21 12:12:24.831: INFO: (16) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.580549ms)
Sep 21 12:12:24.834: INFO: (17) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 3.372939ms)
Sep 21 12:12:24.834: INFO: (17) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 3.175559ms)
Sep 21 12:12:24.834: INFO: (17) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 3.286327ms)
Sep 21 12:12:24.835: INFO: (17) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 4.106058ms)
Sep 21 12:12:24.836: INFO: (17) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 4.220225ms)
Sep 21 12:12:24.836: INFO: (17) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 3.953917ms)
Sep 21 12:12:24.836: INFO: (17) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 4.601097ms)
Sep 21 12:12:24.836: INFO: (17) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 4.978202ms)
Sep 21 12:12:24.836: INFO: (17) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 5.448493ms)
Sep 21 12:12:24.836: INFO: (17) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 4.701135ms)
Sep 21 12:12:24.838: INFO: (17) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 5.593148ms)
Sep 21 12:12:24.838: INFO: (17) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 5.481628ms)
Sep 21 12:12:24.839: INFO: (17) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 7.117883ms)
Sep 21 12:12:24.839: INFO: (17) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 7.210718ms)
Sep 21 12:12:24.840: INFO: (17) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 7.66772ms)
Sep 21 12:12:24.839: INFO: (17) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 7.251157ms)
Sep 21 12:12:24.843: INFO: (18) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 3.068799ms)
Sep 21 12:12:24.845: INFO: (18) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 4.947663ms)
Sep 21 12:12:24.846: INFO: (18) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 6.197122ms)
Sep 21 12:12:24.846: INFO: (18) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 5.932669ms)
Sep 21 12:12:24.846: INFO: (18) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.974712ms)
Sep 21 12:12:24.846: INFO: (18) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 6.434712ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 6.397949ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 6.50451ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 6.47904ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 6.795886ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 6.71672ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 6.743533ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 6.957006ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 7.002084ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 7.083404ms)
Sep 21 12:12:24.847: INFO: (18) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 7.358789ms)
Sep 21 12:12:24.849: INFO: (19) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:462/proxy/: tls qux (200; 1.989213ms)
Sep 21 12:12:24.851: INFO: (19) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd/proxy/rewriteme">test</a> (200; 3.248714ms)
Sep 21 12:12:24.851: INFO: (19) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname1/proxy/: foo (200; 3.737048ms)
Sep 21 12:12:24.851: INFO: (19) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 4.083904ms)
Sep 21 12:12:24.852: INFO: (19) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">test<... (200; 4.284892ms)
Sep 21 12:12:24.852: INFO: (19) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:460/proxy/: tls baz (200; 4.064797ms)
Sep 21 12:12:24.852: INFO: (19) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 4.104716ms)
Sep 21 12:12:24.852: INFO: (19) /api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/https:proxy-service-zb7rs-f2xhd:443/proxy/tlsrewritem... (200; 4.066481ms)
Sep 21 12:12:24.852: INFO: (19) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:1080/proxy/rewriteme">... (200; 4.449697ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/services/proxy-service-zb7rs:portname2/proxy/: bar (200; 5.399757ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/pods/proxy-service-zb7rs-f2xhd:160/proxy/: foo (200; 5.321522ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname1/proxy/: tls baz (200; 5.379756ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/services/https:proxy-service-zb7rs:tlsportname2/proxy/: tls qux (200; 5.57347ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/pods/http:proxy-service-zb7rs-f2xhd:162/proxy/: bar (200; 5.656484ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname1/proxy/: foo (200; 5.919845ms)
Sep 21 12:12:24.853: INFO: (19) /api/v1/namespaces/proxy-2583/services/http:proxy-service-zb7rs:portname2/proxy/: bar (200; 6.060131ms)
STEP: deleting ReplicationController proxy-service-zb7rs in namespace proxy-2583, will wait for the garbage collector to delete the pods
Sep 21 12:12:24.912: INFO: Deleting ReplicationController proxy-service-zb7rs took: 4.831943ms
Sep 21 12:12:25.012: INFO: Terminating ReplicationController proxy-service-zb7rs pods took: 100.552458ms
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Sep 21 12:12:27.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2583" for this suite.

• [SLOW TEST:6.201 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":356,"completed":179,"skipped":3066,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:12:27.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Sep 21 12:12:27.574: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 12:13:27.595: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Sep 21 12:13:27.630: INFO: Created pod: pod0-0-sched-preemption-low-priority
Sep 21 12:13:27.639: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Sep 21 12:13:27.663: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Sep 21 12:13:27.689: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:13:39.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7717" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:72.235 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":356,"completed":180,"skipped":3084,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:13:39.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:13:39.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2558" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":356,"completed":181,"skipped":3097,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:13:39.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:13:39.861: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd" in namespace "downward-api-947" to be "Succeeded or Failed"
Sep 21 12:13:39.863: INFO: Pod "downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439311ms
Sep 21 12:13:41.875: INFO: Pod "downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd": Phase="Running", Reason="", readiness=false. Elapsed: 2.013698491s
Sep 21 12:13:43.890: INFO: Pod "downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02861435s
STEP: Saw pod success
Sep 21 12:13:43.890: INFO: Pod "downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd" satisfied condition "Succeeded or Failed"
Sep 21 12:13:43.895: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd container client-container: <nil>
STEP: delete the pod
Sep 21 12:13:43.914: INFO: Waiting for pod downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd to disappear
Sep 21 12:13:43.917: INFO: Pod downwardapi-volume-60d65381-aa58-4253-aff7-a9712090ecfd no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:13:43.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-947" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":182,"skipped":3123,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:13:43.927: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Sep 21 12:13:43.955: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 12:14:44.003: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:14:44.006: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:14:44.033: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Sep 21 12:14:44.036: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:188
Sep 21 12:14:44.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8374" for this suite.
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:14:44.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3807" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:60.160 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":356,"completed":183,"skipped":3124,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:14:44.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:14:44.112: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a" in namespace "projected-4279" to be "Succeeded or Failed"
Sep 21 12:14:44.123: INFO: Pod "downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.476186ms
Sep 21 12:14:46.133: INFO: Pod "downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020917595s
Sep 21 12:14:48.140: INFO: Pod "downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027051592s
STEP: Saw pod success
Sep 21 12:14:48.140: INFO: Pod "downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a" satisfied condition "Succeeded or Failed"
Sep 21 12:14:48.142: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a container client-container: <nil>
STEP: delete the pod
Sep 21 12:14:48.155: INFO: Waiting for pod downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a to disappear
Sep 21 12:14:48.157: INFO: Pod downwardapi-volume-88ab9462-f445-49fa-811d-b99c868c830a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 12:14:48.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4279" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":356,"completed":184,"skipped":3127,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:14:48.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-7663
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 12:14:48.180: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 21 12:14:48.211: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:14:50.221: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:14:52.220: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:14:54.220: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:14:56.216: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:14:58.218: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:15:00.223: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 21 12:15:00.228: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 21 12:15:02.264: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Sep 21 12:15:02.264: INFO: Going to poll 10.129.34.244 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Sep 21 12:15:02.268: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.129.34.244:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7663 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:15:02.268: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:15:02.269: INFO: ExecWithOptions: Clientset creation
Sep 21 12:15:02.269: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-7663/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.129.34.244%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Sep 21 12:15:02.365: INFO: Found all 1 expected endpoints: [netserver-0]
Sep 21 12:15:02.365: INFO: Going to poll 10.129.53.210 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Sep 21 12:15:02.370: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.129.53.210:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7663 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:15:02.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:15:02.371: INFO: ExecWithOptions: Clientset creation
Sep 21 12:15:02.372: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-7663/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.129.53.210%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Sep 21 12:15:02.463: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Sep 21 12:15:02.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7663" for this suite.

• [SLOW TEST:14.308 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":185,"skipped":3153,"failed":0}
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:15:02.475: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Sep 21 12:15:02.496: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 12:15:02.501: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 12:15:02.503: INFO: 
Logging pods the apiserver thinks is on node general-2-kofawi before test
Sep 21 12:15:02.508: INFO: calico-node-hghrr from kube-system started at 2022-09-21 11:58:34 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.508: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 12:15:02.508: INFO: kube-proxy-lck7k from kube-system started at 2022-09-21 11:58:34 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.508: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 12:15:02.508: INFO: host-test-container-pod from pod-network-test-7663 started at 2022-09-21 12:15:00 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.508: INFO: 	Container agnhost-container ready: true, restart count 0
Sep 21 12:15:02.509: INFO: netserver-0 from pod-network-test-7663 started at 2022-09-21 12:14:48 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.509: INFO: 	Container webserver ready: true, restart count 0
Sep 21 12:15:02.509: INFO: test-container-pod from pod-network-test-7663 started at 2022-09-21 12:15:00 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.509: INFO: 	Container webserver ready: true, restart count 0
Sep 21 12:15:02.509: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-6wqhs from sonobuoy started at 2022-09-21 11:58:34 +0000 UTC (2 container statuses recorded)
Sep 21 12:15:02.509: INFO: 	Container sonobuoy-worker ready: false, restart count 7
Sep 21 12:15:02.509: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 12:15:02.510: INFO: csi-symbiosis-node-4zrmh from symbiosis-system started at 2022-09-21 11:59:14 +0000 UTC (2 container statuses recorded)
Sep 21 12:15:02.510: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 12:15:02.510: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 21 12:15:02.510: INFO: 
Logging pods the apiserver thinks is on node general-2-xtetrn before test
Sep 21 12:15:02.515: INFO: calico-kube-controllers-56cdb7c587-8xmzh from kube-system started at 2022-09-21 11:55:01 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.516: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Sep 21 12:15:02.516: INFO: calico-node-f4g47 from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.516: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 12:15:02.516: INFO: calico-typha-6775694657-tkchp from kube-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.516: INFO: 	Container calico-typha ready: true, restart count 0
Sep 21 12:15:02.516: INFO: coredns-685b6584b-4lqkm from kube-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.516: INFO: 	Container coredns ready: true, restart count 0
Sep 21 12:15:02.516: INFO: coredns-685b6584b-m4p42 from kube-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.517: INFO: 	Container coredns ready: true, restart count 0
Sep 21 12:15:02.517: INFO: kube-proxy-687zc from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.517: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 12:15:02.517: INFO: netserver-1 from pod-network-test-7663 started at 2022-09-21 12:14:48 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.517: INFO: 	Container webserver ready: true, restart count 0
Sep 21 12:15:02.517: INFO: sonobuoy from sonobuoy started at 2022-09-21 11:23:09 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.517: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 12:15:02.518: INFO: sonobuoy-e2e-job-d15d7ff7630543da from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 12:15:02.518: INFO: 	Container e2e ready: true, restart count 0
Sep 21 12:15:02.518: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 12:15:02.518: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-xk2rh from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 12:15:02.518: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 12:15:02.518: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 12:15:02.518: INFO: csi-symbiosis-node-lkfrb from symbiosis-system started at 2022-09-21 11:45:27 +0000 UTC (2 container statuses recorded)
Sep 21 12:15:02.518: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 12:15:02.519: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 21 12:15:02.519: INFO: symbiosis-block-csi-controller-0 from symbiosis-system started at 2022-09-21 11:55:47 +0000 UTC (3 container statuses recorded)
Sep 21 12:15:02.519: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 21 12:15:02.519: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 21 12:15:02.519: INFO: 	Container symbiosis-csi-plugin ready: true, restart count 0
Sep 21 12:15:02.519: INFO: symbiosis-cloud-controller-manager-67cd6bf5b9-76824 from symbiosis-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.519: INFO: 	Container symbiosis-cloud-controller-manager ready: true, restart count 0
Sep 21 12:15:02.519: INFO: symbiosis-k8s-controller-676ccb7ff7-7xg2s from symbiosis-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:15:02.520: INFO: 	Container symbiosis-k8s-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-682239cd-4d35-4406-8cb4-12e320ff2649 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-682239cd-4d35-4406-8cb4-12e320ff2649 off the node general-2-kofawi
STEP: verifying the node doesn't have the label kubernetes.io/e2e-682239cd-4d35-4406-8cb4-12e320ff2649
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:15:06.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4173" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":356,"completed":186,"skipped":3162,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:15:06.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:15:06.636: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Sep 21 12:15:08.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-410 --namespace=crd-publish-openapi-410 create -f -'
Sep 21 12:15:09.980: INFO: stderr: ""
Sep 21 12:15:09.980: INFO: stdout: "e2e-test-crd-publish-openapi-5072-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 21 12:15:09.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-410 --namespace=crd-publish-openapi-410 delete e2e-test-crd-publish-openapi-5072-crds test-cr'
Sep 21 12:15:10.048: INFO: stderr: ""
Sep 21 12:15:10.048: INFO: stdout: "e2e-test-crd-publish-openapi-5072-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Sep 21 12:15:10.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-410 --namespace=crd-publish-openapi-410 apply -f -'
Sep 21 12:15:10.374: INFO: stderr: ""
Sep 21 12:15:10.374: INFO: stdout: "e2e-test-crd-publish-openapi-5072-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 21 12:15:10.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-410 --namespace=crd-publish-openapi-410 delete e2e-test-crd-publish-openapi-5072-crds test-cr'
Sep 21 12:15:10.453: INFO: stderr: ""
Sep 21 12:15:10.453: INFO: stdout: "e2e-test-crd-publish-openapi-5072-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Sep 21 12:15:10.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=crd-publish-openapi-410 explain e2e-test-crd-publish-openapi-5072-crds'
Sep 21 12:15:10.768: INFO: stderr: ""
Sep 21 12:15:10.768: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5072-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:15:12.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-410" for this suite.

• [SLOW TEST:6.344 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":356,"completed":187,"skipped":3163,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:15:12.968: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:15:12.984: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6c5e2442-f95f-4bff-a808-07d0c69f19e0" in namespace "security-context-test-1633" to be "Succeeded or Failed"
Sep 21 12:15:12.987: INFO: Pod "busybox-readonly-false-6c5e2442-f95f-4bff-a808-07d0c69f19e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.835758ms
Sep 21 12:15:14.999: INFO: Pod "busybox-readonly-false-6c5e2442-f95f-4bff-a808-07d0c69f19e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01471243s
Sep 21 12:15:17.010: INFO: Pod "busybox-readonly-false-6c5e2442-f95f-4bff-a808-07d0c69f19e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026349523s
Sep 21 12:15:17.010: INFO: Pod "busybox-readonly-false-6c5e2442-f95f-4bff-a808-07d0c69f19e0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Sep 21 12:15:17.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1633" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":356,"completed":188,"skipped":3240,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:15:17.022: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-084810b1-c21d-4e4f-aff6-baf9e6552939
STEP: Creating a pod to test consume secrets
Sep 21 12:15:17.075: INFO: Waiting up to 5m0s for pod "pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74" in namespace "secrets-5297" to be "Succeeded or Failed"
Sep 21 12:15:17.098: INFO: Pod "pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74": Phase="Pending", Reason="", readiness=false. Elapsed: 22.50227ms
Sep 21 12:15:20.263: INFO: Pod "pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74": Phase="Running", Reason="", readiness=false. Elapsed: 3.187416093s
Sep 21 12:15:22.267: INFO: Pod "pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.192235025s
STEP: Saw pod success
Sep 21 12:15:22.267: INFO: Pod "pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74" satisfied condition "Succeeded or Failed"
Sep 21 12:15:22.269: INFO: Trying to get logs from node general-2-kofawi pod pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:15:22.282: INFO: Waiting for pod pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74 to disappear
Sep 21 12:15:22.284: INFO: Pod pod-secrets-caa6e81e-51a1-489b-b8d2-d223cc319d74 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:15:22.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5297" for this suite.

• [SLOW TEST:5.279 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":189,"skipped":3263,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:15:22.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:15:22.605: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:15:25.642: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:15:25.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-250" for this suite.
STEP: Destroying namespace "webhook-250-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":356,"completed":190,"skipped":3277,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:15:25.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Sep 21 12:20:25.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4434" for this suite.

• [SLOW TEST:300.070 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":356,"completed":191,"skipped":3313,"failed":0}
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:25.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Sep 21 12:20:27.878: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7010 PodName:pod-sharedvolume-daa8b0d2-70ac-4b4d-b921-53fc22822dc5 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:20:27.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:20:27.879: INFO: ExecWithOptions: Clientset creation
Sep 21 12:20:27.879: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/emptydir-7010/pods/pod-sharedvolume-daa8b0d2-70ac-4b4d-b921-53fc22822dc5/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Sep 21 12:20:27.968: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:20:27.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7010" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":356,"completed":192,"skipped":3313,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:27.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service nodeport-test with type=NodePort in namespace services-8292
STEP: creating replication controller nodeport-test in namespace services-8292
I0921 12:20:28.029000      18 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8292, replica count: 2
Sep 21 12:20:31.080: INFO: Creating new exec pod
I0921 12:20:31.080413      18 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:20:34.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8292 exec execpods6vcm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Sep 21 12:20:34.277: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Sep 21 12:20:34.277: INFO: stdout: "nodeport-test-htl7g"
Sep 21 12:20:34.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8292 exec execpods6vcm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.148.9 80'
Sep 21 12:20:34.432: INFO: stderr: "+ nc -v -t -w 2 10.127.148.9 80\n+ echo hostName\nConnection to 10.127.148.9 80 port [tcp/http] succeeded!\n"
Sep 21 12:20:34.432: INFO: stdout: "nodeport-test-htl7g"
Sep 21 12:20:34.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8292 exec execpods6vcm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.2 31588'
Sep 21 12:20:34.621: INFO: stderr: "+ nc -v -t -w 2 10.128.0.2 31588\n+ echo hostName\nConnection to 10.128.0.2 31588 port [tcp/*] succeeded!\n"
Sep 21 12:20:34.621: INFO: stdout: "nodeport-test-htl7g"
Sep 21 12:20:34.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8292 exec execpods6vcm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.3 31588'
Sep 21 12:20:34.800: INFO: stderr: "+ nc -v -t -w 2 10.128.0.3 31588\n+ echo hostName\nConnection to 10.128.0.3 31588 port [tcp/*] succeeded!\n"
Sep 21 12:20:34.800: INFO: stdout: ""
Sep 21 12:20:35.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8292 exec execpods6vcm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.3 31588'
Sep 21 12:20:35.981: INFO: stderr: "+ nc -v -t -w 2 10.128.0.3 31588\n+ echo hostName\nConnection to 10.128.0.3 31588 port [tcp/*] succeeded!\n"
Sep 21 12:20:35.982: INFO: stdout: "nodeport-test-js977"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:20:35.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8292" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:8.012 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":356,"completed":193,"skipped":3341,"failed":0}
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:35.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Sep 21 12:20:36.019: INFO: Waiting up to 5m0s for pod "downward-api-a14629f3-45d8-46b4-875b-26d0a863194c" in namespace "downward-api-7663" to be "Succeeded or Failed"
Sep 21 12:20:36.021: INFO: Pod "downward-api-a14629f3-45d8-46b4-875b-26d0a863194c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.974631ms
Sep 21 12:20:38.027: INFO: Pod "downward-api-a14629f3-45d8-46b4-875b-26d0a863194c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007579384s
Sep 21 12:20:40.036: INFO: Pod "downward-api-a14629f3-45d8-46b4-875b-26d0a863194c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016684485s
STEP: Saw pod success
Sep 21 12:20:40.036: INFO: Pod "downward-api-a14629f3-45d8-46b4-875b-26d0a863194c" satisfied condition "Succeeded or Failed"
Sep 21 12:20:40.038: INFO: Trying to get logs from node general-2-kofawi pod downward-api-a14629f3-45d8-46b4-875b-26d0a863194c container dapi-container: <nil>
STEP: delete the pod
Sep 21 12:20:40.063: INFO: Waiting for pod downward-api-a14629f3-45d8-46b4-875b-26d0a863194c to disappear
Sep 21 12:20:40.065: INFO: Pod downward-api-a14629f3-45d8-46b4-875b-26d0a863194c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Sep 21 12:20:40.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7663" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":356,"completed":194,"skipped":3344,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:40.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-46cc9aa4-8752-47f4-9e3b-f950aba66455
STEP: Creating the pod
Sep 21 12:20:40.111: INFO: The status of Pod pod-configmaps-95537e4d-886f-4ea7-b971-b1c1fdb3a2de is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:20:42.124: INFO: The status of Pod pod-configmaps-95537e4d-886f-4ea7-b971-b1c1fdb3a2de is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-46cc9aa4-8752-47f4-9e3b-f950aba66455
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:20:44.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5334" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":195,"skipped":3344,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Sep 21 12:20:44.217: INFO: Waiting up to 5m0s for pod "security-context-d387de69-282b-48da-a4fc-bcab4573c266" in namespace "security-context-7331" to be "Succeeded or Failed"
Sep 21 12:20:44.219: INFO: Pod "security-context-d387de69-282b-48da-a4fc-bcab4573c266": Phase="Pending", Reason="", readiness=false. Elapsed: 2.287436ms
Sep 21 12:20:46.227: INFO: Pod "security-context-d387de69-282b-48da-a4fc-bcab4573c266": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009822439s
Sep 21 12:20:48.233: INFO: Pod "security-context-d387de69-282b-48da-a4fc-bcab4573c266": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016138908s
STEP: Saw pod success
Sep 21 12:20:48.233: INFO: Pod "security-context-d387de69-282b-48da-a4fc-bcab4573c266" satisfied condition "Succeeded or Failed"
Sep 21 12:20:48.236: INFO: Trying to get logs from node general-2-kofawi pod security-context-d387de69-282b-48da-a4fc-bcab4573c266 container test-container: <nil>
STEP: delete the pod
Sep 21 12:20:48.325: INFO: Waiting for pod security-context-d387de69-282b-48da-a4fc-bcab4573c266 to disappear
Sep 21 12:20:48.327: INFO: Pod security-context-d387de69-282b-48da-a4fc-bcab4573c266 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Sep 21 12:20:48.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7331" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":196,"skipped":3370,"failed":0}
SS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:48.337: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Sep 21 12:20:50.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2139" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","total":356,"completed":197,"skipped":3372,"failed":0}

------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:50.402: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Service
STEP: watching for the Service to be added
Sep 21 12:20:50.433: INFO: Found Service test-service-w7f57 in namespace services-6202 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Sep 21 12:20:50.433: INFO: Service test-service-w7f57 created
STEP: Getting /status
Sep 21 12:20:50.437: INFO: Service test-service-w7f57 has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Sep 21 12:20:50.446: INFO: observed Service test-service-w7f57 in namespace services-6202 with annotations: map[] & LoadBalancer: {[]}
Sep 21 12:20:50.446: INFO: Found Service test-service-w7f57 in namespace services-6202 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Sep 21 12:20:50.446: INFO: Service test-service-w7f57 has service status patched
STEP: updating the ServiceStatus
Sep 21 12:20:50.465: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Sep 21 12:20:50.470: INFO: Observed Service test-service-w7f57 in namespace services-6202 with annotations: map[] & Conditions: {[]}
Sep 21 12:20:50.470: INFO: Observed event: &Service{ObjectMeta:{test-service-w7f57  services-6202  24f655fe-9cac-4ba1-a780-cad0cc813cc8 18845 0 2022-09-21 12:20:50 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-09-21 12:20:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-09-21 12:20:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.125.84.76,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.125.84.76],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Sep 21 12:20:50.471: INFO: Found Service test-service-w7f57 in namespace services-6202 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Sep 21 12:20:50.471: INFO: Service test-service-w7f57 has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Sep 21 12:20:50.492: INFO: observed Service test-service-w7f57 in namespace services-6202 with labels: map[test-service-static:true]
Sep 21 12:20:50.492: INFO: observed Service test-service-w7f57 in namespace services-6202 with labels: map[test-service-static:true]
Sep 21 12:20:50.492: INFO: observed Service test-service-w7f57 in namespace services-6202 with labels: map[test-service-static:true]
Sep 21 12:20:50.493: INFO: Found Service test-service-w7f57 in namespace services-6202 with labels: map[test-service:patched test-service-static:true]
Sep 21 12:20:50.493: INFO: Service test-service-w7f57 patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Sep 21 12:20:50.504: INFO: Observed event: ADDED
Sep 21 12:20:50.504: INFO: Observed event: MODIFIED
Sep 21 12:20:50.504: INFO: Observed event: MODIFIED
Sep 21 12:20:50.504: INFO: Observed event: MODIFIED
Sep 21 12:20:50.504: INFO: Found Service test-service-w7f57 in namespace services-6202 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Sep 21 12:20:50.504: INFO: Service test-service-w7f57 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:20:50.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6202" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":356,"completed":198,"skipped":3372,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:20:50.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-projected-28c8
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 12:20:50.547: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-28c8" in namespace "subpath-6082" to be "Succeeded or Failed"
Sep 21 12:20:50.552: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.903874ms
Sep 21 12:20:52.564: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016412125s
Sep 21 12:20:54.571: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 4.023897226s
Sep 21 12:20:56.575: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 6.028178626s
Sep 21 12:20:58.580: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 8.033197477s
Sep 21 12:21:00.591: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 10.043559444s
Sep 21 12:21:02.601: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 12.053403124s
Sep 21 12:21:04.612: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 14.064609921s
Sep 21 12:21:06.623: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 16.075639624s
Sep 21 12:21:08.628: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 18.080928657s
Sep 21 12:21:10.638: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 20.090985945s
Sep 21 12:21:12.644: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Running", Reason="", readiness=true. Elapsed: 22.097063414s
Sep 21 12:21:14.656: INFO: Pod "pod-subpath-test-projected-28c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.10935715s
STEP: Saw pod success
Sep 21 12:21:14.657: INFO: Pod "pod-subpath-test-projected-28c8" satisfied condition "Succeeded or Failed"
Sep 21 12:21:14.662: INFO: Trying to get logs from node general-2-kofawi pod pod-subpath-test-projected-28c8 container test-container-subpath-projected-28c8: <nil>
STEP: delete the pod
Sep 21 12:21:14.691: INFO: Waiting for pod pod-subpath-test-projected-28c8 to disappear
Sep 21 12:21:14.694: INFO: Pod pod-subpath-test-projected-28c8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-28c8
Sep 21 12:21:14.695: INFO: Deleting pod "pod-subpath-test-projected-28c8" in namespace "subpath-6082"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Sep 21 12:21:14.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6082" for this suite.

• [SLOW TEST:24.192 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","total":356,"completed":199,"skipped":3389,"failed":0}
S
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:21:14.706: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's command
Sep 21 12:21:14.867: INFO: Waiting up to 5m0s for pod "var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f" in namespace "var-expansion-8143" to be "Succeeded or Failed"
Sep 21 12:21:14.875: INFO: Pod "var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.746591ms
Sep 21 12:21:16.887: INFO: Pod "var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f": Phase="Running", Reason="", readiness=false. Elapsed: 2.019474024s
Sep 21 12:21:18.893: INFO: Pod "var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025828513s
STEP: Saw pod success
Sep 21 12:21:18.893: INFO: Pod "var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f" satisfied condition "Succeeded or Failed"
Sep 21 12:21:18.895: INFO: Trying to get logs from node general-2-kofawi pod var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f container dapi-container: <nil>
STEP: delete the pod
Sep 21 12:21:18.912: INFO: Waiting for pod var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f to disappear
Sep 21 12:21:18.916: INFO: Pod var-expansion-ba17e981-42cc-4759-b4b2-c10d35a0420f no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 12:21:18.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8143" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":356,"completed":200,"skipped":3390,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:21:18.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 12:21:22.985: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Sep 21 12:21:22.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6372" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":201,"skipped":3435,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:21:23.006: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Sep 21 12:21:51.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6313" for this suite.

• [SLOW TEST:28.877 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":356,"completed":202,"skipped":3462,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:21:51.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-5a494186-ff4e-4e17-8622-f4d3591a45c6
STEP: Creating a pod to test consume configMaps
Sep 21 12:21:51.911: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278" in namespace "projected-2836" to be "Succeeded or Failed"
Sep 21 12:21:51.913: INFO: Pod "pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278": Phase="Pending", Reason="", readiness=false. Elapsed: 2.554573ms
Sep 21 12:21:53.921: INFO: Pod "pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010526605s
Sep 21 12:21:55.931: INFO: Pod "pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020004175s
STEP: Saw pod success
Sep 21 12:21:55.931: INFO: Pod "pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278" satisfied condition "Succeeded or Failed"
Sep 21 12:21:55.933: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:21:55.947: INFO: Waiting for pod pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278 to disappear
Sep 21 12:21:55.949: INFO: Pod pod-projected-configmaps-1292399a-d517-4f97-9596-c55336ff7278 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:21:55.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2836" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":203,"skipped":3484,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:21:55.963: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:21:56.000: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 12:21:56.014: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:21:56.014: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:21:57.155: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:21:57.155: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 12:21:58.023: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:21:58.023: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 21 12:21:58.054: INFO: Wrong image for pod: daemon-set-hdnd5. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Sep 21 12:21:58.054: INFO: Wrong image for pod: daemon-set-skxzc. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Sep 21 12:21:59.068: INFO: Wrong image for pod: daemon-set-hdnd5. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Sep 21 12:22:00.069: INFO: Pod daemon-set-4lfpm is not available
Sep 21 12:22:00.069: INFO: Wrong image for pod: daemon-set-hdnd5. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Sep 21 12:22:02.073: INFO: Pod daemon-set-8q9ml is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 21 12:22:02.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:22:02.082: INFO: Node general-2-xtetrn is running 0 daemon pod, expected 1
Sep 21 12:22:03.090: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:22:03.090: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-391, will wait for the garbage collector to delete the pods
Sep 21 12:22:03.160: INFO: Deleting DaemonSet.extensions daemon-set took: 5.554311ms
Sep 21 12:22:03.261: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.407387ms
Sep 21 12:22:06.071: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:22:06.071: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Sep 21 12:22:06.074: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19299"},"items":null}

Sep 21 12:22:06.077: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19299"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:22:06.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-391" for this suite.

• [SLOW TEST:10.128 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":356,"completed":204,"skipped":3503,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:22:06.092: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5137
[It] should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-5137
Sep 21 12:22:06.142: INFO: Found 0 stateful pods, waiting for 1
Sep 21 12:22:16.154: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:22:16.181: INFO: Deleting all statefulset in ns statefulset-5137
Sep 21 12:22:16.183: INFO: Scaling statefulset ss to 0
Sep 21 12:22:26.217: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:22:26.220: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:22:26.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5137" for this suite.

• [SLOW TEST:20.164 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":356,"completed":205,"skipped":3523,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:22:26.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 12:22:26.333: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:22:26.333: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:22:27.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:22:27.344: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:22:28.344: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:22:28.344: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status
Sep 21 12:22:28.352: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Sep 21 12:22:28.362: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Sep 21 12:22:28.364: INFO: Observed &DaemonSet event: ADDED
Sep 21 12:22:28.365: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.365: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.365: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.366: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.366: INFO: Found daemon set daemon-set in namespace daemonsets-4867 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Sep 21 12:22:28.366: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Sep 21 12:22:28.377: INFO: Observed &DaemonSet event: ADDED
Sep 21 12:22:28.378: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.378: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.378: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.378: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.378: INFO: Observed daemon set daemon-set in namespace daemonsets-4867 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Sep 21 12:22:28.379: INFO: Observed &DaemonSet event: MODIFIED
Sep 21 12:22:28.379: INFO: Found daemon set daemon-set in namespace daemonsets-4867 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Sep 21 12:22:28.379: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4867, will wait for the garbage collector to delete the pods
Sep 21 12:22:28.440: INFO: Deleting DaemonSet.extensions daemon-set took: 4.73699ms
Sep 21 12:22:28.540: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.447991ms
Sep 21 12:22:31.249: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:22:31.249: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Sep 21 12:22:31.251: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19508"},"items":null}

Sep 21 12:22:31.255: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19508"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:22:31.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4867" for this suite.

• [SLOW TEST:5.026 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":356,"completed":206,"skipped":3526,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:22:31.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 21 12:22:31.325: INFO: Waiting up to 5m0s for pod "pod-e64bb5a5-153c-449b-8eea-f000901d7880" in namespace "emptydir-1528" to be "Succeeded or Failed"
Sep 21 12:22:31.330: INFO: Pod "pod-e64bb5a5-153c-449b-8eea-f000901d7880": Phase="Pending", Reason="", readiness=false. Elapsed: 4.179021ms
Sep 21 12:22:33.335: INFO: Pod "pod-e64bb5a5-153c-449b-8eea-f000901d7880": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009992112s
Sep 21 12:22:35.344: INFO: Pod "pod-e64bb5a5-153c-449b-8eea-f000901d7880": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01830682s
STEP: Saw pod success
Sep 21 12:22:35.344: INFO: Pod "pod-e64bb5a5-153c-449b-8eea-f000901d7880" satisfied condition "Succeeded or Failed"
Sep 21 12:22:35.346: INFO: Trying to get logs from node general-2-kofawi pod pod-e64bb5a5-153c-449b-8eea-f000901d7880 container test-container: <nil>
STEP: delete the pod
Sep 21 12:22:35.360: INFO: Waiting for pod pod-e64bb5a5-153c-449b-8eea-f000901d7880 to disappear
Sep 21 12:22:35.362: INFO: Pod pod-e64bb5a5-153c-449b-8eea-f000901d7880 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:22:35.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1528" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":207,"skipped":3545,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:22:35.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Sep 21 12:22:35.407: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Sep 21 12:22:35.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9685" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":356,"completed":208,"skipped":3570,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:22:35.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8091
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Sep 21 12:22:35.471: INFO: Found 0 stateful pods, waiting for 3
Sep 21 12:22:45.479: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:22:45.479: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:22:45.479: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Sep 21 12:22:45.506: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 21 12:22:55.555: INFO: Updating stateful set ss2
Sep 21 12:22:55.562: INFO: Waiting for Pod statefulset-8091/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Sep 21 12:23:05.622: INFO: Found 2 stateful pods, waiting for 3
Sep 21 12:23:15.629: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:23:15.629: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:23:15.629: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 21 12:23:15.652: INFO: Updating stateful set ss2
Sep 21 12:23:15.675: INFO: Waiting for Pod statefulset-8091/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Sep 21 12:23:25.701: INFO: Updating stateful set ss2
Sep 21 12:23:25.714: INFO: Waiting for StatefulSet statefulset-8091/ss2 to complete update
Sep 21 12:23:25.714: INFO: Waiting for Pod statefulset-8091/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:23:35.725: INFO: Deleting all statefulset in ns statefulset-8091
Sep 21 12:23:35.727: INFO: Scaling statefulset ss2 to 0
Sep 21 12:23:45.747: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:23:45.749: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:23:45.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8091" for this suite.

• [SLOW TEST:70.356 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":356,"completed":209,"skipped":3610,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:23:45.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-2e44304e-1577-4ab0-9717-9640fca3ea66
STEP: Creating a pod to test consume configMaps
Sep 21 12:23:45.822: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5" in namespace "projected-5969" to be "Succeeded or Failed"
Sep 21 12:23:45.837: INFO: Pod "pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.044003ms
Sep 21 12:23:47.840: INFO: Pod "pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018151878s
Sep 21 12:23:49.847: INFO: Pod "pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025509538s
STEP: Saw pod success
Sep 21 12:23:49.847: INFO: Pod "pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5" satisfied condition "Succeeded or Failed"
Sep 21 12:23:49.850: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:23:49.865: INFO: Waiting for pod pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5 to disappear
Sep 21 12:23:49.872: INFO: Pod pod-projected-configmaps-3486f7a1-702a-42b2-9920-745d632f0ef5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:23:49.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5969" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":210,"skipped":3611,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:23:49.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:23:49.925: INFO: The status of Pod busybox-host-aliases3a73c856-9b74-445c-a02d-bac1da302fcf is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:23:51.937: INFO: The status of Pod busybox-host-aliases3a73c856-9b74-445c-a02d-bac1da302fcf is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Sep 21 12:23:51.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5971" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":211,"skipped":3619,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:23:51.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
Sep 21 12:23:52.307: INFO: created test-event-1
Sep 21 12:23:52.324: INFO: created test-event-2
Sep 21 12:23:52.328: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Sep 21 12:23:52.332: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Sep 21 12:23:52.346: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Sep 21 12:23:52.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4206" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":356,"completed":212,"skipped":3633,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:23:52.382: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Sep 21 12:23:52.418: INFO: The status of Pod annotationupdate461932fa-3b22-4943-b5a7-e5d8da47e349 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:23:54.429: INFO: The status of Pod annotationupdate461932fa-3b22-4943-b5a7-e5d8da47e349 is Running (Ready = true)
Sep 21 12:23:54.953: INFO: Successfully updated pod "annotationupdate461932fa-3b22-4943-b5a7-e5d8da47e349"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:23:58.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-431" for this suite.

• [SLOW TEST:6.602 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":213,"skipped":3655,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:23:58.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:23:59.012: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2" in namespace "downward-api-4366" to be "Succeeded or Failed"
Sep 21 12:23:59.015: INFO: Pod "downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723913ms
Sep 21 12:24:01.027: INFO: Pod "downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014913291s
Sep 21 12:24:03.033: INFO: Pod "downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020471863s
STEP: Saw pod success
Sep 21 12:24:03.033: INFO: Pod "downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2" satisfied condition "Succeeded or Failed"
Sep 21 12:24:03.036: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2 container client-container: <nil>
STEP: delete the pod
Sep 21 12:24:03.048: INFO: Waiting for pod downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2 to disappear
Sep 21 12:24:03.050: INFO: Pod downwardapi-volume-41dc578b-6649-4713-9dec-9d7f3a3c2db2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:24:03.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4366" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":214,"skipped":3660,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:24:03.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Sep 21 12:24:03.106: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Sep 21 12:24:03.128: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Sep 21 12:24:03.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-134" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":356,"completed":215,"skipped":3669,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:24:03.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Indexed job
STEP: Ensuring job reaches completions
STEP: Ensuring pods with index for job exist
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Sep 21 12:24:11.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1551" for this suite.

• [SLOW TEST:8.049 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","total":356,"completed":216,"skipped":3680,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:24:11.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Sep 21 12:24:11.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:24:24.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6551" for this suite.

• [SLOW TEST:13.402 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":356,"completed":217,"skipped":3727,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:24:24.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Sep 21 12:24:24.630: INFO: Waiting up to 5m0s for pod "security-context-a70723de-b5be-4711-a429-4daa7d5dfe47" in namespace "security-context-7198" to be "Succeeded or Failed"
Sep 21 12:24:24.634: INFO: Pod "security-context-a70723de-b5be-4711-a429-4daa7d5dfe47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251992ms
Sep 21 12:24:26.643: INFO: Pod "security-context-a70723de-b5be-4711-a429-4daa7d5dfe47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013425789s
Sep 21 12:24:28.648: INFO: Pod "security-context-a70723de-b5be-4711-a429-4daa7d5dfe47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018468282s
STEP: Saw pod success
Sep 21 12:24:28.648: INFO: Pod "security-context-a70723de-b5be-4711-a429-4daa7d5dfe47" satisfied condition "Succeeded or Failed"
Sep 21 12:24:28.651: INFO: Trying to get logs from node general-2-kofawi pod security-context-a70723de-b5be-4711-a429-4daa7d5dfe47 container test-container: <nil>
STEP: delete the pod
Sep 21 12:24:28.663: INFO: Waiting for pod security-context-a70723de-b5be-4711-a429-4daa7d5dfe47 to disappear
Sep 21 12:24:28.666: INFO: Pod security-context-a70723de-b5be-4711-a429-4daa7d5dfe47 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Sep 21 12:24:28.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7198" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":218,"skipped":3735,"failed":0}

------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:24:28.673: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 21 12:24:28.707: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 21 12:24:33.714: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Sep 21 12:24:34.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7829" for this suite.

• [SLOW TEST:6.074 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":356,"completed":219,"skipped":3735,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:24:34.750: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod with failed condition
STEP: updating the pod
Sep 21 12:26:35.295: INFO: Successfully updated pod "var-expansion-1e992063-493c-4490-b7d6-6f114ab9ed7c"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Sep 21 12:26:37.306: INFO: Deleting pod "var-expansion-1e992063-493c-4490-b7d6-6f114ab9ed7c" in namespace "var-expansion-1173"
Sep 21 12:26:37.310: INFO: Wait up to 5m0s for pod "var-expansion-1e992063-493c-4490-b7d6-6f114ab9ed7c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 12:27:09.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1173" for this suite.

• [SLOW TEST:154.576 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":356,"completed":220,"skipped":3766,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:09.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Sep 21 12:27:11.386: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Sep 21 12:27:13.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9160" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":356,"completed":221,"skipped":3803,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:13.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensure pods equal to paralellism count is attached to the job
STEP: patching /status
STEP: updating /status
STEP: get /status
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Sep 21 12:27:15.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7626" for this suite.
•{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","total":356,"completed":222,"skipped":3812,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:15.511: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-c28e35e5-5e1a-4048-8a55-db25456dae78
STEP: Creating a pod to test consume secrets
Sep 21 12:27:15.562: INFO: Waiting up to 5m0s for pod "pod-secrets-60fefff6-1970-41c9-abba-868e7788887a" in namespace "secrets-6870" to be "Succeeded or Failed"
Sep 21 12:27:15.565: INFO: Pod "pod-secrets-60fefff6-1970-41c9-abba-868e7788887a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.538978ms
Sep 21 12:27:17.574: INFO: Pod "pod-secrets-60fefff6-1970-41c9-abba-868e7788887a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011041198s
Sep 21 12:27:19.581: INFO: Pod "pod-secrets-60fefff6-1970-41c9-abba-868e7788887a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018360358s
STEP: Saw pod success
Sep 21 12:27:19.581: INFO: Pod "pod-secrets-60fefff6-1970-41c9-abba-868e7788887a" satisfied condition "Succeeded or Failed"
Sep 21 12:27:19.584: INFO: Trying to get logs from node general-2-kofawi pod pod-secrets-60fefff6-1970-41c9-abba-868e7788887a container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:27:19.610: INFO: Waiting for pod pod-secrets-60fefff6-1970-41c9-abba-868e7788887a to disappear
Sep 21 12:27:19.613: INFO: Pod pod-secrets-60fefff6-1970-41c9-abba-868e7788887a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:27:19.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6870" for this suite.
STEP: Destroying namespace "secret-namespace-1576" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":356,"completed":223,"skipped":3830,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:19.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-f637bb1b-f5e8-4344-adf5-5ebf050c44c9
STEP: Creating a pod to test consume secrets
Sep 21 12:27:19.658: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca" in namespace "projected-5582" to be "Succeeded or Failed"
Sep 21 12:27:19.661: INFO: Pod "pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.629424ms
Sep 21 12:27:21.671: INFO: Pod "pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012824249s
Sep 21 12:27:23.681: INFO: Pod "pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022754129s
STEP: Saw pod success
Sep 21 12:27:23.681: INFO: Pod "pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca" satisfied condition "Succeeded or Failed"
Sep 21 12:27:23.684: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:27:23.698: INFO: Waiting for pod pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca to disappear
Sep 21 12:27:23.700: INFO: Pod pod-projected-secrets-f6c723e5-803e-4df9-9cc7-8f7f6cf4b6ca no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 12:27:23.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5582" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":224,"skipped":3840,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:23.711: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-d04b798a-ffbc-44bf-b800-d32396804cad
STEP: Creating a pod to test consume secrets
Sep 21 12:27:23.739: INFO: Waiting up to 5m0s for pod "pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81" in namespace "secrets-9969" to be "Succeeded or Failed"
Sep 21 12:27:23.742: INFO: Pod "pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.504019ms
Sep 21 12:27:25.760: INFO: Pod "pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020809405s
Sep 21 12:27:27.767: INFO: Pod "pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027226189s
STEP: Saw pod success
Sep 21 12:27:27.767: INFO: Pod "pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81" satisfied condition "Succeeded or Failed"
Sep 21 12:27:27.769: INFO: Trying to get logs from node general-2-kofawi pod pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:27:27.782: INFO: Waiting for pod pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81 to disappear
Sep 21 12:27:27.784: INFO: Pod pod-secrets-a635e00e-5fc0-4dfa-a5b1-1b6ce219ad81 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:27:27.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9969" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":225,"skipped":3842,"failed":0}
SSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:27.798: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
STEP: mirroring a new custom Endpoint
Sep 21 12:27:27.837: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
Sep 21 12:27:29.854: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
Sep 21 12:27:31.873: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:188
Sep 21 12:27:33.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-847" for this suite.

• [SLOW TEST:6.088 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":356,"completed":226,"skipped":3849,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:27:33.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Sep 21 12:29:01.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1950" for this suite.

• [SLOW TEST:88.072 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":356,"completed":227,"skipped":3859,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:01.963: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating secret secrets-998/secret-test-4f615394-e73a-40fd-9140-9116d25b20dd
STEP: Creating a pod to test consume secrets
Sep 21 12:29:01.992: INFO: Waiting up to 5m0s for pod "pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d" in namespace "secrets-998" to be "Succeeded or Failed"
Sep 21 12:29:01.998: INFO: Pod "pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.11303ms
Sep 21 12:29:04.004: INFO: Pod "pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012486989s
Sep 21 12:29:06.014: INFO: Pod "pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022558518s
STEP: Saw pod success
Sep 21 12:29:06.015: INFO: Pod "pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d" satisfied condition "Succeeded or Failed"
Sep 21 12:29:06.017: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d container env-test: <nil>
STEP: delete the pod
Sep 21 12:29:06.040: INFO: Waiting for pod pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d to disappear
Sep 21 12:29:06.042: INFO: Pod pod-configmaps-338045ff-e7a4-488b-8a5e-7cd46b96d41d no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:29:06.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-998" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":228,"skipped":3876,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:06.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
STEP: create deployment with httpd image
Sep 21 12:29:06.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-4967 create -f -'
Sep 21 12:29:06.799: INFO: stderr: ""
Sep 21 12:29:06.799: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Sep 21 12:29:06.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-4967 diff -f -'
Sep 21 12:29:07.084: INFO: rc: 1
Sep 21 12:29:07.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-4967 delete -f -'
Sep 21 12:29:07.169: INFO: stderr: ""
Sep 21 12:29:07.169: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:29:07.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4967" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":356,"completed":229,"skipped":3883,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:07.181: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:29:07.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7680" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":356,"completed":230,"skipped":3919,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:07.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-a28db1f7-2e67-44ee-97b1-a80e14b9e452
STEP: Creating a pod to test consume configMaps
Sep 21 12:29:07.237: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3" in namespace "projected-6610" to be "Succeeded or Failed"
Sep 21 12:29:07.240: INFO: Pod "pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.770171ms
Sep 21 12:29:09.245: INFO: Pod "pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008209343s
Sep 21 12:29:11.254: INFO: Pod "pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017164315s
STEP: Saw pod success
Sep 21 12:29:11.255: INFO: Pod "pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3" satisfied condition "Succeeded or Failed"
Sep 21 12:29:11.257: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:29:11.268: INFO: Waiting for pod pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3 to disappear
Sep 21 12:29:11.270: INFO: Pod pod-projected-configmaps-d28ada86-f2e2-4b3a-a495-5d1c7b44ffc3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:29:11.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6610" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":231,"skipped":3933,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:11.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:29:11.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:29:12.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3651" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":356,"completed":232,"skipped":3936,"failed":0}
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:12.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Sep 21 12:29:12.368: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 12:29:12.372: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 12:29:12.374: INFO: 
Logging pods the apiserver thinks is on node general-2-kofawi before test
Sep 21 12:29:12.378: INFO: replace-27729388-t6ccb from cronjob-1950 started at 2022-09-21 12:28:00 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.378: INFO: 	Container c ready: true, restart count 0
Sep 21 12:29:12.378: INFO: replace-27729389-qgz79 from cronjob-1950 started at 2022-09-21 12:29:00 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.378: INFO: 	Container c ready: true, restart count 0
Sep 21 12:29:12.378: INFO: calico-node-hghrr from kube-system started at 2022-09-21 11:58:34 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.378: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 12:29:12.378: INFO: kube-proxy-lck7k from kube-system started at 2022-09-21 11:58:34 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.378: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 12:29:12.378: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-6wqhs from sonobuoy started at 2022-09-21 11:58:34 +0000 UTC (2 container statuses recorded)
Sep 21 12:29:12.378: INFO: 	Container sonobuoy-worker ready: false, restart count 10
Sep 21 12:29:12.379: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 12:29:12.379: INFO: csi-symbiosis-node-4zrmh from symbiosis-system started at 2022-09-21 11:59:14 +0000 UTC (2 container statuses recorded)
Sep 21 12:29:12.379: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 12:29:12.379: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 21 12:29:12.379: INFO: 
Logging pods the apiserver thinks is on node general-2-xtetrn before test
Sep 21 12:29:12.382: INFO: calico-kube-controllers-56cdb7c587-8xmzh from kube-system started at 2022-09-21 11:55:01 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.382: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Sep 21 12:29:12.382: INFO: calico-node-f4g47 from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.382: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 12:29:12.382: INFO: calico-typha-6775694657-tkchp from kube-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container calico-typha ready: true, restart count 0
Sep 21 12:29:12.383: INFO: coredns-685b6584b-4lqkm from kube-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container coredns ready: true, restart count 0
Sep 21 12:29:12.383: INFO: coredns-685b6584b-m4p42 from kube-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container coredns ready: true, restart count 0
Sep 21 12:29:12.383: INFO: kube-proxy-687zc from kube-system started at 2022-09-21 11:22:27 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 21 12:29:12.383: INFO: sonobuoy from sonobuoy started at 2022-09-21 11:23:09 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 12:29:12.383: INFO: sonobuoy-e2e-job-d15d7ff7630543da from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container e2e ready: true, restart count 0
Sep 21 12:29:12.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 12:29:12.383: INFO: sonobuoy-systemd-logs-daemon-set-f8844f7da65e4067-xk2rh from sonobuoy started at 2022-09-21 11:23:14 +0000 UTC (2 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 12:29:12.383: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 12:29:12.383: INFO: csi-symbiosis-node-lkfrb from symbiosis-system started at 2022-09-21 11:45:27 +0000 UTC (2 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container csi-symbiosis-plugin ready: true, restart count 0
Sep 21 12:29:12.383: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 21 12:29:12.383: INFO: symbiosis-block-csi-controller-0 from symbiosis-system started at 2022-09-21 11:55:47 +0000 UTC (3 container statuses recorded)
Sep 21 12:29:12.383: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 21 12:29:12.384: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 21 12:29:12.384: INFO: 	Container symbiosis-csi-plugin ready: true, restart count 0
Sep 21 12:29:12.384: INFO: symbiosis-cloud-controller-manager-67cd6bf5b9-76824 from symbiosis-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.384: INFO: 	Container symbiosis-cloud-controller-manager ready: true, restart count 0
Sep 21 12:29:12.384: INFO: symbiosis-k8s-controller-676ccb7ff7-7xg2s from symbiosis-system started at 2022-09-21 11:55:02 +0000 UTC (1 container statuses recorded)
Sep 21 12:29:12.384: INFO: 	Container symbiosis-k8s-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1716dff43a86db71], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:29:13.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4221" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":356,"completed":233,"skipped":3945,"failed":0}
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:13.425: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5801
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5801
I0921 12:29:13.489626      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5801, replica count: 2
Sep 21 12:29:16.546: INFO: Creating new exec pod
I0921 12:29:16.546186      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:29:20.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-5801 exec execpodbh5k9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Sep 21 12:29:21.142: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 21 12:29:21.142: INFO: stdout: "externalname-service-b899x"
Sep 21 12:29:21.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-5801 exec execpodbh5k9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.126.175.184 80'
Sep 21 12:29:21.316: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.126.175.184 80\nConnection to 10.126.175.184 80 port [tcp/http] succeeded!\n"
Sep 21 12:29:21.316: INFO: stdout: "externalname-service-vtsww"
Sep 21 12:29:21.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-5801 exec execpodbh5k9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.2 30055'
Sep 21 12:29:21.493: INFO: stderr: "+ nc -v -t -w 2 10.128.0.2 30055\nConnection to 10.128.0.2 30055 port [tcp/*] succeeded!\n+ echo hostName\n"
Sep 21 12:29:21.493: INFO: stdout: "externalname-service-b899x"
Sep 21 12:29:21.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-5801 exec execpodbh5k9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.3 30055'
Sep 21 12:29:21.678: INFO: stderr: "+ nc -v -t -w 2 10.128.0.3 30055\n+ echo hostName\nConnection to 10.128.0.3 30055 port [tcp/*] succeeded!\n"
Sep 21 12:29:21.678: INFO: stdout: "externalname-service-vtsww"
Sep 21 12:29:21.678: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:29:21.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5801" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:8.286 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":356,"completed":234,"skipped":3947,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:21.711: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4576, will wait for the garbage collector to delete the pods
Sep 21 12:29:23.804: INFO: Deleting Job.batch foo took: 5.599158ms
Sep 21 12:29:24.005: INFO: Terminating Job.batch foo pods took: 200.441203ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Sep 21 12:29:56.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4576" for this suite.

• [SLOW TEST:34.617 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":356,"completed":235,"skipped":3957,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:29:56.328: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:29:56.351: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Creating first CR 
Sep 21 12:29:58.919: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-09-21T12:29:58Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-09-21T12:29:58Z]] name:name1 resourceVersion:21617 uid:235c1f7c-0233-42d2-8c49-29cfcb285b2a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Sep 21 12:30:08.928: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-09-21T12:30:08Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-09-21T12:30:08Z]] name:name2 resourceVersion:21647 uid:fb799c02-cc77-428a-aa6c-de326f989d02] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Sep 21 12:30:18.938: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-09-21T12:29:58Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-09-21T12:30:18Z]] name:name1 resourceVersion:21661 uid:235c1f7c-0233-42d2-8c49-29cfcb285b2a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Sep 21 12:30:28.950: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-09-21T12:30:08Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-09-21T12:30:28Z]] name:name2 resourceVersion:21675 uid:fb799c02-cc77-428a-aa6c-de326f989d02] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Sep 21 12:30:38.959: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-09-21T12:29:58Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-09-21T12:30:18Z]] name:name1 resourceVersion:21693 uid:235c1f7c-0233-42d2-8c49-29cfcb285b2a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Sep 21 12:30:48.967: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-09-21T12:30:08Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-09-21T12:30:28Z]] name:name2 resourceVersion:21707 uid:fb799c02-cc77-428a-aa6c-de326f989d02] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:30:59.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8606" for this suite.

• [SLOW TEST:63.157 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":356,"completed":236,"skipped":3958,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:30:59.485: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0921 12:31:39.831015      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Sep 21 12:31:39.831: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Sep 21 12:31:39.831: INFO: Deleting pod "simpletest.rc-268nc" in namespace "gc-5848"
Sep 21 12:31:39.841: INFO: Deleting pod "simpletest.rc-2hkzd" in namespace "gc-5848"
Sep 21 12:31:39.876: INFO: Deleting pod "simpletest.rc-2m5ln" in namespace "gc-5848"
Sep 21 12:31:39.890: INFO: Deleting pod "simpletest.rc-2mlls" in namespace "gc-5848"
Sep 21 12:31:39.909: INFO: Deleting pod "simpletest.rc-49d79" in namespace "gc-5848"
Sep 21 12:31:39.947: INFO: Deleting pod "simpletest.rc-4n4vd" in namespace "gc-5848"
Sep 21 12:31:39.972: INFO: Deleting pod "simpletest.rc-4p7nh" in namespace "gc-5848"
Sep 21 12:31:39.986: INFO: Deleting pod "simpletest.rc-5fhsh" in namespace "gc-5848"
Sep 21 12:31:40.035: INFO: Deleting pod "simpletest.rc-5jm6c" in namespace "gc-5848"
Sep 21 12:31:40.066: INFO: Deleting pod "simpletest.rc-5qhp6" in namespace "gc-5848"
Sep 21 12:31:40.082: INFO: Deleting pod "simpletest.rc-65hfv" in namespace "gc-5848"
Sep 21 12:31:40.100: INFO: Deleting pod "simpletest.rc-6cb8w" in namespace "gc-5848"
Sep 21 12:31:40.129: INFO: Deleting pod "simpletest.rc-6m4mz" in namespace "gc-5848"
Sep 21 12:31:40.133: INFO: Deleting pod "simpletest.rc-6sxhs" in namespace "gc-5848"
Sep 21 12:31:40.151: INFO: Deleting pod "simpletest.rc-7lj8v" in namespace "gc-5848"
Sep 21 12:31:40.207: INFO: Deleting pod "simpletest.rc-7tfg4" in namespace "gc-5848"
Sep 21 12:31:40.267: INFO: Deleting pod "simpletest.rc-876ff" in namespace "gc-5848"
Sep 21 12:31:40.308: INFO: Deleting pod "simpletest.rc-88tbl" in namespace "gc-5848"
Sep 21 12:31:40.470: INFO: Deleting pod "simpletest.rc-8d77q" in namespace "gc-5848"
Sep 21 12:31:40.572: INFO: Deleting pod "simpletest.rc-929cc" in namespace "gc-5848"
Sep 21 12:31:40.627: INFO: Deleting pod "simpletest.rc-92z8l" in namespace "gc-5848"
Sep 21 12:31:40.743: INFO: Deleting pod "simpletest.rc-97ch5" in namespace "gc-5848"
Sep 21 12:31:40.751: INFO: Deleting pod "simpletest.rc-99zxt" in namespace "gc-5848"
Sep 21 12:31:40.756: INFO: Deleting pod "simpletest.rc-c7gg7" in namespace "gc-5848"
Sep 21 12:31:40.940: INFO: Deleting pod "simpletest.rc-c949q" in namespace "gc-5848"
Sep 21 12:31:40.970: INFO: Deleting pod "simpletest.rc-clw55" in namespace "gc-5848"
Sep 21 12:31:40.999: INFO: Deleting pod "simpletest.rc-cqqp6" in namespace "gc-5848"
Sep 21 12:31:41.171: INFO: Deleting pod "simpletest.rc-crnt6" in namespace "gc-5848"
Sep 21 12:31:41.267: INFO: Deleting pod "simpletest.rc-cttsx" in namespace "gc-5848"
Sep 21 12:31:41.303: INFO: Deleting pod "simpletest.rc-d7rk7" in namespace "gc-5848"
Sep 21 12:31:41.348: INFO: Deleting pod "simpletest.rc-dwdft" in namespace "gc-5848"
Sep 21 12:31:41.415: INFO: Deleting pod "simpletest.rc-dzcdb" in namespace "gc-5848"
Sep 21 12:31:41.630: INFO: Deleting pod "simpletest.rc-fbdw7" in namespace "gc-5848"
Sep 21 12:31:41.644: INFO: Deleting pod "simpletest.rc-fn4zc" in namespace "gc-5848"
Sep 21 12:31:41.718: INFO: Deleting pod "simpletest.rc-g54rn" in namespace "gc-5848"
Sep 21 12:31:41.732: INFO: Deleting pod "simpletest.rc-gc7k2" in namespace "gc-5848"
Sep 21 12:31:41.833: INFO: Deleting pod "simpletest.rc-gzmff" in namespace "gc-5848"
Sep 21 12:31:41.939: INFO: Deleting pod "simpletest.rc-h86m4" in namespace "gc-5848"
Sep 21 12:31:41.944: INFO: Deleting pod "simpletest.rc-hfd2b" in namespace "gc-5848"
Sep 21 12:31:41.976: INFO: Deleting pod "simpletest.rc-ht8f9" in namespace "gc-5848"
Sep 21 12:31:42.004: INFO: Deleting pod "simpletest.rc-j5gpb" in namespace "gc-5848"
Sep 21 12:31:42.020: INFO: Deleting pod "simpletest.rc-j8g2p" in namespace "gc-5848"
Sep 21 12:31:42.077: INFO: Deleting pod "simpletest.rc-j8hb7" in namespace "gc-5848"
Sep 21 12:31:42.115: INFO: Deleting pod "simpletest.rc-j8q4b" in namespace "gc-5848"
Sep 21 12:31:42.177: INFO: Deleting pod "simpletest.rc-jkldm" in namespace "gc-5848"
Sep 21 12:31:42.203: INFO: Deleting pod "simpletest.rc-jlb78" in namespace "gc-5848"
Sep 21 12:31:42.251: INFO: Deleting pod "simpletest.rc-jlvz4" in namespace "gc-5848"
Sep 21 12:31:42.286: INFO: Deleting pod "simpletest.rc-k7swp" in namespace "gc-5848"
Sep 21 12:31:42.357: INFO: Deleting pod "simpletest.rc-kbrpl" in namespace "gc-5848"
Sep 21 12:31:42.415: INFO: Deleting pod "simpletest.rc-kspvv" in namespace "gc-5848"
Sep 21 12:31:42.441: INFO: Deleting pod "simpletest.rc-l2xb5" in namespace "gc-5848"
Sep 21 12:31:42.475: INFO: Deleting pod "simpletest.rc-l6h9q" in namespace "gc-5848"
Sep 21 12:31:42.506: INFO: Deleting pod "simpletest.rc-lbkd7" in namespace "gc-5848"
Sep 21 12:31:42.596: INFO: Deleting pod "simpletest.rc-ltpfd" in namespace "gc-5848"
Sep 21 12:31:42.653: INFO: Deleting pod "simpletest.rc-m2crn" in namespace "gc-5848"
Sep 21 12:31:42.663: INFO: Deleting pod "simpletest.rc-m44k7" in namespace "gc-5848"
Sep 21 12:31:42.671: INFO: Deleting pod "simpletest.rc-m5wsj" in namespace "gc-5848"
Sep 21 12:31:42.681: INFO: Deleting pod "simpletest.rc-m6jr4" in namespace "gc-5848"
Sep 21 12:31:42.806: INFO: Deleting pod "simpletest.rc-mqhrs" in namespace "gc-5848"
Sep 21 12:31:42.828: INFO: Deleting pod "simpletest.rc-n2tb9" in namespace "gc-5848"
Sep 21 12:31:42.841: INFO: Deleting pod "simpletest.rc-nn6h2" in namespace "gc-5848"
Sep 21 12:31:42.901: INFO: Deleting pod "simpletest.rc-nxvdb" in namespace "gc-5848"
Sep 21 12:31:43.198: INFO: Deleting pod "simpletest.rc-p2cf2" in namespace "gc-5848"
Sep 21 12:31:43.230: INFO: Deleting pod "simpletest.rc-pmfzv" in namespace "gc-5848"
Sep 21 12:31:43.313: INFO: Deleting pod "simpletest.rc-pnlhs" in namespace "gc-5848"
Sep 21 12:31:43.326: INFO: Deleting pod "simpletest.rc-pqwgn" in namespace "gc-5848"
Sep 21 12:31:43.416: INFO: Deleting pod "simpletest.rc-q5qvx" in namespace "gc-5848"
Sep 21 12:31:43.544: INFO: Deleting pod "simpletest.rc-q7jhv" in namespace "gc-5848"
Sep 21 12:31:43.617: INFO: Deleting pod "simpletest.rc-q928l" in namespace "gc-5848"
Sep 21 12:31:43.671: INFO: Deleting pod "simpletest.rc-qdf6b" in namespace "gc-5848"
Sep 21 12:31:43.679: INFO: Deleting pod "simpletest.rc-qdndx" in namespace "gc-5848"
Sep 21 12:31:43.759: INFO: Deleting pod "simpletest.rc-qjn62" in namespace "gc-5848"
Sep 21 12:31:43.919: INFO: Deleting pod "simpletest.rc-rk2pq" in namespace "gc-5848"
Sep 21 12:31:43.984: INFO: Deleting pod "simpletest.rc-rm7zq" in namespace "gc-5848"
Sep 21 12:31:44.110: INFO: Deleting pod "simpletest.rc-rnc7q" in namespace "gc-5848"
Sep 21 12:31:44.280: INFO: Deleting pod "simpletest.rc-rrlhk" in namespace "gc-5848"
Sep 21 12:31:44.343: INFO: Deleting pod "simpletest.rc-sg2qr" in namespace "gc-5848"
Sep 21 12:31:44.372: INFO: Deleting pod "simpletest.rc-st967" in namespace "gc-5848"
Sep 21 12:31:44.482: INFO: Deleting pod "simpletest.rc-swm5l" in namespace "gc-5848"
Sep 21 12:31:44.751: INFO: Deleting pod "simpletest.rc-t5rh7" in namespace "gc-5848"
Sep 21 12:31:44.853: INFO: Deleting pod "simpletest.rc-tbxqf" in namespace "gc-5848"
Sep 21 12:31:45.111: INFO: Deleting pod "simpletest.rc-tft2m" in namespace "gc-5848"
Sep 21 12:31:45.180: INFO: Deleting pod "simpletest.rc-thnkv" in namespace "gc-5848"
Sep 21 12:31:45.496: INFO: Deleting pod "simpletest.rc-tz8nd" in namespace "gc-5848"
Sep 21 12:31:45.545: INFO: Deleting pod "simpletest.rc-vd2zj" in namespace "gc-5848"
Sep 21 12:31:45.571: INFO: Deleting pod "simpletest.rc-vgqgq" in namespace "gc-5848"
Sep 21 12:31:45.653: INFO: Deleting pod "simpletest.rc-vjk9g" in namespace "gc-5848"
Sep 21 12:31:45.687: INFO: Deleting pod "simpletest.rc-w6gb8" in namespace "gc-5848"
Sep 21 12:31:45.770: INFO: Deleting pod "simpletest.rc-w78rm" in namespace "gc-5848"
Sep 21 12:31:45.781: INFO: Deleting pod "simpletest.rc-wx8vv" in namespace "gc-5848"
Sep 21 12:31:45.794: INFO: Deleting pod "simpletest.rc-xbjsl" in namespace "gc-5848"
Sep 21 12:31:45.887: INFO: Deleting pod "simpletest.rc-xcqdn" in namespace "gc-5848"
Sep 21 12:31:45.960: INFO: Deleting pod "simpletest.rc-xhtp2" in namespace "gc-5848"
Sep 21 12:31:45.973: INFO: Deleting pod "simpletest.rc-xwgsz" in namespace "gc-5848"
Sep 21 12:31:46.047: INFO: Deleting pod "simpletest.rc-xwzqw" in namespace "gc-5848"
Sep 21 12:31:46.176: INFO: Deleting pod "simpletest.rc-z565p" in namespace "gc-5848"
Sep 21 12:31:46.184: INFO: Deleting pod "simpletest.rc-zbkpz" in namespace "gc-5848"
Sep 21 12:31:46.189: INFO: Deleting pod "simpletest.rc-zdrvr" in namespace "gc-5848"
Sep 21 12:31:46.242: INFO: Deleting pod "simpletest.rc-zhc5p" in namespace "gc-5848"
Sep 21 12:31:46.403: INFO: Deleting pod "simpletest.rc-zzb7c" in namespace "gc-5848"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Sep 21 12:31:46.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5848" for this suite.

• [SLOW TEST:46.996 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":356,"completed":237,"skipped":3959,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:31:46.588: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 12:31:47.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:31:47.226: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:48.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:31:48.240: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:49.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:31:49.242: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:50.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:31:50.244: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:51.237: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:31:51.237: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:52.233: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:31:52.233: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:53.233: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:31:53.233: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:54.237: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:31:54.238: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:31:55.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:31:55.240: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Sep 21 12:31:55.290: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24127"},"items":null}

Sep 21 12:31:55.294: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24127"},"items":[{"metadata":{"name":"daemon-set-7c66j","generateName":"daemon-set-","namespace":"daemonsets-3516","uid":"d5d7c3f8-3f4b-44e2-8fcc-cba08bfd6251","resourceVersion":"24123","creationTimestamp":"2022-09-21T12:31:47Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"05cd17d7a56cab2a3bb3231e717077e50eb53e2a36f240154bfc2fa88261299f","cni.projectcalico.org/podIP":"10.129.34.226/32","cni.projectcalico.org/podIPs":"10.129.34.226/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"677f9e5f-e8e3-4dd7-9aa3-d65418476a9c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-21T12:31:47Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"677f9e5f-e8e3-4dd7-9aa3-d65418476a9c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-09-21T12:31:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-21T12:31:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.34.226\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-l768f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-l768f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"general-2-kofawi","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["general-2-kofawi"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:47Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:48Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:48Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:47Z"}],"hostIP":"10.128.0.2","podIP":"10.129.34.226","podIPs":[{"ip":"10.129.34.226"}],"startTime":"2022-09-21T12:31:47Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-09-21T12:31:48Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://f8af22db66f473662b668c404623106b0abd6ec1bf3c70135d1a1195da06a0be","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qmm9p","generateName":"daemon-set-","namespace":"daemonsets-3516","uid":"7a4525b4-db7d-4563-ae6a-a15ff7e37f09","resourceVersion":"23619","creationTimestamp":"2022-09-21T12:31:47Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"6e3e447866c7e11c1f7f2d942906117cfae8d9ef6fb07d5cb6a1364b7e291378","cni.projectcalico.org/podIP":"10.129.53.239/32","cni.projectcalico.org/podIPs":"10.129.53.239/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"677f9e5f-e8e3-4dd7-9aa3-d65418476a9c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-21T12:31:47Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"677f9e5f-e8e3-4dd7-9aa3-d65418476a9c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-09-21T12:31:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-21T12:31:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.53.239\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vc2bn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vc2bn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"general-2-xtetrn","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["general-2-xtetrn"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:47Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:49Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:49Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-21T12:31:47Z"}],"hostIP":"10.128.0.3","podIP":"10.129.53.239","podIPs":[{"ip":"10.129.53.239"}],"startTime":"2022-09-21T12:31:47Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-09-21T12:31:48Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://2d2b5b85b5dd6b97f898d93e4440270f8aab4db902f33949359406f16ad6086b","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:31:55.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3516" for this suite.

• [SLOW TEST:8.731 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":356,"completed":238,"skipped":4048,"failed":0}
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:31:55.321: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Sep 21 12:31:59.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-7539" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":239,"skipped":4049,"failed":0}
SSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:31:59.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Sep 21 12:31:59.430: INFO: observed Pod pod-test in namespace pods-3043 in phase Pending with labels: map[test-pod-static:true] & conditions []
Sep 21 12:31:59.434: INFO: observed Pod pod-test in namespace pods-3043 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  }]
Sep 21 12:31:59.446: INFO: observed Pod pod-test in namespace pods-3043 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  }]
Sep 21 12:31:59.946: INFO: observed Pod pod-test in namespace pods-3043 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  }]
Sep 21 12:32:00.776: INFO: Found Pod pod-test in namespace pods-3043 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:32:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:32:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-09-21 12:31:59 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Sep 21 12:32:00.813: INFO: observed event type MODIFIED
Sep 21 12:32:02.781: INFO: observed event type MODIFIED
Sep 21 12:32:03.152: INFO: observed event type MODIFIED
Sep 21 12:32:03.776: INFO: observed event type MODIFIED
Sep 21 12:32:03.781: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 12:32:03.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3043" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":356,"completed":240,"skipped":4054,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:32:03.802: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:32:03.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524" in namespace "projected-5804" to be "Succeeded or Failed"
Sep 21 12:32:03.837: INFO: Pod "downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524": Phase="Pending", Reason="", readiness=false. Elapsed: 1.657266ms
Sep 21 12:32:05.845: INFO: Pod "downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009770745s
Sep 21 12:32:07.850: INFO: Pod "downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014677252s
STEP: Saw pod success
Sep 21 12:32:07.850: INFO: Pod "downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524" satisfied condition "Succeeded or Failed"
Sep 21 12:32:07.854: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524 container client-container: <nil>
STEP: delete the pod
Sep 21 12:32:07.868: INFO: Waiting for pod downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524 to disappear
Sep 21 12:32:07.872: INFO: Pod downwardapi-volume-226c0620-2883-4b48-b2a7-ad92331d7524 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 12:32:07.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5804" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":241,"skipped":4074,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:32:07.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6736.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6736.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6736.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6736.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 12:32:09.951: INFO: DNS probes using dns-6736/dns-test-7193c3e1-4efd-4836-ac91-02f8d6dab6cc succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 12:32:09.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6736" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","total":356,"completed":242,"skipped":4076,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:32:09.988: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Sep 21 12:32:10.019: INFO: The status of Pod pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:32:12.030: INFO: The status of Pod pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:32:14.029: INFO: The status of Pod pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 21 12:32:14.548: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c"
Sep 21 12:32:14.548: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c" in namespace "pods-1964" to be "terminated due to deadline exceeded"
Sep 21 12:32:14.551: INFO: Pod "pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c": Phase="Running", Reason="", readiness=true. Elapsed: 2.269035ms
Sep 21 12:32:16.563: INFO: Pod "pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c": Phase="Running", Reason="", readiness=false. Elapsed: 2.014118254s
Sep 21 12:32:18.571: INFO: Pod "pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.022380339s
Sep 21 12:32:18.571: INFO: Pod "pod-update-activedeadlineseconds-1f2db4fe-73d5-4c7c-8cf3-f2bfdd7d6d7c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 12:32:18.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1964" for this suite.

• [SLOW TEST:8.593 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":356,"completed":243,"skipped":4084,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:32:18.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-d7083a0b-1349-413e-bbca-c909bb591591 in namespace container-probe-9198
Sep 21 12:32:20.622: INFO: Started pod liveness-d7083a0b-1349-413e-bbca-c909bb591591 in namespace container-probe-9198
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 12:32:20.625: INFO: Initial restart count of pod liveness-d7083a0b-1349-413e-bbca-c909bb591591 is 0
Sep 21 12:32:40.721: INFO: Restart count of pod container-probe-9198/liveness-d7083a0b-1349-413e-bbca-c909bb591591 is now 1 (20.09602654s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 12:32:40.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9198" for this suite.

• [SLOW TEST:22.156 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":244,"skipped":4095,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:32:40.738: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-3292
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 12:32:40.761: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 21 12:32:40.790: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:32:42.801: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:32:44.801: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:32:46.800: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:32:48.801: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:32:50.806: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 21 12:32:52.804: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 21 12:32:52.808: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 21 12:32:54.861: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Sep 21 12:32:54.862: INFO: Going to poll 10.129.34.235 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Sep 21 12:32:54.864: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.129.34.235 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3292 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:32:54.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:32:54.865: INFO: ExecWithOptions: Clientset creation
Sep 21 12:32:54.865: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-3292/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.129.34.235+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Sep 21 12:32:55.950: INFO: Found all 1 expected endpoints: [netserver-0]
Sep 21 12:32:55.950: INFO: Going to poll 10.129.53.233 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Sep 21 12:32:55.958: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.129.53.233 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3292 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:32:55.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:32:55.959: INFO: ExecWithOptions: Clientset creation
Sep 21 12:32:55.959: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/pod-network-test-3292/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.129.53.233+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Sep 21 12:32:57.039: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Sep 21 12:32:57.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3292" for this suite.

• [SLOW TEST:16.315 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":245,"skipped":4113,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:32:57.054: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:32:57.083: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4" in namespace "downward-api-7072" to be "Succeeded or Failed"
Sep 21 12:32:57.085: INFO: Pod "downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.229574ms
Sep 21 12:32:59.108: INFO: Pod "downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025330117s
Sep 21 12:33:01.118: INFO: Pod "downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034740643s
STEP: Saw pod success
Sep 21 12:33:01.118: INFO: Pod "downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4" satisfied condition "Succeeded or Failed"
Sep 21 12:33:01.120: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4 container client-container: <nil>
STEP: delete the pod
Sep 21 12:33:01.145: INFO: Waiting for pod downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4 to disappear
Sep 21 12:33:01.147: INFO: Pod downwardapi-volume-5576db86-1f81-4141-abc6-588dc2326bc4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:33:01.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7072" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":246,"skipped":4131,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:01.158: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:33:01.194: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee" in namespace "downward-api-1356" to be "Succeeded or Failed"
Sep 21 12:33:01.197: INFO: Pod "downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.67843ms
Sep 21 12:33:03.202: INFO: Pod "downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee": Phase="Running", Reason="", readiness=true. Elapsed: 2.007354112s
Sep 21 12:33:05.214: INFO: Pod "downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01939343s
STEP: Saw pod success
Sep 21 12:33:05.214: INFO: Pod "downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee" satisfied condition "Succeeded or Failed"
Sep 21 12:33:05.217: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee container client-container: <nil>
STEP: delete the pod
Sep 21 12:33:05.230: INFO: Waiting for pod downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee to disappear
Sep 21 12:33:05.234: INFO: Pod downwardapi-volume-69a4f8d2-f57f-4d8b-a677-0509d30a69ee no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:33:05.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1356" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":247,"skipped":4136,"failed":0}
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:05.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Sep 21 12:33:05.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5275" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":356,"completed":248,"skipped":4142,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:05.305: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating cluster-info
Sep 21 12:33:05.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2892 cluster-info'
Sep 21 12:33:05.411: INFO: stderr: ""
Sep 21 12:33:05.411: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.124.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:33:05.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2892" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":356,"completed":249,"skipped":4167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:05.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Sep 21 12:33:05.465: INFO: Pod name sample-pod: Found 1 pods out of 3
Sep 21 12:33:10.470: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Sep 21 12:33:10.473: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Sep 21 12:33:10.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3496" for this suite.

• [SLOW TEST:5.071 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":356,"completed":250,"skipped":4252,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:10.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 21 12:33:10.550: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Sep 21 12:33:15.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6887" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":356,"completed":251,"skipped":4302,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:15.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 21 12:33:15.203: INFO: Waiting up to 5m0s for pod "pod-daa5454f-eab1-4e3c-862c-c79479137e58" in namespace "emptydir-6527" to be "Succeeded or Failed"
Sep 21 12:33:15.220: INFO: Pod "pod-daa5454f-eab1-4e3c-862c-c79479137e58": Phase="Pending", Reason="", readiness=false. Elapsed: 16.87314ms
Sep 21 12:33:17.236: INFO: Pod "pod-daa5454f-eab1-4e3c-862c-c79479137e58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03291884s
Sep 21 12:33:19.246: INFO: Pod "pod-daa5454f-eab1-4e3c-862c-c79479137e58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042561886s
STEP: Saw pod success
Sep 21 12:33:19.246: INFO: Pod "pod-daa5454f-eab1-4e3c-862c-c79479137e58" satisfied condition "Succeeded or Failed"
Sep 21 12:33:19.249: INFO: Trying to get logs from node general-2-kofawi pod pod-daa5454f-eab1-4e3c-862c-c79479137e58 container test-container: <nil>
STEP: delete the pod
Sep 21 12:33:19.262: INFO: Waiting for pod pod-daa5454f-eab1-4e3c-862c-c79479137e58 to disappear
Sep 21 12:33:19.265: INFO: Pod pod-daa5454f-eab1-4e3c-862c-c79479137e58 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:33:19.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6527" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":252,"skipped":4312,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:19.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 21 12:33:19.306: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4087  ff3d58b4-9903-4089-9c97-aacb58d01c40 24808 0 2022-09-21 12:33:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-09-21 12:33:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:33:19.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4087  ff3d58b4-9903-4089-9c97-aacb58d01c40 24809 0 2022-09-21 12:33:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-09-21 12:33:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 21 12:33:19.318: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4087  ff3d58b4-9903-4089-9c97-aacb58d01c40 24810 0 2022-09-21 12:33:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-09-21 12:33:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:33:19.318: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4087  ff3d58b4-9903-4089-9c97-aacb58d01c40 24811 0 2022-09-21 12:33:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-09-21 12:33:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Sep 21 12:33:19.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4087" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":356,"completed":253,"skipped":4348,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:19.330: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-effbf80b-edf8-4adc-99a8-3872bcb9cfd0
STEP: Creating a pod to test consume secrets
Sep 21 12:33:19.358: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f" in namespace "projected-9377" to be "Succeeded or Failed"
Sep 21 12:33:19.360: INFO: Pod "pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.856605ms
Sep 21 12:33:21.370: INFO: Pod "pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011419941s
Sep 21 12:33:23.376: INFO: Pod "pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018067051s
STEP: Saw pod success
Sep 21 12:33:23.377: INFO: Pod "pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f" satisfied condition "Succeeded or Failed"
Sep 21 12:33:23.379: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:33:23.394: INFO: Waiting for pod pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f to disappear
Sep 21 12:33:23.396: INFO: Pod pod-projected-secrets-1ae50acf-f804-4b6e-b3ff-77f34c6c825f no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 12:33:23.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9377" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":254,"skipped":4380,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:23.405: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Sep 21 12:33:23.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:33:39.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2691" for this suite.

• [SLOW TEST:15.921 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":356,"completed":255,"skipped":4381,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:39.328: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:33:39.365: INFO: created pod pod-service-account-defaultsa
Sep 21 12:33:39.365: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 21 12:33:39.374: INFO: created pod pod-service-account-mountsa
Sep 21 12:33:39.374: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 21 12:33:39.388: INFO: created pod pod-service-account-nomountsa
Sep 21 12:33:39.388: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 21 12:33:39.393: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 21 12:33:39.394: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 21 12:33:39.399: INFO: created pod pod-service-account-mountsa-mountspec
Sep 21 12:33:39.400: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 21 12:33:39.406: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 21 12:33:39.406: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 21 12:33:39.413: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 21 12:33:39.413: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 21 12:33:39.417: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 21 12:33:39.417: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 21 12:33:39.421: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 21 12:33:39.421: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Sep 21 12:33:39.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-814" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":356,"completed":256,"skipped":4407,"failed":0}

------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:39.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1107
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1107
STEP: creating replication controller externalsvc in namespace services-1107
I0921 12:33:39.498270      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1107, replica count: 2
I0921 12:33:42.549171      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 12:33:45.550333      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 12:33:48.551352      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Sep 21 12:33:48.570: INFO: Creating new exec pod
Sep 21 12:33:54.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-1107 exec execpodlzpkx -- /bin/sh -x -c nslookup nodeport-service.services-1107.svc.cluster.local'
Sep 21 12:33:54.809: INFO: stderr: "+ nslookup nodeport-service.services-1107.svc.cluster.local\n"
Sep 21 12:33:54.809: INFO: stdout: "Server:\t\t10.124.0.10\nAddress:\t10.124.0.10#53\n\nnodeport-service.services-1107.svc.cluster.local\tcanonical name = externalsvc.services-1107.svc.cluster.local.\nName:\texternalsvc.services-1107.svc.cluster.local\nAddress: 10.124.144.31\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1107, will wait for the garbage collector to delete the pods
Sep 21 12:33:54.867: INFO: Deleting ReplicationController externalsvc took: 4.31459ms
Sep 21 12:33:54.968: INFO: Terminating ReplicationController externalsvc pods took: 101.02377ms
Sep 21 12:33:57.389: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:33:57.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1107" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:17.985 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":356,"completed":257,"skipped":4407,"failed":0}
SSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:33:57.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Sep 21 12:33:57.458: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:33:59.463: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Sep 21 12:33:59.472: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:34:01.481: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 21 12:34:01.484: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.484: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.484: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.485: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Sep 21 12:34:01.584: INFO: Exec stderr: ""
Sep 21 12:34:01.584: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.585: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.586: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.587: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Sep 21 12:34:01.672: INFO: Exec stderr: ""
Sep 21 12:34:01.672: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.673: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.674: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Sep 21 12:34:01.748: INFO: Exec stderr: ""
Sep 21 12:34:01.748: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.748: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.749: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.749: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Sep 21 12:34:01.830: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 21 12:34:01.830: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.830: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.831: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.832: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Sep 21 12:34:01.908: INFO: Exec stderr: ""
Sep 21 12:34:01.908: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.909: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.909: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Sep 21 12:34:01.983: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 21 12:34:01.984: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:01.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:01.985: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:01.985: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Sep 21 12:34:02.066: INFO: Exec stderr: ""
Sep 21 12:34:02.066: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:02.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:02.068: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:02.068: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Sep 21 12:34:02.149: INFO: Exec stderr: ""
Sep 21 12:34:02.150: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:02.150: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:02.151: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:02.151: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Sep 21 12:34:02.237: INFO: Exec stderr: ""
Sep 21 12:34:02.237: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3653 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:34:02.237: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:02.238: INFO: ExecWithOptions: Clientset creation
Sep 21 12:34:02.238: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3653/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Sep 21 12:34:02.305: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:188
Sep 21 12:34:02.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3653" for this suite.
•{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":258,"skipped":4413,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:02.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  test/e2e/framework/framework.go:652
STEP: Request ServerVersion
STEP: Confirm major version
Sep 21 12:34:02.363: INFO: Major version: 1
STEP: Confirm minor version
Sep 21 12:34:02.363: INFO: cleanMinorVersion: 24
Sep 21 12:34:02.364: INFO: Minor version: 24
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:188
Sep 21 12:34:02.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-5118" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":356,"completed":259,"skipped":4426,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:02.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:34:03.523: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:34:06.550: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:34:06.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8018" for this suite.
STEP: Destroying namespace "webhook-8018-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":356,"completed":260,"skipped":4441,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:06.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0921 12:34:07.303447      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Sep 21 12:34:07.303: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Sep 21 12:34:07.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4567" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":356,"completed":261,"skipped":4504,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:07.312: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1412
STEP: creating an pod
Sep 21 12:34:07.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.39 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Sep 21 12:34:07.444: INFO: stderr: ""
Sep 21 12:34:07.444: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for log generator to start.
Sep 21 12:34:07.444: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Sep 21 12:34:07.444: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2732" to be "running and ready, or succeeded"
Sep 21 12:34:07.447: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.57068ms
Sep 21 12:34:09.453: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.00838573s
Sep 21 12:34:09.453: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Sep 21 12:34:09.453: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Sep 21 12:34:09.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 logs logs-generator logs-generator'
Sep 21 12:34:09.563: INFO: stderr: ""
Sep 21 12:34:09.563: INFO: stdout: "I0921 12:34:08.261638       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/655s 509\nI0921 12:34:08.461923       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/ndj 271\nI0921 12:34:08.663633       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/6gfj 277\nI0921 12:34:08.862060       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/hxn 291\nI0921 12:34:09.062559       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/h58 276\nI0921 12:34:09.262108       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/pch 411\nI0921 12:34:09.462604       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/zsv 256\n"
STEP: limiting log lines
Sep 21 12:34:09.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 logs logs-generator logs-generator --tail=1'
Sep 21 12:34:09.661: INFO: stderr: ""
Sep 21 12:34:09.661: INFO: stdout: "I0921 12:34:09.661753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/t2vh 203\n"
Sep 21 12:34:09.661: INFO: got output "I0921 12:34:09.661753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/t2vh 203\n"
STEP: limiting log bytes
Sep 21 12:34:09.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 logs logs-generator logs-generator --limit-bytes=1'
Sep 21 12:34:09.751: INFO: stderr: ""
Sep 21 12:34:09.751: INFO: stdout: "I"
Sep 21 12:34:09.751: INFO: got output "I"
STEP: exposing timestamps
Sep 21 12:34:09.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 logs logs-generator logs-generator --tail=1 --timestamps'
Sep 21 12:34:09.834: INFO: stderr: ""
Sep 21 12:34:09.834: INFO: stdout: "2022-09-21T12:34:09.661895199Z I0921 12:34:09.661753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/t2vh 203\n"
Sep 21 12:34:09.834: INFO: got output "2022-09-21T12:34:09.661895199Z I0921 12:34:09.661753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/t2vh 203\n"
STEP: restricting to a time range
Sep 21 12:34:12.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 logs logs-generator logs-generator --since=1s'
Sep 21 12:34:12.437: INFO: stderr: ""
Sep 21 12:34:12.437: INFO: stdout: "I0921 12:34:11.461691       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/lcl6 520\nI0921 12:34:11.661989       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/xrq9 422\nI0921 12:34:11.862303       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/jg8 265\nI0921 12:34:12.062642       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/5tg 210\nI0921 12:34:12.262041       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/5vf 446\n"
Sep 21 12:34:12.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 logs logs-generator logs-generator --since=24h'
Sep 21 12:34:12.511: INFO: stderr: ""
Sep 21 12:34:12.511: INFO: stdout: "I0921 12:34:08.261638       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/655s 509\nI0921 12:34:08.461923       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/ndj 271\nI0921 12:34:08.663633       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/6gfj 277\nI0921 12:34:08.862060       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/hxn 291\nI0921 12:34:09.062559       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/h58 276\nI0921 12:34:09.262108       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/pch 411\nI0921 12:34:09.462604       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/zsv 256\nI0921 12:34:09.661753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/t2vh 203\nI0921 12:34:09.862151       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/jlm 448\nI0921 12:34:10.064137       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/77b 323\nI0921 12:34:10.262651       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/s8c4 205\nI0921 12:34:10.461995       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/khn 499\nI0921 12:34:10.662333       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/4lv2 207\nI0921 12:34:10.862735       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/569 532\nI0921 12:34:11.062013       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/lkn 378\nI0921 12:34:11.262437       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/8t2 541\nI0921 12:34:11.461691       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/lcl6 520\nI0921 12:34:11.661989       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/xrq9 422\nI0921 12:34:11.862303       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/jg8 265\nI0921 12:34:12.062642       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/5tg 210\nI0921 12:34:12.262041       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/5vf 446\nI0921 12:34:12.462386       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/s8c 559\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1417
Sep 21 12:34:12.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2732 delete pod logs-generator'
Sep 21 12:34:13.382: INFO: stderr: ""
Sep 21 12:34:13.382: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:34:13.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2732" for this suite.

• [SLOW TEST:6.078 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1409
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":356,"completed":262,"skipped":4505,"failed":0}
S
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:13.390: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:188
Sep 21 12:34:13.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4509" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":356,"completed":263,"skipped":4506,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:13.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Sep 21 12:34:13.450: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Sep 21 12:34:24.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:34:26.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:34:36.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1298" for this suite.

• [SLOW TEST:22.870 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":356,"completed":264,"skipped":4510,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:36.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:34:37.024: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:34:40.048: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:34:40.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2611" for this suite.
STEP: Destroying namespace "webhook-2611-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":356,"completed":265,"skipped":4523,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:40.158: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Sep 21 12:34:44.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3348" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":356,"completed":266,"skipped":4540,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:34:44.214: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:34:44.244: INFO: created pod
Sep 21 12:34:44.244: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1549" to be "Succeeded or Failed"
Sep 21 12:34:44.246: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.825508ms
Sep 21 12:34:46.255: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011288172s
Sep 21 12:34:48.261: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017146925s
STEP: Saw pod success
Sep 21 12:34:48.262: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Sep 21 12:35:18.262: INFO: polling logs
Sep 21 12:35:18.267: INFO: Pod logs: 
I0921 12:34:44.969631       1 log.go:195] OK: Got token
I0921 12:34:44.969718       1 log.go:195] validating with in-cluster discovery
I0921 12:34:44.969944       1 log.go:195] OK: got issuer https://ynhqaouc.amd-5.germany-1.symbiosis.host
I0921 12:34:44.969991       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://ynhqaouc.amd-5.germany-1.symbiosis.host", Subject:"system:serviceaccount:svcaccounts-1549:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1663764284, NotBefore:1663763684, IssuedAt:1663763684, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1549", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e3c14f00-811f-4a08-90e1-2cd11240b5b3"}}}
I0921 12:34:44.988110       1 log.go:195] OK: Constructed OIDC provider for issuer https://ynhqaouc.amd-5.germany-1.symbiosis.host
I0921 12:34:44.995221       1 log.go:195] OK: Validated signature on JWT
I0921 12:34:44.995329       1 log.go:195] OK: Got valid claims from token!
I0921 12:34:44.995374       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://ynhqaouc.amd-5.germany-1.symbiosis.host", Subject:"system:serviceaccount:svcaccounts-1549:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1663764284, NotBefore:1663763684, IssuedAt:1663763684, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1549", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e3c14f00-811f-4a08-90e1-2cd11240b5b3"}}}

Sep 21 12:35:18.267: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Sep 21 12:35:18.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1549" for this suite.

• [SLOW TEST:34.065 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":356,"completed":267,"skipped":4553,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:35:18.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a pod template
STEP: Replace a pod template
Sep 21 12:35:18.309: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Sep 21 12:35:18.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8662" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","total":356,"completed":268,"skipped":4564,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:35:18.325: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test env composition
Sep 21 12:35:18.353: INFO: Waiting up to 5m0s for pod "var-expansion-18cbac94-04a0-456e-aec7-46a906e70677" in namespace "var-expansion-9735" to be "Succeeded or Failed"
Sep 21 12:35:18.357: INFO: Pod "var-expansion-18cbac94-04a0-456e-aec7-46a906e70677": Phase="Pending", Reason="", readiness=false. Elapsed: 3.936653ms
Sep 21 12:35:20.365: INFO: Pod "var-expansion-18cbac94-04a0-456e-aec7-46a906e70677": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01186392s
Sep 21 12:35:22.371: INFO: Pod "var-expansion-18cbac94-04a0-456e-aec7-46a906e70677": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018076757s
STEP: Saw pod success
Sep 21 12:35:22.371: INFO: Pod "var-expansion-18cbac94-04a0-456e-aec7-46a906e70677" satisfied condition "Succeeded or Failed"
Sep 21 12:35:22.376: INFO: Trying to get logs from node general-2-kofawi pod var-expansion-18cbac94-04a0-456e-aec7-46a906e70677 container dapi-container: <nil>
STEP: delete the pod
Sep 21 12:35:22.389: INFO: Waiting for pod var-expansion-18cbac94-04a0-456e-aec7-46a906e70677 to disappear
Sep 21 12:35:22.392: INFO: Pod var-expansion-18cbac94-04a0-456e-aec7-46a906e70677 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 12:35:22.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9735" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":356,"completed":269,"skipped":4625,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:35:22.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3069
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:35:22.441: INFO: Found 0 stateful pods, waiting for 1
Sep 21 12:35:32.451: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Sep 21 12:35:32.468: INFO: Found 1 stateful pods, waiting for 2
Sep 21 12:35:42.480: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:35:42.480: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:35:42.501: INFO: Deleting all statefulset in ns statefulset-3069
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:35:42.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3069" for this suite.

• [SLOW TEST:20.164 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":356,"completed":270,"skipped":4627,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:35:42.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Sep 21 12:35:48.684: INFO: 80 pods remaining
Sep 21 12:35:48.684: INFO: 80 pods has nil DeletionTimestamp
Sep 21 12:35:48.684: INFO: 
Sep 21 12:35:49.725: INFO: 68 pods remaining
Sep 21 12:35:49.725: INFO: 68 pods has nil DeletionTimestamp
Sep 21 12:35:49.725: INFO: 
Sep 21 12:35:50.934: INFO: 60 pods remaining
Sep 21 12:35:50.934: INFO: 60 pods has nil DeletionTimestamp
Sep 21 12:35:50.935: INFO: 
Sep 21 12:35:51.683: INFO: 40 pods remaining
Sep 21 12:35:51.819: INFO: 40 pods has nil DeletionTimestamp
Sep 21 12:35:51.865: INFO: 
Sep 21 12:35:53.232: INFO: 22 pods remaining
Sep 21 12:35:53.232: INFO: 22 pods has nil DeletionTimestamp
Sep 21 12:35:53.232: INFO: 
Sep 21 12:35:53.680: INFO: 20 pods remaining
Sep 21 12:35:53.680: INFO: 20 pods has nil DeletionTimestamp
Sep 21 12:35:53.680: INFO: 
STEP: Gathering metrics
W0921 12:35:55.117106      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Sep 21 12:35:55.338: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Sep 21 12:35:55.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4574" for this suite.

• [SLOW TEST:12.844 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":356,"completed":271,"skipped":4647,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:35:55.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:35:55.455: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 21 12:35:55.465: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 21 12:36:00.476: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 21 12:36:24.490: INFO: Creating deployment "test-rolling-update-deployment"
Sep 21 12:36:24.494: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 21 12:36:24.498: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 21 12:36:26.512: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 21 12:36:26.514: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 12:36:26.521: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9011  2fe78999-860b-426f-b237-0e4159ea976a 27464 1 2022-09-21 12:36:24 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-09-21 12:36:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:36:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00492ea68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-09-21 12:36:24 +0000 UTC,LastTransitionTime:2022-09-21 12:36:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67c8f74c6c" has successfully progressed.,LastUpdateTime:2022-09-21 12:36:26 +0000 UTC,LastTransitionTime:2022-09-21 12:36:24 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 21 12:36:26.524: INFO: New ReplicaSet "test-rolling-update-deployment-67c8f74c6c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c  deployment-9011  82f71293-5816-4be2-bfb4-b7cbd3f9d460 27455 1 2022-09-21 12:36:24 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 2fe78999-860b-426f-b237-0e4159ea976a 0xc0049789d7 0xc0049789d8}] []  [{kube-controller-manager Update apps/v1 2022-09-21 12:36:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2fe78999-860b-426f-b237-0e4159ea976a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:36:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67c8f74c6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004978ac8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:36:26.524: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 21 12:36:26.524: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9011  57e9597f-6d09-46ec-906d-7262b6aa7f60 27463 2 2022-09-21 12:35:55 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 2fe78999-860b-426f-b237-0e4159ea976a 0xc004978807 0xc004978808}] []  [{e2e.test Update apps/v1 2022-09-21 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:36:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2fe78999-860b-426f-b237-0e4159ea976a\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:36:26 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004978938 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:36:26.527: INFO: Pod "test-rolling-update-deployment-67c8f74c6c-mfxw5" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c-mfxw5 test-rolling-update-deployment-67c8f74c6c- deployment-9011  157a622c-0d22-41bd-85ad-4cba3f49c3e8 27454 0 2022-09-21 12:36:24 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[cni.projectcalico.org/containerID:f93a6423fe18cf821f3637e19ef17a63192b8b94b664b9ed5d1ed3d643b19f80 cni.projectcalico.org/podIP:10.129.34.225/32 cni.projectcalico.org/podIPs:10.129.34.225/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-67c8f74c6c 82f71293-5816-4be2-bfb4-b7cbd3f9d460 0xc004979027 0xc004979028}] []  [{kube-controller-manager Update v1 2022-09-21 12:36:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"82f71293-5816-4be2-bfb4-b7cbd3f9d460\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 12:36:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 12:36:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.34.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8fhzr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fhzr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-kofawi,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:36:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:36:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:36:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:36:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.34.225,StartTime:2022-09-21 12:36:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 12:36:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://d41e7d081d68626212e699aa39d56a8ae55082e65ea8cdbfc239faa6ebc7b40a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.34.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 12:36:26.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9011" for this suite.

• [SLOW TEST:31.129 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":272,"skipped":4665,"failed":0}
SSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:36:26.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 in namespace container-probe-9299
Sep 21 12:36:28.579: INFO: Started pod liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 in namespace container-probe-9299
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 12:36:28.582: INFO: Initial restart count of pod liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 is 0
Sep 21 12:36:48.671: INFO: Restart count of pod container-probe-9299/liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 is now 1 (20.089299863s elapsed)
Sep 21 12:37:08.749: INFO: Restart count of pod container-probe-9299/liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 is now 2 (40.167372228s elapsed)
Sep 21 12:37:28.836: INFO: Restart count of pod container-probe-9299/liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 is now 3 (1m0.253755607s elapsed)
Sep 21 12:37:48.923: INFO: Restart count of pod container-probe-9299/liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 is now 4 (1m20.341008949s elapsed)
Sep 21 12:38:49.199: INFO: Restart count of pod container-probe-9299/liveness-dc7c4bc1-f4f3-4db5-9916-166e766492d8 is now 5 (2m20.617229939s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Sep 21 12:38:49.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9299" for this suite.

• [SLOW TEST:142.680 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":356,"completed":273,"skipped":4671,"failed":0}
SSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:49.217: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pod templates
Sep 21 12:38:49.243: INFO: created test-podtemplate-1
Sep 21 12:38:49.246: INFO: created test-podtemplate-2
Sep 21 12:38:49.248: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Sep 21 12:38:49.249: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Sep 21 12:38:49.255: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Sep 21 12:38:49.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7363" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":356,"completed":274,"skipped":4674,"failed":0}
SSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:49.264: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:188
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Sep 21 12:38:49.288: INFO: starting watch
STEP: patching
STEP: updating
Sep 21 12:38:49.293: INFO: waiting for watch events with expected annotations
Sep 21 12:38:49.293: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:188
Sep 21 12:38:49.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-2180" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":356,"completed":275,"skipped":4682,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:49.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 21 12:38:49.326: INFO: Waiting up to 5m0s for pod "pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063" in namespace "emptydir-9948" to be "Succeeded or Failed"
Sep 21 12:38:49.333: INFO: Pod "pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063": Phase="Pending", Reason="", readiness=false. Elapsed: 6.118504ms
Sep 21 12:38:51.343: INFO: Pod "pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016622282s
Sep 21 12:38:53.350: INFO: Pod "pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023608376s
STEP: Saw pod success
Sep 21 12:38:53.351: INFO: Pod "pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063" satisfied condition "Succeeded or Failed"
Sep 21 12:38:53.354: INFO: Trying to get logs from node general-2-kofawi pod pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063 container test-container: <nil>
STEP: delete the pod
Sep 21 12:38:53.380: INFO: Waiting for pod pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063 to disappear
Sep 21 12:38:53.382: INFO: Pod pod-b576c2c0-5069-4ec9-9d5c-cbca3d967063 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:38:53.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9948" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":276,"skipped":4693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:53.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:38:53.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-416" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":356,"completed":277,"skipped":4726,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:53.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Sep 21 12:38:53.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4613" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":278,"skipped":4744,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:53.464: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-312f4318-a240-40ed-9f05-4bcd945892eb
STEP: Creating configMap with name cm-test-opt-upd-e1897b1b-fb97-4f45-80ab-c242d37efac4
STEP: Creating the pod
Sep 21 12:38:53.503: INFO: The status of Pod pod-projected-configmaps-0059d527-6f17-4248-95fe-64d959b403b7 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:38:55.509: INFO: The status of Pod pod-projected-configmaps-0059d527-6f17-4248-95fe-64d959b403b7 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-312f4318-a240-40ed-9f05-4bcd945892eb
STEP: Updating configmap cm-test-opt-upd-e1897b1b-fb97-4f45-80ab-c242d37efac4
STEP: Creating configMap with name cm-test-opt-create-1a941979-319d-4192-8af6-cd381505677b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:38:57.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5931" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":279,"skipped":4755,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:38:57.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Sep 21 12:38:57.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:38:59.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:39:09.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-348" for this suite.

• [SLOW TEST:11.723 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":356,"completed":280,"skipped":4774,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:09.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Starting the proxy
Sep 21 12:39:09.332: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-297 proxy --unix-socket=/tmp/kubectl-proxy-unix2643364986/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:39:09.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-297" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":356,"completed":281,"skipped":4820,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:09.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:39:09.466: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 21 12:39:14.470: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 21 12:39:14.471: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 12:39:14.484: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2465  afaa0c9d-17fa-43f7-83b2-0b0b42f77ea4 27956 1 2022-09-21 12:39:14 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-09-21 12:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ce8218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Sep 21 12:39:14.492: INFO: New ReplicaSet "test-cleanup-deployment-6755c7b765" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-6755c7b765  deployment-2465  5bb93ae1-587b-46c8-a80a-427282af2751 27958 1 2022-09-21 12:39:14 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment afaa0c9d-17fa-43f7-83b2-0b0b42f77ea4 0xc004ce8737 0xc004ce8738}] []  [{kube-controller-manager Update apps/v1 2022-09-21 12:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"afaa0c9d-17fa-43f7-83b2-0b0b42f77ea4\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6755c7b765,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ce87c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:39:14.492: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 21 12:39:14.492: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2465  df697cff-27a3-4011-8d7c-45db59a35616 27957 1 2022-09-21 12:39:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment afaa0c9d-17fa-43f7-83b2-0b0b42f77ea4 0xc004ce85c7 0xc004ce85c8}] []  [{e2e.test Update apps/v1 2022-09-21 12:39:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:39:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-09-21 12:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"afaa0c9d-17fa-43f7-83b2-0b0b42f77ea4\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004ce8698 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:39:14.501: INFO: Pod "test-cleanup-controller-jl4jz" is available:
&Pod{ObjectMeta:{test-cleanup-controller-jl4jz test-cleanup-controller- deployment-2465  5b24d6f1-f6d9-411f-806f-463d3604aca0 27945 0 2022-09-21 12:39:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:1c8a3f6f1e57888b79a7acce3d991af2154b74c72cd771812c0cd9059c4108a2 cni.projectcalico.org/podIP:10.129.34.229/32 cni.projectcalico.org/podIPs:10.129.34.229/32] [{apps/v1 ReplicaSet test-cleanup-controller df697cff-27a3-4011-8d7c-45db59a35616 0xc00446c237 0xc00446c238}] []  [{kube-controller-manager Update v1 2022-09-21 12:39:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"df697cff-27a3-4011-8d7c-45db59a35616\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 12:39:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 12:39:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.34.229\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mnbh2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mnbh2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-kofawi,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:39:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:39:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:39:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:39:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.34.229,StartTime:2022-09-21 12:39:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 12:39:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c66e320fc3312b4c7ca95a3ec7affb2c128f94c3337da019d9e5b6e83eabcfb6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.34.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 12:39:14.502: INFO: Pod "test-cleanup-deployment-6755c7b765-hqlhj" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-6755c7b765-hqlhj test-cleanup-deployment-6755c7b765- deployment-2465  2e368eff-f3dd-4e06-8601-c317dd7458ce 27962 0 2022-09-21 12:39:14 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-6755c7b765 5bb93ae1-587b-46c8-a80a-427282af2751 0xc00446c497 0xc00446c498}] []  [{kube-controller-manager Update v1 2022-09-21 12:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5bb93ae1-587b-46c8-a80a-427282af2751\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqzlv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqzlv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-kofawi,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:39:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 12:39:14.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2465" for this suite.

• [SLOW TEST:5.124 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":356,"completed":282,"skipped":4827,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:14.519: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-1317cfd9-1fe9-49ab-95de-e10e24755f91
STEP: Creating a pod to test consume configMaps
Sep 21 12:39:14.542: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026" in namespace "projected-4237" to be "Succeeded or Failed"
Sep 21 12:39:14.544: INFO: Pod "pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742239ms
Sep 21 12:39:16.559: INFO: Pod "pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016987348s
Sep 21 12:39:18.567: INFO: Pod "pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024855913s
STEP: Saw pod success
Sep 21 12:39:18.567: INFO: Pod "pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026" satisfied condition "Succeeded or Failed"
Sep 21 12:39:18.569: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:39:18.581: INFO: Waiting for pod pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026 to disappear
Sep 21 12:39:18.584: INFO: Pod pod-projected-configmaps-55f343f4-8d11-4d43-9cf5-20b846668026 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Sep 21 12:39:18.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4237" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":283,"skipped":4828,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:18.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-76797ab9-19d7-4e11-a790-cccc05c34465
STEP: Creating a pod to test consume secrets
Sep 21 12:39:18.635: INFO: Waiting up to 5m0s for pod "pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d" in namespace "secrets-6634" to be "Succeeded or Failed"
Sep 21 12:39:18.643: INFO: Pod "pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585438ms
Sep 21 12:39:20.648: INFO: Pod "pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012875471s
Sep 21 12:39:22.661: INFO: Pod "pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02522568s
STEP: Saw pod success
Sep 21 12:39:22.661: INFO: Pod "pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d" satisfied condition "Succeeded or Failed"
Sep 21 12:39:22.669: INFO: Trying to get logs from node general-2-kofawi pod pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:39:22.680: INFO: Waiting for pod pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d to disappear
Sep 21 12:39:22.683: INFO: Pod pod-secrets-fcafc038-5012-473f-9bc5-2e8faddf325d no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:39:22.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6634" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":284,"skipped":4855,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:22.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Sep 21 12:39:22.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2" in namespace "downward-api-3684" to be "Succeeded or Failed"
Sep 21 12:39:22.720: INFO: Pod "downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.967943ms
Sep 21 12:39:24.732: INFO: Pod "downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017975261s
Sep 21 12:39:26.743: INFO: Pod "downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029700747s
STEP: Saw pod success
Sep 21 12:39:26.744: INFO: Pod "downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2" satisfied condition "Succeeded or Failed"
Sep 21 12:39:26.747: INFO: Trying to get logs from node general-2-kofawi pod downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2 container client-container: <nil>
STEP: delete the pod
Sep 21 12:39:26.761: INFO: Waiting for pod downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2 to disappear
Sep 21 12:39:26.764: INFO: Pod downwardapi-volume-88b37615-786b-44f1-974f-7c11d79f14b2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Sep 21 12:39:26.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3684" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":285,"skipped":4874,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:26.776: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-f2v2
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 12:39:26.813: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f2v2" in namespace "subpath-584" to be "Succeeded or Failed"
Sep 21 12:39:26.819: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026909ms
Sep 21 12:39:28.829: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015995348s
Sep 21 12:39:30.837: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 4.023596113s
Sep 21 12:39:32.841: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 6.02740051s
Sep 21 12:39:34.851: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 8.03765485s
Sep 21 12:39:36.862: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 10.048523358s
Sep 21 12:39:38.870: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 12.056660838s
Sep 21 12:39:40.876: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 14.062748516s
Sep 21 12:39:42.880: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 16.066364711s
Sep 21 12:39:44.889: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 18.075724574s
Sep 21 12:39:46.896: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=true. Elapsed: 20.082236755s
Sep 21 12:39:48.903: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Running", Reason="", readiness=false. Elapsed: 22.089762394s
Sep 21 12:39:50.909: INFO: Pod "pod-subpath-test-configmap-f2v2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.095410679s
STEP: Saw pod success
Sep 21 12:39:50.909: INFO: Pod "pod-subpath-test-configmap-f2v2" satisfied condition "Succeeded or Failed"
Sep 21 12:39:50.911: INFO: Trying to get logs from node general-2-kofawi pod pod-subpath-test-configmap-f2v2 container test-container-subpath-configmap-f2v2: <nil>
STEP: delete the pod
Sep 21 12:39:50.924: INFO: Waiting for pod pod-subpath-test-configmap-f2v2 to disappear
Sep 21 12:39:50.926: INFO: Pod pod-subpath-test-configmap-f2v2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f2v2
Sep 21 12:39:50.926: INFO: Deleting pod "pod-subpath-test-configmap-f2v2" in namespace "subpath-584"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Sep 21 12:39:50.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-584" for this suite.

• [SLOW TEST:24.159 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","total":356,"completed":286,"skipped":4899,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:39:50.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 21 12:39:50.977: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28174 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:39:50.977: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28174 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 21 12:39:50.983: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28175 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:39:50.984: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28175 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 21 12:39:50.989: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28176 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:39:50.989: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28176 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 21 12:39:50.993: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28177 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:39:50.994: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8749  54b2b1c6-0405-4f5e-b9d4-4a25e1f93ec8 28177 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 21 12:39:50.998: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8749  619561df-456f-41ed-9d3e-a3ab65f73e77 28178 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:39:50.998: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8749  619561df-456f-41ed-9d3e-a3ab65f73e77 28178 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 21 12:40:01.006: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8749  619561df-456f-41ed-9d3e-a3ab65f73e77 28202 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 21 12:40:01.006: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8749  619561df-456f-41ed-9d3e-a3ab65f73e77 28202 0 2022-09-21 12:39:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-09-21 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Sep 21 12:40:11.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8749" for this suite.

• [SLOW TEST:20.082 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":356,"completed":287,"skipped":4935,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:40:11.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:40:11.410: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:40:14.429: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:40:14.436: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2503-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:40:17.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1754" for this suite.
STEP: Destroying namespace "webhook-1754-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.562 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":356,"completed":288,"skipped":4950,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:40:17.600: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching services
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:40:17.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2023" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":356,"completed":289,"skipped":4971,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:40:17.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Sep 21 12:40:19.719: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Sep 21 12:40:21.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2727" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":356,"completed":290,"skipped":4982,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:40:21.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Sep 21 12:40:21.788: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 12:41:21.816: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:41:21.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Sep 21 12:41:23.866: INFO: found a healthy node: general-2-kofawi
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:41:35.943: INFO: pods created so far: [1 1 1]
Sep 21 12:41:35.943: INFO: length of pods created so far: 3
Sep 21 12:41:37.954: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:188
Sep 21 12:41:44.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-5012" for this suite.
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:41:44.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4532" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:83.287 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":356,"completed":291,"skipped":5030,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:41:45.044: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 21 12:41:45.075: INFO: Waiting up to 5m0s for pod "pod-c6862761-744a-4abc-bfb6-821c93c9f103" in namespace "emptydir-5280" to be "Succeeded or Failed"
Sep 21 12:41:45.079: INFO: Pod "pod-c6862761-744a-4abc-bfb6-821c93c9f103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.890585ms
Sep 21 12:41:47.092: INFO: Pod "pod-c6862761-744a-4abc-bfb6-821c93c9f103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017020401s
Sep 21 12:41:49.107: INFO: Pod "pod-c6862761-744a-4abc-bfb6-821c93c9f103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032821952s
STEP: Saw pod success
Sep 21 12:41:49.108: INFO: Pod "pod-c6862761-744a-4abc-bfb6-821c93c9f103" satisfied condition "Succeeded or Failed"
Sep 21 12:41:49.110: INFO: Trying to get logs from node general-2-kofawi pod pod-c6862761-744a-4abc-bfb6-821c93c9f103 container test-container: <nil>
STEP: delete the pod
Sep 21 12:41:49.165: INFO: Waiting for pod pod-c6862761-744a-4abc-bfb6-821c93c9f103 to disappear
Sep 21 12:41:49.168: INFO: Pod pod-c6862761-744a-4abc-bfb6-821c93c9f103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:41:49.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5280" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":292,"skipped":5040,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:41:49.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:42:02.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7367" for this suite.

• [SLOW TEST:13.130 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":356,"completed":293,"skipped":5075,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:42:02.337: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5690
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5690
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5690
Sep 21 12:42:02.379: INFO: Found 0 stateful pods, waiting for 1
Sep 21 12:42:12.388: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 21 12:42:12.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:42:12.570: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:42:12.570: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:42:12.570: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:42:12.574: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 21 12:42:22.587: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:42:22.587: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:42:22.604: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999619s
Sep 21 12:42:23.612: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997652809s
Sep 21 12:42:24.618: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.9896822s
Sep 21 12:42:25.627: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98282242s
Sep 21 12:42:26.636: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.97385926s
Sep 21 12:42:27.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.965460613s
Sep 21 12:42:28.651: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.959112554s
Sep 21 12:42:29.659: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.949703962s
Sep 21 12:42:30.663: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.942502063s
Sep 21 12:42:31.672: INFO: Verifying statefulset ss doesn't scale past 1 for another 937.796569ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5690
Sep 21 12:42:32.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:42:32.839: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:42:32.840: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:42:32.840: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:42:32.842: INFO: Found 1 stateful pods, waiting for 3
Sep 21 12:42:42.846: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:42:42.846: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:42:42.846: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 21 12:42:42.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:42:43.010: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:42:43.010: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:42:43.010: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:42:43.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:42:43.149: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:42:43.149: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:42:43.149: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:42:43.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:42:43.288: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:42:43.288: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:42:43.288: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:42:43.288: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:42:43.292: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 21 12:42:53.299: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:42:53.299: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:42:53.299: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 12:42:53.317: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999539s
Sep 21 12:42:54.326: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996495719s
Sep 21 12:42:55.334: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988055798s
Sep 21 12:42:56.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.979842044s
Sep 21 12:42:57.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972473053s
Sep 21 12:42:58.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964479382s
Sep 21 12:42:59.365: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.958373595s
Sep 21 12:43:00.370: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.948845619s
Sep 21 12:43:01.378: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.945024971s
Sep 21 12:43:02.386: INFO: Verifying statefulset ss doesn't scale past 3 for another 935.760233ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5690
Sep 21 12:43:03.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:43:03.529: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:43:03.529: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:43:03.529: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:43:03.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:43:03.697: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:43:03.697: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:43:03.697: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:43:03.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-5690 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:43:03.850: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:43:03.850: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:43:03.850: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:43:03.850: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:43:13.867: INFO: Deleting all statefulset in ns statefulset-5690
Sep 21 12:43:13.870: INFO: Scaling statefulset ss to 0
Sep 21 12:43:13.880: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:43:13.882: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:43:13.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5690" for this suite.

• [SLOW TEST:71.570 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":356,"completed":294,"skipped":5086,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:43:13.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:43:24.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8495" for this suite.

• [SLOW TEST:11.082 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":356,"completed":295,"skipped":5098,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:43:24.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:43:41.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5646" for this suite.

• [SLOW TEST:16.168 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":356,"completed":296,"skipped":5116,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:43:41.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1334
STEP: creating the pod
Sep 21 12:43:41.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 create -f -'
Sep 21 12:43:42.079: INFO: stderr: ""
Sep 21 12:43:42.079: INFO: stdout: "pod/pause created\n"
Sep 21 12:43:42.079: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 21 12:43:42.079: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5429" to be "running and ready"
Sep 21 12:43:42.085: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.517741ms
Sep 21 12:43:44.093: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014115632s
Sep 21 12:43:44.093: INFO: Pod "pause" satisfied condition "running and ready"
Sep 21 12:43:44.093: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 21 12:43:44.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 label pods pause testing-label=testing-label-value'
Sep 21 12:43:44.199: INFO: stderr: ""
Sep 21 12:43:44.199: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 21 12:43:44.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 get pod pause -L testing-label'
Sep 21 12:43:44.291: INFO: stderr: ""
Sep 21 12:43:44.291: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 21 12:43:44.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 label pods pause testing-label-'
Sep 21 12:43:44.389: INFO: stderr: ""
Sep 21 12:43:44.389: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 21 12:43:44.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 get pod pause -L testing-label'
Sep 21 12:43:44.478: INFO: stderr: ""
Sep 21 12:43:44.478: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
Sep 21 12:43:44.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 delete --grace-period=0 --force -f -'
Sep 21 12:43:44.558: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:43:44.558: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 21 12:43:44.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 get rc,svc -l name=pause --no-headers'
Sep 21 12:43:44.663: INFO: stderr: "No resources found in kubectl-5429 namespace.\n"
Sep 21 12:43:44.663: INFO: stdout: ""
Sep 21 12:43:44.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5429 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 12:43:44.748: INFO: stderr: ""
Sep 21 12:43:44.748: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:43:44.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5429" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":356,"completed":297,"skipped":5147,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:43:44.755: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:43:44.773: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7034
I0921 12:43:44.778012      18 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7034, replica count: 1
I0921 12:43:45.828929      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 12:43:46.829578      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:43:46.942: INFO: Created: latency-svc-kkvmg
Sep 21 12:43:46.952: INFO: Got endpoints: latency-svc-kkvmg [22.262704ms]
Sep 21 12:43:46.970: INFO: Created: latency-svc-44jrt
Sep 21 12:43:46.976: INFO: Created: latency-svc-w6n5m
Sep 21 12:43:46.982: INFO: Got endpoints: latency-svc-44jrt [30.163013ms]
Sep 21 12:43:46.986: INFO: Got endpoints: latency-svc-w6n5m [32.983432ms]
Sep 21 12:43:46.990: INFO: Created: latency-svc-qxgq5
Sep 21 12:43:46.991: INFO: Created: latency-svc-2rqvc
Sep 21 12:43:47.002: INFO: Created: latency-svc-x4nlr
Sep 21 12:43:47.015: INFO: Got endpoints: latency-svc-x4nlr [62.095084ms]
Sep 21 12:43:47.003: INFO: Got endpoints: latency-svc-2rqvc [49.961072ms]
Sep 21 12:43:47.003: INFO: Got endpoints: latency-svc-qxgq5 [49.722864ms]
Sep 21 12:43:47.013: INFO: Created: latency-svc-tq9nl
Sep 21 12:43:47.020: INFO: Created: latency-svc-2n7nr
Sep 21 12:43:47.028: INFO: Got endpoints: latency-svc-tq9nl [74.791776ms]
Sep 21 12:43:47.032: INFO: Got endpoints: latency-svc-2n7nr [78.500035ms]
Sep 21 12:43:47.032: INFO: Created: latency-svc-5ghj4
Sep 21 12:43:47.037: INFO: Created: latency-svc-q9t5z
Sep 21 12:43:47.041: INFO: Got endpoints: latency-svc-5ghj4 [87.118235ms]
Sep 21 12:43:47.043: INFO: Got endpoints: latency-svc-q9t5z [21.647228ms]
Sep 21 12:43:47.075: INFO: Created: latency-svc-s952z
Sep 21 12:43:47.076: INFO: Created: latency-svc-n5zgp
Sep 21 12:43:47.077: INFO: Created: latency-svc-hp6rf
Sep 21 12:43:47.077: INFO: Created: latency-svc-nxjbd
Sep 21 12:43:47.080: INFO: Created: latency-svc-rl8n6
Sep 21 12:43:47.081: INFO: Got endpoints: latency-svc-s952z [97.766806ms]
Sep 21 12:43:47.082: INFO: Created: latency-svc-dqdv8
Sep 21 12:43:47.082: INFO: Created: latency-svc-7jpzg
Sep 21 12:43:47.083: INFO: Created: latency-svc-lk7rl
Sep 21 12:43:47.083: INFO: Created: latency-svc-vbrjz
Sep 21 12:43:47.083: INFO: Created: latency-svc-5d47q
Sep 21 12:43:47.083: INFO: Created: latency-svc-7fzz6
Sep 21 12:43:47.083: INFO: Created: latency-svc-d4zvn
Sep 21 12:43:47.083: INFO: Created: latency-svc-7znzh
Sep 21 12:43:47.084: INFO: Created: latency-svc-dlb4d
Sep 21 12:43:47.084: INFO: Created: latency-svc-s9gp6
Sep 21 12:43:47.105: INFO: Created: latency-svc-9gb97
Sep 21 12:43:47.111: INFO: Got endpoints: latency-svc-nxjbd [157.167144ms]
Sep 21 12:43:47.112: INFO: Got endpoints: latency-svc-hp6rf [158.190246ms]
Sep 21 12:43:47.112: INFO: Got endpoints: latency-svc-s9gp6 [158.468746ms]
Sep 21 12:43:47.113: INFO: Got endpoints: latency-svc-d4zvn [80.583814ms]
Sep 21 12:43:47.113: INFO: Got endpoints: latency-svc-n5zgp [92.114615ms]
Sep 21 12:43:47.129: INFO: Created: latency-svc-vgkcc
Sep 21 12:43:47.129: INFO: Got endpoints: latency-svc-lk7rl [175.764703ms]
Sep 21 12:43:47.129: INFO: Got endpoints: latency-svc-7znzh [85.838916ms]
Sep 21 12:43:47.131: INFO: Got endpoints: latency-svc-dlb4d [102.889883ms]
Sep 21 12:43:47.133: INFO: Got endpoints: latency-svc-7fzz6 [116.901011ms]
Sep 21 12:43:47.133: INFO: Got endpoints: latency-svc-vbrjz [179.311289ms]
Sep 21 12:43:47.139: INFO: Got endpoints: latency-svc-rl8n6 [185.552438ms]
Sep 21 12:43:47.140: INFO: Created: latency-svc-cxfwr
Sep 21 12:43:47.143: INFO: Got endpoints: latency-svc-dqdv8 [156.890026ms]
Sep 21 12:43:47.143: INFO: Got endpoints: latency-svc-9gb97 [61.993368ms]
Sep 21 12:43:47.143: INFO: Got endpoints: latency-svc-5d47q [102.77353ms]
Sep 21 12:43:47.154: INFO: Created: latency-svc-xqnhp
Sep 21 12:43:47.155: INFO: Got endpoints: latency-svc-xqnhp [43.157109ms]
Sep 21 12:43:47.155: INFO: Got endpoints: latency-svc-7jpzg [201.629692ms]
Sep 21 12:43:47.155: INFO: Got endpoints: latency-svc-vgkcc [44.490884ms]
Sep 21 12:43:47.156: INFO: Got endpoints: latency-svc-cxfwr [43.912987ms]
Sep 21 12:43:47.182: INFO: Created: latency-svc-vrh8z
Sep 21 12:43:47.191: INFO: Created: latency-svc-ff5c6
Sep 21 12:43:47.191: INFO: Created: latency-svc-rnkv5
Sep 21 12:43:47.191: INFO: Created: latency-svc-n4pz8
Sep 21 12:43:47.192: INFO: Created: latency-svc-z7tpw
Sep 21 12:43:47.192: INFO: Created: latency-svc-7q7l6
Sep 21 12:43:47.192: INFO: Created: latency-svc-59pzh
Sep 21 12:43:47.192: INFO: Created: latency-svc-nqt8z
Sep 21 12:43:47.192: INFO: Created: latency-svc-9z46q
Sep 21 12:43:47.193: INFO: Created: latency-svc-jmz6t
Sep 21 12:43:47.193: INFO: Created: latency-svc-hswbx
Sep 21 12:43:47.193: INFO: Created: latency-svc-tprcq
Sep 21 12:43:47.193: INFO: Created: latency-svc-xj9f6
Sep 21 12:43:47.193: INFO: Created: latency-svc-qqpm6
Sep 21 12:43:47.193: INFO: Created: latency-svc-4w758
Sep 21 12:43:47.195: INFO: Got endpoints: latency-svc-n4pz8 [82.05248ms]
Sep 21 12:43:47.205: INFO: Got endpoints: latency-svc-59pzh [72.22776ms]
Sep 21 12:43:47.206: INFO: Created: latency-svc-cqbqc
Sep 21 12:43:47.206: INFO: Got endpoints: latency-svc-9z46q [63.385651ms]
Sep 21 12:43:47.206: INFO: Got endpoints: latency-svc-nqt8z [67.107878ms]
Sep 21 12:43:47.206: INFO: Got endpoints: latency-svc-ff5c6 [77.141568ms]
Sep 21 12:43:47.206: INFO: Got endpoints: latency-svc-7q7l6 [73.302967ms]
Sep 21 12:43:47.213: INFO: Created: latency-svc-47qcv
Sep 21 12:43:47.218: INFO: Created: latency-svc-8sj6h
Sep 21 12:43:47.219: INFO: Created: latency-svc-qj94x
Sep 21 12:43:47.224: INFO: Created: latency-svc-ptls8
Sep 21 12:43:47.226: INFO: Created: latency-svc-vd875
Sep 21 12:43:47.244: INFO: Got endpoints: latency-svc-jmz6t [131.830211ms]
Sep 21 12:43:47.252: INFO: Created: latency-svc-nnzxs
Sep 21 12:43:47.296: INFO: Got endpoints: latency-svc-hswbx [139.422494ms]
Sep 21 12:43:47.301: INFO: Created: latency-svc-xltxb
Sep 21 12:43:47.343: INFO: Got endpoints: latency-svc-qqpm6 [187.401416ms]
Sep 21 12:43:47.352: INFO: Created: latency-svc-dww89
Sep 21 12:43:47.393: INFO: Got endpoints: latency-svc-4w758 [262.655696ms]
Sep 21 12:43:47.399: INFO: Created: latency-svc-8rv96
Sep 21 12:43:47.445: INFO: Got endpoints: latency-svc-tprcq [302.003927ms]
Sep 21 12:43:47.466: INFO: Created: latency-svc-wq294
Sep 21 12:43:47.496: INFO: Got endpoints: latency-svc-xj9f6 [352.733598ms]
Sep 21 12:43:47.505: INFO: Created: latency-svc-768sc
Sep 21 12:43:47.546: INFO: Got endpoints: latency-svc-rnkv5 [390.7081ms]
Sep 21 12:43:47.555: INFO: Created: latency-svc-pdzrd
Sep 21 12:43:47.597: INFO: Got endpoints: latency-svc-vrh8z [441.824287ms]
Sep 21 12:43:47.611: INFO: Created: latency-svc-hvf26
Sep 21 12:43:47.655: INFO: Got endpoints: latency-svc-z7tpw [524.220595ms]
Sep 21 12:43:47.671: INFO: Created: latency-svc-dl9nh
Sep 21 12:43:47.695: INFO: Got endpoints: latency-svc-cqbqc [499.375081ms]
Sep 21 12:43:47.712: INFO: Created: latency-svc-692m8
Sep 21 12:43:47.744: INFO: Got endpoints: latency-svc-47qcv [538.079157ms]
Sep 21 12:43:47.754: INFO: Created: latency-svc-fx5q6
Sep 21 12:43:47.798: INFO: Got endpoints: latency-svc-8sj6h [590.853873ms]
Sep 21 12:43:47.809: INFO: Created: latency-svc-qk5wg
Sep 21 12:43:47.846: INFO: Got endpoints: latency-svc-qj94x [639.605496ms]
Sep 21 12:43:47.856: INFO: Created: latency-svc-2msl2
Sep 21 12:43:47.895: INFO: Got endpoints: latency-svc-ptls8 [688.249524ms]
Sep 21 12:43:47.906: INFO: Created: latency-svc-zlwpl
Sep 21 12:43:47.951: INFO: Got endpoints: latency-svc-vd875 [743.337768ms]
Sep 21 12:43:47.966: INFO: Created: latency-svc-xhjv6
Sep 21 12:43:48.000: INFO: Got endpoints: latency-svc-nnzxs [755.073673ms]
Sep 21 12:43:48.010: INFO: Created: latency-svc-r6phh
Sep 21 12:43:48.047: INFO: Got endpoints: latency-svc-xltxb [751.138415ms]
Sep 21 12:43:48.060: INFO: Created: latency-svc-nnxl6
Sep 21 12:43:48.094: INFO: Got endpoints: latency-svc-dww89 [750.878342ms]
Sep 21 12:43:48.104: INFO: Created: latency-svc-zrgh2
Sep 21 12:43:48.146: INFO: Got endpoints: latency-svc-8rv96 [752.998181ms]
Sep 21 12:43:48.155: INFO: Created: latency-svc-v46mm
Sep 21 12:43:48.198: INFO: Got endpoints: latency-svc-wq294 [752.287121ms]
Sep 21 12:43:48.206: INFO: Created: latency-svc-vhdsp
Sep 21 12:43:48.246: INFO: Got endpoints: latency-svc-768sc [750.03953ms]
Sep 21 12:43:48.258: INFO: Created: latency-svc-pnvwt
Sep 21 12:43:48.300: INFO: Got endpoints: latency-svc-pdzrd [753.631163ms]
Sep 21 12:43:48.311: INFO: Created: latency-svc-8wdlt
Sep 21 12:43:48.344: INFO: Got endpoints: latency-svc-hvf26 [746.068269ms]
Sep 21 12:43:48.354: INFO: Created: latency-svc-h7jxw
Sep 21 12:43:48.396: INFO: Got endpoints: latency-svc-dl9nh [740.400826ms]
Sep 21 12:43:48.403: INFO: Created: latency-svc-rzv7z
Sep 21 12:43:48.444: INFO: Got endpoints: latency-svc-692m8 [749.664608ms]
Sep 21 12:43:48.452: INFO: Created: latency-svc-ltwt9
Sep 21 12:43:48.495: INFO: Got endpoints: latency-svc-fx5q6 [751.344405ms]
Sep 21 12:43:48.508: INFO: Created: latency-svc-lw9tj
Sep 21 12:43:48.546: INFO: Got endpoints: latency-svc-qk5wg [748.058912ms]
Sep 21 12:43:48.557: INFO: Created: latency-svc-4bdw9
Sep 21 12:43:48.596: INFO: Got endpoints: latency-svc-2msl2 [749.353555ms]
Sep 21 12:43:48.611: INFO: Created: latency-svc-8fqxw
Sep 21 12:43:48.646: INFO: Got endpoints: latency-svc-zlwpl [750.240032ms]
Sep 21 12:43:48.655: INFO: Created: latency-svc-6hgzf
Sep 21 12:43:48.698: INFO: Got endpoints: latency-svc-xhjv6 [746.603635ms]
Sep 21 12:43:48.709: INFO: Created: latency-svc-d66kp
Sep 21 12:43:48.746: INFO: Got endpoints: latency-svc-r6phh [746.510546ms]
Sep 21 12:43:48.755: INFO: Created: latency-svc-6k9st
Sep 21 12:43:48.799: INFO: Got endpoints: latency-svc-nnxl6 [752.574179ms]
Sep 21 12:43:48.811: INFO: Created: latency-svc-hhwws
Sep 21 12:43:48.846: INFO: Got endpoints: latency-svc-zrgh2 [751.890359ms]
Sep 21 12:43:48.857: INFO: Created: latency-svc-lt6nf
Sep 21 12:43:48.899: INFO: Got endpoints: latency-svc-v46mm [752.35877ms]
Sep 21 12:43:48.909: INFO: Created: latency-svc-mkb47
Sep 21 12:43:48.946: INFO: Got endpoints: latency-svc-vhdsp [748.553285ms]
Sep 21 12:43:48.961: INFO: Created: latency-svc-4kklb
Sep 21 12:43:48.995: INFO: Got endpoints: latency-svc-pnvwt [748.217984ms]
Sep 21 12:43:49.005: INFO: Created: latency-svc-wqbwl
Sep 21 12:43:49.046: INFO: Got endpoints: latency-svc-8wdlt [746.621638ms]
Sep 21 12:43:49.056: INFO: Created: latency-svc-c5wkv
Sep 21 12:43:49.105: INFO: Got endpoints: latency-svc-h7jxw [760.938176ms]
Sep 21 12:43:49.124: INFO: Created: latency-svc-rr2c4
Sep 21 12:43:49.146: INFO: Got endpoints: latency-svc-rzv7z [750.434131ms]
Sep 21 12:43:49.158: INFO: Created: latency-svc-s8fdr
Sep 21 12:43:49.200: INFO: Got endpoints: latency-svc-ltwt9 [755.780945ms]
Sep 21 12:43:49.216: INFO: Created: latency-svc-5bbgh
Sep 21 12:43:49.247: INFO: Got endpoints: latency-svc-lw9tj [751.310303ms]
Sep 21 12:43:49.262: INFO: Created: latency-svc-pjbjf
Sep 21 12:43:49.296: INFO: Got endpoints: latency-svc-4bdw9 [750.220677ms]
Sep 21 12:43:49.302: INFO: Created: latency-svc-x22hh
Sep 21 12:43:49.345: INFO: Got endpoints: latency-svc-8fqxw [748.224701ms]
Sep 21 12:43:49.353: INFO: Created: latency-svc-qnjbq
Sep 21 12:43:49.396: INFO: Got endpoints: latency-svc-6hgzf [750.153439ms]
Sep 21 12:43:49.403: INFO: Created: latency-svc-4f9zz
Sep 21 12:43:49.444: INFO: Got endpoints: latency-svc-d66kp [745.695152ms]
Sep 21 12:43:49.451: INFO: Created: latency-svc-7mrqp
Sep 21 12:43:49.504: INFO: Got endpoints: latency-svc-6k9st [757.870373ms]
Sep 21 12:43:49.511: INFO: Created: latency-svc-nbhbx
Sep 21 12:43:49.548: INFO: Got endpoints: latency-svc-hhwws [748.723302ms]
Sep 21 12:43:49.557: INFO: Created: latency-svc-cdwdl
Sep 21 12:43:49.595: INFO: Got endpoints: latency-svc-lt6nf [748.876067ms]
Sep 21 12:43:49.609: INFO: Created: latency-svc-zs8nv
Sep 21 12:43:49.646: INFO: Got endpoints: latency-svc-mkb47 [747.696927ms]
Sep 21 12:43:49.657: INFO: Created: latency-svc-cx6m8
Sep 21 12:43:49.698: INFO: Got endpoints: latency-svc-4kklb [751.19907ms]
Sep 21 12:43:49.711: INFO: Created: latency-svc-4l55w
Sep 21 12:43:49.748: INFO: Got endpoints: latency-svc-wqbwl [752.914049ms]
Sep 21 12:43:49.761: INFO: Created: latency-svc-cjntc
Sep 21 12:43:49.795: INFO: Got endpoints: latency-svc-c5wkv [748.698451ms]
Sep 21 12:43:49.807: INFO: Created: latency-svc-c5gsj
Sep 21 12:43:49.845: INFO: Got endpoints: latency-svc-rr2c4 [739.715421ms]
Sep 21 12:43:49.852: INFO: Created: latency-svc-s7c28
Sep 21 12:43:49.894: INFO: Got endpoints: latency-svc-s8fdr [748.046293ms]
Sep 21 12:43:49.901: INFO: Created: latency-svc-zdm4q
Sep 21 12:43:49.945: INFO: Got endpoints: latency-svc-5bbgh [744.222542ms]
Sep 21 12:43:49.956: INFO: Created: latency-svc-qh5tk
Sep 21 12:43:49.997: INFO: Got endpoints: latency-svc-pjbjf [750.22293ms]
Sep 21 12:43:50.007: INFO: Created: latency-svc-2svqb
Sep 21 12:43:50.045: INFO: Got endpoints: latency-svc-x22hh [748.656674ms]
Sep 21 12:43:50.052: INFO: Created: latency-svc-6qq2v
Sep 21 12:43:50.094: INFO: Got endpoints: latency-svc-qnjbq [749.647741ms]
Sep 21 12:43:50.103: INFO: Created: latency-svc-4ggg4
Sep 21 12:43:50.145: INFO: Got endpoints: latency-svc-4f9zz [749.157104ms]
Sep 21 12:43:50.153: INFO: Created: latency-svc-xmk5d
Sep 21 12:43:50.195: INFO: Got endpoints: latency-svc-7mrqp [750.770538ms]
Sep 21 12:43:50.206: INFO: Created: latency-svc-4c7wh
Sep 21 12:43:50.245: INFO: Got endpoints: latency-svc-nbhbx [740.986229ms]
Sep 21 12:43:50.256: INFO: Created: latency-svc-zrfkh
Sep 21 12:43:50.298: INFO: Got endpoints: latency-svc-cdwdl [749.658002ms]
Sep 21 12:43:50.311: INFO: Created: latency-svc-6srcd
Sep 21 12:43:50.349: INFO: Got endpoints: latency-svc-zs8nv [754.061953ms]
Sep 21 12:43:50.360: INFO: Created: latency-svc-ntmpw
Sep 21 12:43:50.398: INFO: Got endpoints: latency-svc-cx6m8 [751.955214ms]
Sep 21 12:43:50.409: INFO: Created: latency-svc-5xflw
Sep 21 12:43:50.450: INFO: Got endpoints: latency-svc-4l55w [752.350516ms]
Sep 21 12:43:50.462: INFO: Created: latency-svc-pkzp6
Sep 21 12:43:50.495: INFO: Got endpoints: latency-svc-cjntc [747.710404ms]
Sep 21 12:43:50.508: INFO: Created: latency-svc-bf2tt
Sep 21 12:43:50.546: INFO: Got endpoints: latency-svc-c5gsj [750.965722ms]
Sep 21 12:43:50.555: INFO: Created: latency-svc-hm8f4
Sep 21 12:43:50.597: INFO: Got endpoints: latency-svc-s7c28 [752.004364ms]
Sep 21 12:43:50.604: INFO: Created: latency-svc-tqmq8
Sep 21 12:43:50.648: INFO: Got endpoints: latency-svc-zdm4q [753.383698ms]
Sep 21 12:43:50.660: INFO: Created: latency-svc-gpjr5
Sep 21 12:43:50.696: INFO: Got endpoints: latency-svc-qh5tk [751.164033ms]
Sep 21 12:43:50.706: INFO: Created: latency-svc-ttjrx
Sep 21 12:43:50.749: INFO: Got endpoints: latency-svc-2svqb [751.384262ms]
Sep 21 12:43:50.759: INFO: Created: latency-svc-6rtzx
Sep 21 12:43:50.801: INFO: Got endpoints: latency-svc-6qq2v [755.758956ms]
Sep 21 12:43:50.814: INFO: Created: latency-svc-hcblk
Sep 21 12:43:50.849: INFO: Got endpoints: latency-svc-4ggg4 [753.70134ms]
Sep 21 12:43:50.856: INFO: Created: latency-svc-8wvfq
Sep 21 12:43:50.897: INFO: Got endpoints: latency-svc-xmk5d [751.824606ms]
Sep 21 12:43:50.908: INFO: Created: latency-svc-qvjhp
Sep 21 12:43:50.947: INFO: Got endpoints: latency-svc-4c7wh [752.092865ms]
Sep 21 12:43:50.960: INFO: Created: latency-svc-tkzcn
Sep 21 12:43:51.005: INFO: Got endpoints: latency-svc-zrfkh [759.56849ms]
Sep 21 12:43:51.023: INFO: Created: latency-svc-gb2bx
Sep 21 12:43:51.047: INFO: Got endpoints: latency-svc-6srcd [748.405103ms]
Sep 21 12:43:51.060: INFO: Created: latency-svc-5lthm
Sep 21 12:43:51.097: INFO: Got endpoints: latency-svc-ntmpw [747.979457ms]
Sep 21 12:43:51.107: INFO: Created: latency-svc-w2qkw
Sep 21 12:43:51.149: INFO: Got endpoints: latency-svc-5xflw [750.092374ms]
Sep 21 12:43:51.156: INFO: Created: latency-svc-z767t
Sep 21 12:43:51.197: INFO: Got endpoints: latency-svc-pkzp6 [746.893586ms]
Sep 21 12:43:51.212: INFO: Created: latency-svc-t5tgw
Sep 21 12:43:51.246: INFO: Got endpoints: latency-svc-bf2tt [750.096318ms]
Sep 21 12:43:51.258: INFO: Created: latency-svc-4sz5f
Sep 21 12:43:51.299: INFO: Got endpoints: latency-svc-hm8f4 [751.836596ms]
Sep 21 12:43:51.309: INFO: Created: latency-svc-nlzlq
Sep 21 12:43:51.346: INFO: Got endpoints: latency-svc-tqmq8 [748.650021ms]
Sep 21 12:43:51.359: INFO: Created: latency-svc-f6l2x
Sep 21 12:43:51.397: INFO: Got endpoints: latency-svc-gpjr5 [749.431358ms]
Sep 21 12:43:51.412: INFO: Created: latency-svc-dvqpn
Sep 21 12:43:51.454: INFO: Got endpoints: latency-svc-ttjrx [757.812938ms]
Sep 21 12:43:51.468: INFO: Created: latency-svc-prx5s
Sep 21 12:43:51.506: INFO: Got endpoints: latency-svc-6rtzx [757.339536ms]
Sep 21 12:43:51.517: INFO: Created: latency-svc-lfc6d
Sep 21 12:43:51.548: INFO: Got endpoints: latency-svc-hcblk [746.663517ms]
Sep 21 12:43:51.559: INFO: Created: latency-svc-qkpgd
Sep 21 12:43:51.597: INFO: Got endpoints: latency-svc-8wvfq [748.5006ms]
Sep 21 12:43:51.612: INFO: Created: latency-svc-ncl68
Sep 21 12:43:51.651: INFO: Got endpoints: latency-svc-qvjhp [753.688224ms]
Sep 21 12:43:51.667: INFO: Created: latency-svc-cfgwg
Sep 21 12:43:51.696: INFO: Got endpoints: latency-svc-tkzcn [748.800205ms]
Sep 21 12:43:51.705: INFO: Created: latency-svc-dmj8k
Sep 21 12:43:51.749: INFO: Got endpoints: latency-svc-gb2bx [744.580869ms]
Sep 21 12:43:51.761: INFO: Created: latency-svc-n2wbt
Sep 21 12:43:51.801: INFO: Got endpoints: latency-svc-5lthm [754.339203ms]
Sep 21 12:43:51.812: INFO: Created: latency-svc-79w5s
Sep 21 12:43:51.846: INFO: Got endpoints: latency-svc-w2qkw [748.237284ms]
Sep 21 12:43:51.856: INFO: Created: latency-svc-t2plz
Sep 21 12:43:51.895: INFO: Got endpoints: latency-svc-z767t [746.542806ms]
Sep 21 12:43:51.908: INFO: Created: latency-svc-xn7rl
Sep 21 12:43:51.947: INFO: Got endpoints: latency-svc-t5tgw [749.72667ms]
Sep 21 12:43:51.961: INFO: Created: latency-svc-6lrjx
Sep 21 12:43:51.995: INFO: Got endpoints: latency-svc-4sz5f [748.983792ms]
Sep 21 12:43:52.011: INFO: Created: latency-svc-8lxqs
Sep 21 12:43:52.048: INFO: Got endpoints: latency-svc-nlzlq [749.286827ms]
Sep 21 12:43:52.056: INFO: Created: latency-svc-kldmh
Sep 21 12:43:52.096: INFO: Got endpoints: latency-svc-f6l2x [749.991598ms]
Sep 21 12:43:52.113: INFO: Created: latency-svc-449kq
Sep 21 12:43:52.145: INFO: Got endpoints: latency-svc-dvqpn [747.40152ms]
Sep 21 12:43:52.156: INFO: Created: latency-svc-j6gnn
Sep 21 12:43:52.196: INFO: Got endpoints: latency-svc-prx5s [741.995094ms]
Sep 21 12:43:52.205: INFO: Created: latency-svc-9nkdx
Sep 21 12:43:52.249: INFO: Got endpoints: latency-svc-lfc6d [742.244301ms]
Sep 21 12:43:52.258: INFO: Created: latency-svc-5djxh
Sep 21 12:43:52.297: INFO: Got endpoints: latency-svc-qkpgd [749.366915ms]
Sep 21 12:43:52.308: INFO: Created: latency-svc-46n42
Sep 21 12:43:52.346: INFO: Got endpoints: latency-svc-ncl68 [748.723111ms]
Sep 21 12:43:52.360: INFO: Created: latency-svc-p7m6s
Sep 21 12:43:52.395: INFO: Got endpoints: latency-svc-cfgwg [742.50655ms]
Sep 21 12:43:52.410: INFO: Created: latency-svc-8tb6p
Sep 21 12:43:52.446: INFO: Got endpoints: latency-svc-dmj8k [749.918365ms]
Sep 21 12:43:52.460: INFO: Created: latency-svc-sppwb
Sep 21 12:43:52.497: INFO: Got endpoints: latency-svc-n2wbt [747.37411ms]
Sep 21 12:43:52.508: INFO: Created: latency-svc-m5crc
Sep 21 12:43:52.548: INFO: Got endpoints: latency-svc-79w5s [746.354071ms]
Sep 21 12:43:52.560: INFO: Created: latency-svc-2jdjl
Sep 21 12:43:52.597: INFO: Got endpoints: latency-svc-t2plz [750.842933ms]
Sep 21 12:43:52.607: INFO: Created: latency-svc-jrq9w
Sep 21 12:43:52.648: INFO: Got endpoints: latency-svc-xn7rl [752.296506ms]
Sep 21 12:43:52.662: INFO: Created: latency-svc-cl895
Sep 21 12:43:52.699: INFO: Got endpoints: latency-svc-6lrjx [751.397901ms]
Sep 21 12:43:52.708: INFO: Created: latency-svc-9zb2q
Sep 21 12:43:52.746: INFO: Got endpoints: latency-svc-8lxqs [751.408227ms]
Sep 21 12:43:52.760: INFO: Created: latency-svc-gd5l2
Sep 21 12:43:52.797: INFO: Got endpoints: latency-svc-kldmh [749.15083ms]
Sep 21 12:43:52.807: INFO: Created: latency-svc-ctr2m
Sep 21 12:43:52.851: INFO: Got endpoints: latency-svc-449kq [754.52932ms]
Sep 21 12:43:52.859: INFO: Created: latency-svc-f5wjr
Sep 21 12:43:52.899: INFO: Got endpoints: latency-svc-j6gnn [753.515916ms]
Sep 21 12:43:52.908: INFO: Created: latency-svc-czwr2
Sep 21 12:43:52.947: INFO: Got endpoints: latency-svc-9nkdx [750.508012ms]
Sep 21 12:43:52.955: INFO: Created: latency-svc-gjfpn
Sep 21 12:43:52.997: INFO: Got endpoints: latency-svc-5djxh [748.624414ms]
Sep 21 12:43:53.011: INFO: Created: latency-svc-mxfjp
Sep 21 12:43:53.046: INFO: Got endpoints: latency-svc-46n42 [748.572277ms]
Sep 21 12:43:53.055: INFO: Created: latency-svc-7x8fc
Sep 21 12:43:53.099: INFO: Got endpoints: latency-svc-p7m6s [752.015923ms]
Sep 21 12:43:53.108: INFO: Created: latency-svc-8dmpk
Sep 21 12:43:53.147: INFO: Got endpoints: latency-svc-8tb6p [752.272325ms]
Sep 21 12:43:53.155: INFO: Created: latency-svc-rbstw
Sep 21 12:43:53.198: INFO: Got endpoints: latency-svc-sppwb [752.320367ms]
Sep 21 12:43:53.209: INFO: Created: latency-svc-s29x8
Sep 21 12:43:53.246: INFO: Got endpoints: latency-svc-m5crc [748.780495ms]
Sep 21 12:43:53.255: INFO: Created: latency-svc-9nj52
Sep 21 12:43:53.295: INFO: Got endpoints: latency-svc-2jdjl [747.352517ms]
Sep 21 12:43:53.305: INFO: Created: latency-svc-nw9fg
Sep 21 12:43:53.348: INFO: Got endpoints: latency-svc-jrq9w [751.410716ms]
Sep 21 12:43:53.358: INFO: Created: latency-svc-p7swv
Sep 21 12:43:53.394: INFO: Got endpoints: latency-svc-cl895 [746.222988ms]
Sep 21 12:43:53.404: INFO: Created: latency-svc-mbgxq
Sep 21 12:43:53.445: INFO: Got endpoints: latency-svc-9zb2q [746.256331ms]
Sep 21 12:43:53.457: INFO: Created: latency-svc-hvb9n
Sep 21 12:43:53.498: INFO: Got endpoints: latency-svc-gd5l2 [751.539687ms]
Sep 21 12:43:53.515: INFO: Created: latency-svc-tgsgh
Sep 21 12:43:53.547: INFO: Got endpoints: latency-svc-ctr2m [749.454943ms]
Sep 21 12:43:53.555: INFO: Created: latency-svc-9bnj7
Sep 21 12:43:53.595: INFO: Got endpoints: latency-svc-f5wjr [744.311844ms]
Sep 21 12:43:53.605: INFO: Created: latency-svc-5smrf
Sep 21 12:43:53.647: INFO: Got endpoints: latency-svc-czwr2 [748.4989ms]
Sep 21 12:43:53.659: INFO: Created: latency-svc-j4hx5
Sep 21 12:43:53.696: INFO: Got endpoints: latency-svc-gjfpn [749.224845ms]
Sep 21 12:43:53.724: INFO: Created: latency-svc-2c7gz
Sep 21 12:43:53.747: INFO: Got endpoints: latency-svc-mxfjp [749.335173ms]
Sep 21 12:43:53.757: INFO: Created: latency-svc-4zgr2
Sep 21 12:43:53.796: INFO: Got endpoints: latency-svc-7x8fc [749.71312ms]
Sep 21 12:43:53.806: INFO: Created: latency-svc-2dqwc
Sep 21 12:43:53.847: INFO: Got endpoints: latency-svc-8dmpk [748.35168ms]
Sep 21 12:43:53.860: INFO: Created: latency-svc-zgpjl
Sep 21 12:43:53.894: INFO: Got endpoints: latency-svc-rbstw [747.446014ms]
Sep 21 12:43:53.909: INFO: Created: latency-svc-rxhk4
Sep 21 12:43:53.946: INFO: Got endpoints: latency-svc-s29x8 [747.160261ms]
Sep 21 12:43:53.962: INFO: Created: latency-svc-q7n7r
Sep 21 12:43:54.002: INFO: Got endpoints: latency-svc-9nj52 [755.872336ms]
Sep 21 12:43:54.014: INFO: Created: latency-svc-lplgj
Sep 21 12:43:54.049: INFO: Got endpoints: latency-svc-nw9fg [753.161596ms]
Sep 21 12:43:54.059: INFO: Created: latency-svc-4wlmk
Sep 21 12:43:54.095: INFO: Got endpoints: latency-svc-p7swv [746.342795ms]
Sep 21 12:43:54.107: INFO: Created: latency-svc-bg2bn
Sep 21 12:43:54.147: INFO: Got endpoints: latency-svc-mbgxq [752.879697ms]
Sep 21 12:43:54.159: INFO: Created: latency-svc-lts6x
Sep 21 12:43:54.198: INFO: Got endpoints: latency-svc-hvb9n [753.103823ms]
Sep 21 12:43:54.209: INFO: Created: latency-svc-sm9ns
Sep 21 12:43:54.246: INFO: Got endpoints: latency-svc-tgsgh [743.771463ms]
Sep 21 12:43:54.252: INFO: Created: latency-svc-5cplw
Sep 21 12:43:54.299: INFO: Got endpoints: latency-svc-9bnj7 [751.901489ms]
Sep 21 12:43:54.313: INFO: Created: latency-svc-dt2pq
Sep 21 12:43:54.346: INFO: Got endpoints: latency-svc-5smrf [750.999986ms]
Sep 21 12:43:54.357: INFO: Created: latency-svc-cjsvm
Sep 21 12:43:54.398: INFO: Got endpoints: latency-svc-j4hx5 [750.684741ms]
Sep 21 12:43:54.409: INFO: Created: latency-svc-ckfvj
Sep 21 12:43:54.449: INFO: Got endpoints: latency-svc-2c7gz [753.017018ms]
Sep 21 12:43:54.463: INFO: Created: latency-svc-6bbm4
Sep 21 12:43:54.496: INFO: Got endpoints: latency-svc-4zgr2 [749.435061ms]
Sep 21 12:43:54.505: INFO: Created: latency-svc-87hqs
Sep 21 12:43:54.547: INFO: Got endpoints: latency-svc-2dqwc [751.324488ms]
Sep 21 12:43:54.557: INFO: Created: latency-svc-fwrl6
Sep 21 12:43:54.594: INFO: Got endpoints: latency-svc-zgpjl [746.616511ms]
Sep 21 12:43:54.604: INFO: Created: latency-svc-hx2j9
Sep 21 12:43:54.649: INFO: Got endpoints: latency-svc-rxhk4 [753.963087ms]
Sep 21 12:43:54.659: INFO: Created: latency-svc-gjpgb
Sep 21 12:43:54.699: INFO: Got endpoints: latency-svc-q7n7r [753.070434ms]
Sep 21 12:43:54.714: INFO: Created: latency-svc-hvzgv
Sep 21 12:43:54.748: INFO: Got endpoints: latency-svc-lplgj [745.852884ms]
Sep 21 12:43:54.760: INFO: Created: latency-svc-sms5n
Sep 21 12:43:54.796: INFO: Got endpoints: latency-svc-4wlmk [747.639187ms]
Sep 21 12:43:54.845: INFO: Got endpoints: latency-svc-bg2bn [750.342279ms]
Sep 21 12:43:54.896: INFO: Got endpoints: latency-svc-lts6x [748.351296ms]
Sep 21 12:43:54.951: INFO: Got endpoints: latency-svc-sm9ns [752.831972ms]
Sep 21 12:43:54.997: INFO: Got endpoints: latency-svc-5cplw [750.966951ms]
Sep 21 12:43:55.048: INFO: Got endpoints: latency-svc-dt2pq [748.666836ms]
Sep 21 12:43:55.096: INFO: Got endpoints: latency-svc-cjsvm [749.345674ms]
Sep 21 12:43:55.146: INFO: Got endpoints: latency-svc-ckfvj [747.433998ms]
Sep 21 12:43:55.195: INFO: Got endpoints: latency-svc-6bbm4 [745.908997ms]
Sep 21 12:43:55.249: INFO: Got endpoints: latency-svc-87hqs [752.410997ms]
Sep 21 12:43:55.296: INFO: Got endpoints: latency-svc-fwrl6 [748.31611ms]
Sep 21 12:43:55.346: INFO: Got endpoints: latency-svc-hx2j9 [752.299208ms]
Sep 21 12:43:55.400: INFO: Got endpoints: latency-svc-gjpgb [751.435271ms]
Sep 21 12:43:55.446: INFO: Got endpoints: latency-svc-hvzgv [747.014532ms]
Sep 21 12:43:55.507: INFO: Got endpoints: latency-svc-sms5n [758.503153ms]
Sep 21 12:43:55.508: INFO: Latencies: [21.647228ms 30.163013ms 32.983432ms 43.157109ms 43.912987ms 44.490884ms 49.722864ms 49.961072ms 61.993368ms 62.095084ms 63.385651ms 67.107878ms 72.22776ms 73.302967ms 74.791776ms 77.141568ms 78.500035ms 80.583814ms 82.05248ms 85.838916ms 87.118235ms 92.114615ms 97.766806ms 102.77353ms 102.889883ms 116.901011ms 131.830211ms 139.422494ms 156.890026ms 157.167144ms 158.190246ms 158.468746ms 175.764703ms 179.311289ms 185.552438ms 187.401416ms 201.629692ms 262.655696ms 302.003927ms 352.733598ms 390.7081ms 441.824287ms 499.375081ms 524.220595ms 538.079157ms 590.853873ms 639.605496ms 688.249524ms 739.715421ms 740.400826ms 740.986229ms 741.995094ms 742.244301ms 742.50655ms 743.337768ms 743.771463ms 744.222542ms 744.311844ms 744.580869ms 745.695152ms 745.852884ms 745.908997ms 746.068269ms 746.222988ms 746.256331ms 746.342795ms 746.354071ms 746.510546ms 746.542806ms 746.603635ms 746.616511ms 746.621638ms 746.663517ms 746.893586ms 747.014532ms 747.160261ms 747.352517ms 747.37411ms 747.40152ms 747.433998ms 747.446014ms 747.639187ms 747.696927ms 747.710404ms 747.979457ms 748.046293ms 748.058912ms 748.217984ms 748.224701ms 748.237284ms 748.31611ms 748.351296ms 748.35168ms 748.405103ms 748.4989ms 748.5006ms 748.553285ms 748.572277ms 748.624414ms 748.650021ms 748.656674ms 748.666836ms 748.698451ms 748.723111ms 748.723302ms 748.780495ms 748.800205ms 748.876067ms 748.983792ms 749.15083ms 749.157104ms 749.224845ms 749.286827ms 749.335173ms 749.345674ms 749.353555ms 749.366915ms 749.431358ms 749.435061ms 749.454943ms 749.647741ms 749.658002ms 749.664608ms 749.71312ms 749.72667ms 749.918365ms 749.991598ms 750.03953ms 750.092374ms 750.096318ms 750.153439ms 750.220677ms 750.22293ms 750.240032ms 750.342279ms 750.434131ms 750.508012ms 750.684741ms 750.770538ms 750.842933ms 750.878342ms 750.965722ms 750.966951ms 750.999986ms 751.138415ms 751.164033ms 751.19907ms 751.310303ms 751.324488ms 751.344405ms 751.384262ms 751.397901ms 751.408227ms 751.410716ms 751.435271ms 751.539687ms 751.824606ms 751.836596ms 751.890359ms 751.901489ms 751.955214ms 752.004364ms 752.015923ms 752.092865ms 752.272325ms 752.287121ms 752.296506ms 752.299208ms 752.320367ms 752.350516ms 752.35877ms 752.410997ms 752.574179ms 752.831972ms 752.879697ms 752.914049ms 752.998181ms 753.017018ms 753.070434ms 753.103823ms 753.161596ms 753.383698ms 753.515916ms 753.631163ms 753.688224ms 753.70134ms 753.963087ms 754.061953ms 754.339203ms 754.52932ms 755.073673ms 755.758956ms 755.780945ms 755.872336ms 757.339536ms 757.812938ms 757.870373ms 758.503153ms 759.56849ms 760.938176ms]
Sep 21 12:43:55.509: INFO: 50 %ile: 748.656674ms
Sep 21 12:43:55.509: INFO: 90 %ile: 753.161596ms
Sep 21 12:43:55.509: INFO: 99 %ile: 759.56849ms
Sep 21 12:43:55.509: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:188
Sep 21 12:43:55.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7034" for this suite.

• [SLOW TEST:10.776 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":356,"completed":298,"skipped":5199,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:43:55.533: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 21 12:43:55.609: INFO: Waiting up to 5m0s for pod "pod-39eb797a-2d59-4d46-a86b-fae34a6558a7" in namespace "emptydir-9920" to be "Succeeded or Failed"
Sep 21 12:43:55.620: INFO: Pod "pod-39eb797a-2d59-4d46-a86b-fae34a6558a7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.1226ms
Sep 21 12:43:57.631: INFO: Pod "pod-39eb797a-2d59-4d46-a86b-fae34a6558a7": Phase="Running", Reason="", readiness=false. Elapsed: 2.021328862s
Sep 21 12:43:59.641: INFO: Pod "pod-39eb797a-2d59-4d46-a86b-fae34a6558a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032180344s
STEP: Saw pod success
Sep 21 12:43:59.642: INFO: Pod "pod-39eb797a-2d59-4d46-a86b-fae34a6558a7" satisfied condition "Succeeded or Failed"
Sep 21 12:43:59.644: INFO: Trying to get logs from node general-2-kofawi pod pod-39eb797a-2d59-4d46-a86b-fae34a6558a7 container test-container: <nil>
STEP: delete the pod
Sep 21 12:43:59.669: INFO: Waiting for pod pod-39eb797a-2d59-4d46-a86b-fae34a6558a7 to disappear
Sep 21 12:43:59.671: INFO: Pod pod-39eb797a-2d59-4d46-a86b-fae34a6558a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:43:59.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9920" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":299,"skipped":5223,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:43:59.680: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:43:59.702: INFO: Creating simple deployment test-new-deployment
Sep 21 12:43:59.727: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 12:44:01.771: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-5934  bac1f4d8-3455-40c0-b1d3-cb90c00734ff 30719 3 2022-09-21 12:43:59 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-09-21 12:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:44:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000c095f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-09-21 12:44:01 +0000 UTC,LastTransitionTime:2022-09-21 12:44:01 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-55df494869" has successfully progressed.,LastUpdateTime:2022-09-21 12:44:01 +0000 UTC,LastTransitionTime:2022-09-21 12:43:59 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 21 12:44:01.778: INFO: New ReplicaSet "test-new-deployment-55df494869" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-55df494869  deployment-5934  f3b06631-b0f8-4d3c-9a18-8bdad809c80b 30726 2 2022-09-21 12:43:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment bac1f4d8-3455-40c0-b1d3-cb90c00734ff 0xc0009712b7 0xc0009712b8}] []  [{kube-controller-manager Update apps/v1 2022-09-21 12:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bac1f4d8-3455-40c0-b1d3-cb90c00734ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:44:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000971358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:44:01.785: INFO: Pod "test-new-deployment-55df494869-8xqdl" is not available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-8xqdl test-new-deployment-55df494869- deployment-5934  ecc4e802-2ced-4756-8e67-50e632c6b831 30722 0 2022-09-21 12:44:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet test-new-deployment-55df494869 f3b06631-b0f8-4d3c-9a18-8bdad809c80b 0xc000c09a17 0xc000c09a18}] []  [{kube-controller-manager Update v1 2022-09-21 12:44:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f3b06631-b0f8-4d3c-9a18-8bdad809c80b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ln7hx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ln7hx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-xtetrn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:44:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 12:44:01.785: INFO: Pod "test-new-deployment-55df494869-c759f" is available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-c759f test-new-deployment-55df494869- deployment-5934  1643b641-dde9-45a7-8b91-df57b52f697e 30573 0 2022-09-21 12:43:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:380b835c142bc6f743a64bd7f1af63a6a823a50289407ae9bd3e3a2bf994cbca cni.projectcalico.org/podIP:10.129.34.209/32 cni.projectcalico.org/podIPs:10.129.34.209/32] [{apps/v1 ReplicaSet test-new-deployment-55df494869 f3b06631-b0f8-4d3c-9a18-8bdad809c80b 0xc000c09bb0 0xc000c09bb1}] []  [{kube-controller-manager Update v1 2022-09-21 12:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f3b06631-b0f8-4d3c-9a18-8bdad809c80b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-09-21 12:44:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-09-21 12:44:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.34.209\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vd4rx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vd4rx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-kofawi,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:43:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.34.209,StartTime:2022-09-21 12:43:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 12:44:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f7ae138a4e9fc9d9bdda5f93fb863452709525bc338260478d698f881b4dd55a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.34.209,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 12:44:01.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5934" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":356,"completed":300,"skipped":5259,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:01.810: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:44:12.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2737" for this suite.

• [SLOW TEST:11.083 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":356,"completed":301,"skipped":5285,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:12.898: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:44:13.420: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:44:16.439: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:44:16.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4135" for this suite.
STEP: Destroying namespace "webhook-4135-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":356,"completed":302,"skipped":5335,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:16.665: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-db351602-ed45-4877-82af-3799c6be4881
STEP: Creating secret with name s-test-opt-upd-363bc7a0-5214-41ae-b8c4-3853ea0951b2
STEP: Creating the pod
Sep 21 12:44:16.697: INFO: The status of Pod pod-secrets-3b5efcca-ad80-499c-8d04-9dba5b0554f3 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:44:18.704: INFO: The status of Pod pod-secrets-3b5efcca-ad80-499c-8d04-9dba5b0554f3 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-db351602-ed45-4877-82af-3799c6be4881
STEP: Updating secret s-test-opt-upd-363bc7a0-5214-41ae-b8c4-3853ea0951b2
STEP: Creating secret with name s-test-opt-create-7569d0fe-b21f-48eb-9250-4faf27d5481a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Sep 21 12:44:22.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-363" for this suite.

• [SLOW TEST:6.107 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":303,"skipped":5348,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:22.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service endpoint-test2 in namespace services-4813
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4813 to expose endpoints map[]
Sep 21 12:44:22.808: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Sep 21 12:44:23.819: INFO: successfully validated that service endpoint-test2 in namespace services-4813 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4813
Sep 21 12:44:23.833: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:44:25.840: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4813 to expose endpoints map[pod1:[80]]
Sep 21 12:44:25.849: INFO: successfully validated that service endpoint-test2 in namespace services-4813 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Sep 21 12:44:25.850: INFO: Creating new exec pod
Sep 21 12:44:28.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-4813 exec execpodgh8vn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Sep 21 12:44:29.057: INFO: stderr: "+ + nc -v -t -w 2 endpoint-test2 80\necho hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Sep 21 12:44:29.057: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:44:29.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-4813 exec execpodgh8vn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.82.105 80'
Sep 21 12:44:29.284: INFO: stderr: "+ nc -v -t -w 2 10.127.82.105 80\n+ echo hostName\nConnection to 10.127.82.105 80 port [tcp/http] succeeded!\n"
Sep 21 12:44:29.284: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-4813
Sep 21 12:44:29.311: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:44:31.316: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4813 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 21 12:44:31.328: INFO: successfully validated that service endpoint-test2 in namespace services-4813 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Sep 21 12:44:32.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-4813 exec execpodgh8vn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Sep 21 12:44:32.521: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Sep 21 12:44:32.521: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:44:32.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-4813 exec execpodgh8vn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.82.105 80'
Sep 21 12:44:32.686: INFO: stderr: "+ nc -v -t -w 2 10.127.82.105 80\n+ Connection to 10.127.82.105 80 port [tcp/http] succeeded!\necho hostName\n"
Sep 21 12:44:32.686: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4813
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4813 to expose endpoints map[pod2:[80]]
Sep 21 12:44:32.725: INFO: successfully validated that service endpoint-test2 in namespace services-4813 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Sep 21 12:44:33.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-4813 exec execpodgh8vn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Sep 21 12:44:33.915: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Sep 21 12:44:33.915: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:44:33.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-4813 exec execpodgh8vn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.127.82.105 80'
Sep 21 12:44:34.108: INFO: stderr: "+ nc -v -t -w 2 10.127.82.105 80\nConnection to 10.127.82.105 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Sep 21 12:44:34.108: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-4813
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4813 to expose endpoints map[]
Sep 21 12:44:34.148: INFO: successfully validated that service endpoint-test2 in namespace services-4813 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:44:34.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4813" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:11.409 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":356,"completed":304,"skipped":5355,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:34.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:44:34.248: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-8c660538-3a6e-4b92-90c5-6568c07c3dd6" in namespace "security-context-test-645" to be "Succeeded or Failed"
Sep 21 12:44:34.254: INFO: Pod "busybox-privileged-false-8c660538-3a6e-4b92-90c5-6568c07c3dd6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.276202ms
Sep 21 12:44:36.261: INFO: Pod "busybox-privileged-false-8c660538-3a6e-4b92-90c5-6568c07c3dd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012935382s
Sep 21 12:44:38.266: INFO: Pod "busybox-privileged-false-8c660538-3a6e-4b92-90c5-6568c07c3dd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017886356s
Sep 21 12:44:38.266: INFO: Pod "busybox-privileged-false-8c660538-3a6e-4b92-90c5-6568c07c3dd6" satisfied condition "Succeeded or Failed"
Sep 21 12:44:38.270: INFO: Got logs for pod "busybox-privileged-false-8c660538-3a6e-4b92-90c5-6568c07c3dd6": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Sep 21 12:44:38.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-645" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":305,"skipped":5379,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:38.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7300
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7300
STEP: Waiting until pod test-pod will start running in namespace statefulset-7300
STEP: Creating statefulset with conflicting port in namespace statefulset-7300
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7300
Sep 21 12:44:40.375: INFO: Observed stateful pod in namespace: statefulset-7300, name: ss-0, uid: 056b8070-c0fd-4dac-9e13-308f1dc6dd09, status phase: Pending. Waiting for statefulset controller to delete.
Sep 21 12:44:40.387: INFO: Observed stateful pod in namespace: statefulset-7300, name: ss-0, uid: 056b8070-c0fd-4dac-9e13-308f1dc6dd09, status phase: Failed. Waiting for statefulset controller to delete.
Sep 21 12:44:40.394: INFO: Observed stateful pod in namespace: statefulset-7300, name: ss-0, uid: 056b8070-c0fd-4dac-9e13-308f1dc6dd09, status phase: Failed. Waiting for statefulset controller to delete.
Sep 21 12:44:40.397: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7300
STEP: Removing pod with conflicting port in namespace statefulset-7300
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7300 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:44:42.423: INFO: Deleting all statefulset in ns statefulset-7300
Sep 21 12:44:42.425: INFO: Scaling statefulset ss to 0
Sep 21 12:44:52.453: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:44:52.456: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:44:52.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7300" for this suite.

• [SLOW TEST:14.190 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":356,"completed":306,"skipped":5427,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:52.475: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-947c3edb-aea7-46ef-aa79-700691bd0177
STEP: Creating a pod to test consume configMaps
Sep 21 12:44:52.504: INFO: Waiting up to 5m0s for pod "pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564" in namespace "configmap-3453" to be "Succeeded or Failed"
Sep 21 12:44:52.507: INFO: Pod "pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564": Phase="Pending", Reason="", readiness=false. Elapsed: 2.599959ms
Sep 21 12:44:54.517: INFO: Pod "pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012547926s
Sep 21 12:44:56.527: INFO: Pod "pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023057747s
STEP: Saw pod success
Sep 21 12:44:56.527: INFO: Pod "pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564" satisfied condition "Succeeded or Failed"
Sep 21 12:44:56.530: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:44:56.544: INFO: Waiting for pod pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564 to disappear
Sep 21 12:44:56.546: INFO: Pod pod-configmaps-d787856d-0cd0-4e05-bc63-3afd5cc2d564 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:44:56.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3453" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":307,"skipped":5437,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:44:56.552: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-babb71de-ffed-46a5-9d8a-153fce0105d7
STEP: Creating a pod to test consume configMaps
Sep 21 12:44:56.587: INFO: Waiting up to 5m0s for pod "pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff" in namespace "configmap-9497" to be "Succeeded or Failed"
Sep 21 12:44:56.590: INFO: Pod "pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692583ms
Sep 21 12:44:58.593: INFO: Pod "pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005710582s
Sep 21 12:45:00.598: INFO: Pod "pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011080847s
STEP: Saw pod success
Sep 21 12:45:00.598: INFO: Pod "pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff" satisfied condition "Succeeded or Failed"
Sep 21 12:45:00.600: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:45:00.613: INFO: Waiting for pod pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff to disappear
Sep 21 12:45:00.615: INFO: Pod pod-configmaps-0f56b843-bf88-4da2-bcaf-de9aa0e707ff no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:45:00.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9497" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":308,"skipped":5442,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:00.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:45:00.955: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:45:03.975: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:45:03.981: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:45:07.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5482" for this suite.
STEP: Destroying namespace "webhook-5482-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.575 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":356,"completed":309,"skipped":5456,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:07.199: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:45:07.236: INFO: Creating pod...
Sep 21 12:45:09.254: INFO: Creating service...
Sep 21 12:45:09.261: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/DELETE
Sep 21 12:45:09.285: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Sep 21 12:45:09.285: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/GET
Sep 21 12:45:09.288: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Sep 21 12:45:09.288: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/HEAD
Sep 21 12:45:09.291: INFO: http.Client request:HEAD | StatusCode:200
Sep 21 12:45:09.291: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/OPTIONS
Sep 21 12:45:09.294: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Sep 21 12:45:09.294: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/PATCH
Sep 21 12:45:09.298: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Sep 21 12:45:09.298: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/POST
Sep 21 12:45:09.301: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Sep 21 12:45:09.301: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/pods/agnhost/proxy/some/path/with/PUT
Sep 21 12:45:09.304: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Sep 21 12:45:09.304: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/DELETE
Sep 21 12:45:09.308: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Sep 21 12:45:09.308: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/GET
Sep 21 12:45:09.312: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Sep 21 12:45:09.312: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/HEAD
Sep 21 12:45:09.320: INFO: http.Client request:HEAD | StatusCode:200
Sep 21 12:45:09.320: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/OPTIONS
Sep 21 12:45:09.323: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Sep 21 12:45:09.323: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/PATCH
Sep 21 12:45:09.326: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Sep 21 12:45:09.326: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/POST
Sep 21 12:45:09.329: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Sep 21 12:45:09.329: INFO: Starting http.Client for https://10.124.0.1:443/api/v1/namespaces/proxy-6806/services/test-service/proxy/some/path/with/PUT
Sep 21 12:45:09.331: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Sep 21 12:45:09.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6806" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":356,"completed":310,"skipped":5499,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:09.337: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:45:25.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6723" for this suite.

• [SLOW TEST:16.090 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":356,"completed":311,"skipped":5524,"failed":0}
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:25.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Sep 21 12:45:25.462: INFO: Waiting up to 5m0s for pod "downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4" in namespace "downward-api-2283" to be "Succeeded or Failed"
Sep 21 12:45:25.467: INFO: Pod "downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.97555ms
Sep 21 12:45:27.479: INFO: Pod "downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016835785s
Sep 21 12:45:29.486: INFO: Pod "downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024476114s
STEP: Saw pod success
Sep 21 12:45:29.486: INFO: Pod "downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4" satisfied condition "Succeeded or Failed"
Sep 21 12:45:29.489: INFO: Trying to get logs from node general-2-kofawi pod downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4 container dapi-container: <nil>
STEP: delete the pod
Sep 21 12:45:29.504: INFO: Waiting for pod downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4 to disappear
Sep 21 12:45:29.506: INFO: Pod downward-api-fa8cc8c8-8460-40e0-af5b-28559bc3c0a4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Sep 21 12:45:29.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2283" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":356,"completed":312,"skipped":5524,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:29.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:45:29.910: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:45:32.952: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:45:32.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-59" for this suite.
STEP: Destroying namespace "webhook-59-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":356,"completed":313,"skipped":5549,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:33.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-962a561b-4269-4309-a322-912e3a034586
STEP: Creating a pod to test consume configMaps
Sep 21 12:45:33.032: INFO: Waiting up to 5m0s for pod "pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3" in namespace "configmap-537" to be "Succeeded or Failed"
Sep 21 12:45:33.033: INFO: Pod "pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.538469ms
Sep 21 12:45:35.044: INFO: Pod "pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012419223s
Sep 21 12:45:37.052: INFO: Pod "pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020485957s
STEP: Saw pod success
Sep 21 12:45:37.053: INFO: Pod "pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3" satisfied condition "Succeeded or Failed"
Sep 21 12:45:37.055: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3 container agnhost-container: <nil>
STEP: delete the pod
Sep 21 12:45:37.080: INFO: Waiting for pod pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3 to disappear
Sep 21 12:45:37.082: INFO: Pod pod-configmaps-02dc601e-8771-4782-9767-0d21daa533c3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:45:37.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-537" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":314,"skipped":5575,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:37.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-8820
STEP: creating service affinity-nodeport-transition in namespace services-8820
STEP: creating replication controller affinity-nodeport-transition in namespace services-8820
I0921 12:45:37.138699      18 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-8820, replica count: 3
I0921 12:45:40.191842      18 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:45:40.208: INFO: Creating new exec pod
Sep 21 12:45:43.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8820 exec execpod-affinitylk7wc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Sep 21 12:45:43.413: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Sep 21 12:45:43.413: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:45:43.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8820 exec execpod-affinitylk7wc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.124.195.125 80'
Sep 21 12:45:43.538: INFO: stderr: "+ nc -v -t -w 2 10.124.195.125 80\nConnection to 10.124.195.125 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Sep 21 12:45:43.538: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:45:43.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8820 exec execpod-affinitylk7wc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.2 30886'
Sep 21 12:45:43.681: INFO: stderr: "+ nc -v -t -w 2 10.128.0.2 30886\n+ echo hostName\nConnection to 10.128.0.2 30886 port [tcp/*] succeeded!\n"
Sep 21 12:45:43.681: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:45:43.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8820 exec execpod-affinitylk7wc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.3 30886'
Sep 21 12:45:43.855: INFO: stderr: "+ nc -v -t -w 2 10.128.0.3 30886\n+ echo hostName\nConnection to 10.128.0.3 30886 port [tcp/*] succeeded!\n"
Sep 21 12:45:43.855: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:45:43.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8820 exec execpod-affinitylk7wc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.2:30886/ ; done'
Sep 21 12:45:44.192: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n"
Sep 21 12:45:44.192: INFO: stdout: "\naffinity-nodeport-transition-8tzph\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-8tzph\naffinity-nodeport-transition-7xzxm\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-7xzxm\naffinity-nodeport-transition-7xzxm\naffinity-nodeport-transition-8tzph\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-7xzxm\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-7xzxm\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-7xzxm\naffinity-nodeport-transition-7xzxm"
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-8tzph
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-8tzph
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-8tzph
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.192: INFO: Received response from host: affinity-nodeport-transition-7xzxm
Sep 21 12:45:44.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-8820 exec execpod-affinitylk7wc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.2:30886/ ; done'
Sep 21 12:45:44.471: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.2:30886/\n"
Sep 21 12:45:44.472: INFO: stdout: "\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8\naffinity-nodeport-transition-rqsn8"
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Received response from host: affinity-nodeport-transition-rqsn8
Sep 21 12:45:44.472: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8820, will wait for the garbage collector to delete the pods
Sep 21 12:45:44.542: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.153932ms
Sep 21 12:45:44.643: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.630681ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:45:46.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8820" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.887 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":315,"skipped":5581,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:46.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Sep 21 12:45:47.000: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:45:49.009: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Sep 21 12:45:49.025: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:45:51.032: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Sep 21 12:45:51.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 12:45:51.044: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 12:45:53.045: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 12:45:53.050: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Sep 21 12:45:53.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1085" for this suite.

• [SLOW TEST:6.093 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":356,"completed":316,"skipped":5594,"failed":0}
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:53.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-a01a9dcc-b000-4a7d-910d-5862c4b176b8
STEP: Creating a pod to test consume secrets
Sep 21 12:45:53.119: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4" in namespace "projected-7193" to be "Succeeded or Failed"
Sep 21 12:45:53.122: INFO: Pod "pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.539711ms
Sep 21 12:45:55.135: INFO: Pod "pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015758927s
Sep 21 12:45:57.144: INFO: Pod "pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025069178s
STEP: Saw pod success
Sep 21 12:45:57.144: INFO: Pod "pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4" satisfied condition "Succeeded or Failed"
Sep 21 12:45:57.146: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:45:57.159: INFO: Waiting for pod pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4 to disappear
Sep 21 12:45:57.162: INFO: Pod pod-projected-secrets-3900880b-9625-41fa-bb1e-8f08ca8707e4 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 12:45:57.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7193" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":317,"skipped":5594,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:57.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting the proxy server
Sep 21 12:45:57.190: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-2423 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:45:57.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2423" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":356,"completed":318,"skipped":5672,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:45:57.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:45:57.309: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e285bd06-5b27-4863-8819-d19633f70db5" in namespace "security-context-test-4024" to be "Succeeded or Failed"
Sep 21 12:45:57.316: INFO: Pod "busybox-user-65534-e285bd06-5b27-4863-8819-d19633f70db5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.591878ms
Sep 21 12:45:59.327: INFO: Pod "busybox-user-65534-e285bd06-5b27-4863-8819-d19633f70db5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017831457s
Sep 21 12:46:01.334: INFO: Pod "busybox-user-65534-e285bd06-5b27-4863-8819-d19633f70db5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025169689s
Sep 21 12:46:01.334: INFO: Pod "busybox-user-65534-e285bd06-5b27-4863-8819-d19633f70db5" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Sep 21 12:46:01.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4024" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":319,"skipped":5704,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:01.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Deleting RuntimeClass runtimeclass-2219-delete-me
STEP: Waiting for the RuntimeClass to disappear
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Sep 21 12:46:01.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2219" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":320,"skipped":5713,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:01.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Sep 21 12:46:01.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7897" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","total":356,"completed":321,"skipped":5789,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:01.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 12:46:01.985: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 12:46:05.024: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:46:15.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6271" for this suite.
STEP: Destroying namespace "webhook-6271-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:13.782 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":356,"completed":322,"skipped":5803,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:15.216: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Sep 21 12:46:26.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-490" for this suite.

• [SLOW TEST:11.225 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":356,"completed":323,"skipped":5811,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:26.441: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Sep 21 12:46:26.470: INFO: The status of Pod annotationupdate9f752996-30d8-4d8e-bbee-70ad8ee5ff3f is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:46:28.476: INFO: The status of Pod annotationupdate9f752996-30d8-4d8e-bbee-70ad8ee5ff3f is Running (Ready = true)
Sep 21 12:46:29.001: INFO: Successfully updated pod "annotationupdate9f752996-30d8-4d8e-bbee-70ad8ee5ff3f"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Sep 21 12:46:33.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7809" for this suite.

• [SLOW TEST:6.587 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":324,"skipped":5821,"failed":0}
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:33.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:46:46.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2253" for this suite.
STEP: Destroying namespace "nsdeletetest-3019" for this suite.
Sep 21 12:46:46.178: INFO: Namespace nsdeletetest-3019 was already deleted
STEP: Destroying namespace "nsdeletetest-9904" for this suite.

• [SLOW TEST:13.150 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":356,"completed":325,"skipped":5824,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:46.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Sep 21 12:46:46.208: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7291  2fa3e5e1-02f2-45f3-962d-4e4d6cb1a3df 32478 0 2022-09-21 12:46:46 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-09-21 12:46:46 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xq44c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xq44c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 12:46:46.212: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:46:48.216: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Sep 21 12:46:48.216: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7291 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:46:48.216: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:46:48.217: INFO: ExecWithOptions: Clientset creation
Sep 21 12:46:48.218: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/dns-7291/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod...
Sep 21 12:46:48.323: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7291 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:46:48.323: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:46:48.324: INFO: ExecWithOptions: Clientset creation
Sep 21 12:46:48.324: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/dns-7291/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Sep 21 12:46:48.433: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Sep 21 12:46:48.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7291" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":356,"completed":326,"skipped":5827,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:48.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:46:48.489: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 21 12:46:50.525: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Sep 21 12:46:51.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6150" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":356,"completed":327,"skipped":5839,"failed":0}
SSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:46:51.542: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Sep 21 12:46:51.563: INFO: PodSpec: initContainers in spec.initContainers
Sep 21 12:47:37.152: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-bfe30e49-93e7-42b2-9e45-7bc2b2327efe", GenerateName:"", Namespace:"init-container-9007", SelfLink:"", UID:"fd6a5013-28b6-404e-9006-3657df7bb195", ResourceVersion:"32701", Generation:0, CreationTimestamp:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"563768972"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"062e9206d6d1b724174c49b9adf025e53a9d9f8b28cd688d27474819b10971f5", "cni.projectcalico.org/podIP":"10.129.34.255/32", "cni.projectcalico.org/podIPs":"10.129.34.255/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003378150), Subresource:""}, v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.September, 21, 12, 46, 52, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003378180), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.September, 21, 12, 46, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0033781b0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-8dxtf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00468a0e0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-8dxtf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-8dxtf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.7", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-8dxtf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004974690), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"general-2-kofawi", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00273a150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004974720)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004974740)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004974748), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00497474c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004c2c070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.2", PodIP:"10.129.34.255", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.129.34.255"}}, StartTime:time.Date(2022, time.September, 21, 12, 46, 51, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00273a230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00273a2a0)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://242757e2f2f6ea878ddeff1bc0d9b893916f7aa94628f9285a5314d8e841a56a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00468a160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00468a140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.7", ImageID:"", ContainerID:"", Started:(*bool)(0xc0049747cf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Sep 21 12:47:37.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9007" for this suite.

• [SLOW TEST:45.623 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":356,"completed":328,"skipped":5845,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity 
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:47:37.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename csistoragecapacity
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/storage.k8s.io
STEP: getting /apis/storage.k8s.io/v1
STEP: creating
STEP: watching
Sep 21 12:47:37.211: INFO: starting watch
STEP: getting
STEP: listing in namespace
STEP: listing across namespaces
STEP: patching
STEP: updating
Sep 21 12:47:37.233: INFO: waiting for watch events with expected annotations in namespace
Sep 21 12:47:37.233: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:188
Sep 21 12:47:37.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-9576" for this suite.
•{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","total":356,"completed":329,"skipped":5927,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:47:37.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating server pod server in namespace prestop-1621
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1621
STEP: Deleting pre-stop pod
Sep 21 12:47:46.323: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:188
Sep 21 12:47:46.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1621" for this suite.

• [SLOW TEST:9.082 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":356,"completed":330,"skipped":5949,"failed":0}
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:47:46.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 12:47:49.392: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Sep 21 12:47:49.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2598" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":331,"skipped":5953,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:47:49.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-71250a2f-d4b7-4fc1-b104-bf634edc0b5f
STEP: Creating a pod to test consume secrets
Sep 21 12:47:49.449: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674" in namespace "projected-9791" to be "Succeeded or Failed"
Sep 21 12:47:49.454: INFO: Pod "pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.389972ms
Sep 21 12:47:51.575: INFO: Pod "pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126305597s
Sep 21 12:47:53.581: INFO: Pod "pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.132091698s
STEP: Saw pod success
Sep 21 12:47:53.581: INFO: Pod "pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674" satisfied condition "Succeeded or Failed"
Sep 21 12:47:53.583: INFO: Trying to get logs from node general-2-kofawi pod pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 12:47:53.599: INFO: Waiting for pod pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674 to disappear
Sep 21 12:47:53.602: INFO: Pod pod-projected-secrets-65e831f8-602f-4d1f-bfb7-8383f78a8674 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 12:47:53.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9791" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":332,"skipped":6008,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:47:53.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Sep 21 12:47:57.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-991" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":356,"completed":333,"skipped":6031,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:47:57.695: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Sep 21 12:47:57.727: INFO: Waiting up to 5m0s for pod "downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb" in namespace "downward-api-4318" to be "Succeeded or Failed"
Sep 21 12:47:57.739: INFO: Pod "downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.051645ms
Sep 21 12:47:59.749: INFO: Pod "downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021012544s
Sep 21 12:48:01.757: INFO: Pod "downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029484401s
STEP: Saw pod success
Sep 21 12:48:01.757: INFO: Pod "downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb" satisfied condition "Succeeded or Failed"
Sep 21 12:48:01.760: INFO: Trying to get logs from node general-2-kofawi pod downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb container dapi-container: <nil>
STEP: delete the pod
Sep 21 12:48:01.773: INFO: Waiting for pod downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb to disappear
Sep 21 12:48:01.775: INFO: Pod downward-api-dc46442f-5760-40f5-8ae4-bdfbe41341fb no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Sep 21 12:48:01.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4318" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":356,"completed":334,"skipped":6048,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:01.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:48:01.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Sep 21 12:48:02.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-97" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":356,"completed":335,"skipped":6081,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:02.389: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-4e4eb0cb-345a-4aca-92a1-ac454d24a663
STEP: Creating a pod to test consume configMaps
Sep 21 12:48:02.420: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2" in namespace "configmap-4722" to be "Succeeded or Failed"
Sep 21 12:48:02.422: INFO: Pod "pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.302637ms
Sep 21 12:48:04.431: INFO: Pod "pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011258561s
Sep 21 12:48:06.443: INFO: Pod "pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023260871s
STEP: Saw pod success
Sep 21 12:48:06.444: INFO: Pod "pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2" satisfied condition "Succeeded or Failed"
Sep 21 12:48:06.446: INFO: Trying to get logs from node general-2-kofawi pod pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 12:48:06.461: INFO: Waiting for pod pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2 to disappear
Sep 21 12:48:06.468: INFO: Pod pod-configmaps-4c1ac1a1-9c90-4349-9288-614d797235e2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:48:06.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4722" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":336,"skipped":6083,"failed":0}
SS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:06.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Sep 21 12:48:06.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6047" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":356,"completed":337,"skipped":6085,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:06.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:48:06.567: INFO: Endpoints addresses: [10.128.0.4] , ports: [6443]
Sep 21 12:48:06.567: INFO: EndpointSlices addresses: [10.128.0.4] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Sep 21 12:48:06.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8658" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":356,"completed":338,"skipped":6112,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:06.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 21 12:48:06.600: INFO: Waiting up to 5m0s for pod "pod-fd25874c-145b-49e2-8842-f276c275113b" in namespace "emptydir-80" to be "Succeeded or Failed"
Sep 21 12:48:06.602: INFO: Pod "pod-fd25874c-145b-49e2-8842-f276c275113b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.353027ms
Sep 21 12:48:08.610: INFO: Pod "pod-fd25874c-145b-49e2-8842-f276c275113b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009681246s
Sep 21 12:48:10.621: INFO: Pod "pod-fd25874c-145b-49e2-8842-f276c275113b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021188132s
STEP: Saw pod success
Sep 21 12:48:10.622: INFO: Pod "pod-fd25874c-145b-49e2-8842-f276c275113b" satisfied condition "Succeeded or Failed"
Sep 21 12:48:10.624: INFO: Trying to get logs from node general-2-kofawi pod pod-fd25874c-145b-49e2-8842-f276c275113b container test-container: <nil>
STEP: delete the pod
Sep 21 12:48:10.636: INFO: Waiting for pod pod-fd25874c-145b-49e2-8842-f276c275113b to disappear
Sep 21 12:48:10.639: INFO: Pod pod-fd25874c-145b-49e2-8842-f276c275113b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:48:10.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-80" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":339,"skipped":6113,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:10.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 21 12:48:11.721: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Sep 21 12:48:11.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0921 12:48:11.721099      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
STEP: Destroying namespace "gc-7481" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":356,"completed":340,"skipped":6167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:11.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-4743127f-f3d8-4b78-807b-1025d37e4760
STEP: Creating secret with name s-test-opt-upd-29dd1fdd-c37c-4bdc-b0c8-00ebdeb574e4
STEP: Creating the pod
Sep 21 12:48:11.752: INFO: The status of Pod pod-projected-secrets-2be99441-b6ec-4aa1-8a8a-af8fa5b3f9a2 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:48:13.760: INFO: The status of Pod pod-projected-secrets-2be99441-b6ec-4aa1-8a8a-af8fa5b3f9a2 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-4743127f-f3d8-4b78-807b-1025d37e4760
STEP: Updating secret s-test-opt-upd-29dd1fdd-c37c-4bdc-b0c8-00ebdeb574e4
STEP: Creating secret with name s-test-opt-create-9931e313-2ad8-4c64-a833-7db39edf4d0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Sep 21 12:48:15.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1319" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":341,"skipped":6193,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:15.808: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:48:17.831: INFO: Deleting pod "var-expansion-a91e32b8-d0ac-40dc-bcee-f44d2d4d3860" in namespace "var-expansion-9686"
Sep 21 12:48:17.836: INFO: Wait up to 5m0s for pod "var-expansion-a91e32b8-d0ac-40dc-bcee-f44d2d4d3860" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Sep 21 12:48:21.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9686" for this suite.

• [SLOW TEST:6.046 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":356,"completed":342,"skipped":6212,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:21.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 21 12:48:21.882: INFO: Waiting up to 5m0s for pod "pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5" in namespace "emptydir-6727" to be "Succeeded or Failed"
Sep 21 12:48:21.890: INFO: Pod "pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.123163ms
Sep 21 12:48:23.898: INFO: Pod "pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015829037s
Sep 21 12:48:25.908: INFO: Pod "pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026082642s
STEP: Saw pod success
Sep 21 12:48:25.908: INFO: Pod "pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5" satisfied condition "Succeeded or Failed"
Sep 21 12:48:25.910: INFO: Trying to get logs from node general-2-kofawi pod pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5 container test-container: <nil>
STEP: delete the pod
Sep 21 12:48:25.921: INFO: Waiting for pod pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5 to disappear
Sep 21 12:48:25.923: INFO: Pod pod-c0460a1a-f6b6-47b3-9458-3832c9c1e0d5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:48:25.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6727" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":343,"skipped":6212,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:25.931: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Sep 21 12:48:25.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 create -f -'
Sep 21 12:48:26.897: INFO: stderr: ""
Sep 21 12:48:26.897: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 12:48:26.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 12:48:26.978: INFO: stderr: ""
Sep 21 12:48:26.978: INFO: stdout: "update-demo-nautilus-7qlvj update-demo-nautilus-wzvlz "
Sep 21 12:48:26.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-7qlvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:27.041: INFO: stderr: ""
Sep 21 12:48:27.041: INFO: stdout: ""
Sep 21 12:48:27.041: INFO: update-demo-nautilus-7qlvj is created but not running
Sep 21 12:48:32.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 12:48:32.148: INFO: stderr: ""
Sep 21 12:48:32.148: INFO: stdout: "update-demo-nautilus-7qlvj update-demo-nautilus-wzvlz "
Sep 21 12:48:32.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-7qlvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:32.244: INFO: stderr: ""
Sep 21 12:48:32.244: INFO: stdout: "true"
Sep 21 12:48:32.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-7qlvj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 12:48:32.352: INFO: stderr: ""
Sep 21 12:48:32.352: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 12:48:32.353: INFO: validating pod update-demo-nautilus-7qlvj
Sep 21 12:48:32.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 12:48:32.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 12:48:32.356: INFO: update-demo-nautilus-7qlvj is verified up and running
Sep 21 12:48:32.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-wzvlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:32.423: INFO: stderr: ""
Sep 21 12:48:32.423: INFO: stdout: "true"
Sep 21 12:48:32.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-wzvlz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 12:48:32.480: INFO: stderr: ""
Sep 21 12:48:32.480: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 12:48:32.480: INFO: validating pod update-demo-nautilus-wzvlz
Sep 21 12:48:32.484: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 12:48:32.484: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 12:48:32.484: INFO: update-demo-nautilus-wzvlz is verified up and running
STEP: scaling down the replication controller
Sep 21 12:48:32.485: INFO: scanned /root for discovery docs: <nil>
Sep 21 12:48:32.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Sep 21 12:48:33.558: INFO: stderr: ""
Sep 21 12:48:33.558: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 12:48:33.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 12:48:33.658: INFO: stderr: ""
Sep 21 12:48:33.658: INFO: stdout: "update-demo-nautilus-7qlvj update-demo-nautilus-wzvlz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 21 12:48:38.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 12:48:38.731: INFO: stderr: ""
Sep 21 12:48:38.731: INFO: stdout: "update-demo-nautilus-wzvlz "
Sep 21 12:48:38.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-wzvlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:38.806: INFO: stderr: ""
Sep 21 12:48:38.806: INFO: stdout: "true"
Sep 21 12:48:38.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-wzvlz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 12:48:38.869: INFO: stderr: ""
Sep 21 12:48:38.869: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 12:48:38.869: INFO: validating pod update-demo-nautilus-wzvlz
Sep 21 12:48:38.872: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 12:48:38.872: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 12:48:38.872: INFO: update-demo-nautilus-wzvlz is verified up and running
STEP: scaling up the replication controller
Sep 21 12:48:38.873: INFO: scanned /root for discovery docs: <nil>
Sep 21 12:48:38.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Sep 21 12:48:39.955: INFO: stderr: ""
Sep 21 12:48:39.955: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 12:48:39.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 12:48:40.051: INFO: stderr: ""
Sep 21 12:48:40.051: INFO: stdout: "update-demo-nautilus-2ms67 update-demo-nautilus-wzvlz "
Sep 21 12:48:40.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-2ms67 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:40.133: INFO: stderr: ""
Sep 21 12:48:40.133: INFO: stdout: ""
Sep 21 12:48:40.133: INFO: update-demo-nautilus-2ms67 is created but not running
Sep 21 12:48:45.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Sep 21 12:48:45.240: INFO: stderr: ""
Sep 21 12:48:45.240: INFO: stdout: "update-demo-nautilus-2ms67 update-demo-nautilus-wzvlz "
Sep 21 12:48:45.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-2ms67 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:45.326: INFO: stderr: ""
Sep 21 12:48:45.326: INFO: stdout: "true"
Sep 21 12:48:45.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-2ms67 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 12:48:45.396: INFO: stderr: ""
Sep 21 12:48:45.396: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 12:48:45.396: INFO: validating pod update-demo-nautilus-2ms67
Sep 21 12:48:45.401: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 12:48:45.401: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 12:48:45.401: INFO: update-demo-nautilus-2ms67 is verified up and running
Sep 21 12:48:45.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-wzvlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Sep 21 12:48:45.478: INFO: stderr: ""
Sep 21 12:48:45.478: INFO: stdout: "true"
Sep 21 12:48:45.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods update-demo-nautilus-wzvlz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Sep 21 12:48:45.555: INFO: stderr: ""
Sep 21 12:48:45.555: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Sep 21 12:48:45.555: INFO: validating pod update-demo-nautilus-wzvlz
Sep 21 12:48:45.559: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 12:48:45.559: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 12:48:45.559: INFO: update-demo-nautilus-wzvlz is verified up and running
STEP: using delete to clean up resources
Sep 21 12:48:45.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 delete --grace-period=0 --force -f -'
Sep 21 12:48:45.639: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 12:48:45.640: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 21 12:48:45.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get rc,svc -l name=update-demo --no-headers'
Sep 21 12:48:45.734: INFO: stderr: "No resources found in kubectl-5314 namespace.\n"
Sep 21 12:48:45.734: INFO: stdout: ""
Sep 21 12:48:45.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=kubectl-5314 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 12:48:45.835: INFO: stderr: ""
Sep 21 12:48:45.835: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Sep 21 12:48:45.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5314" for this suite.

• [SLOW TEST:19.917 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should scale a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":356,"completed":344,"skipped":6276,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:48:45.858: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:48:45.893: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 21 12:48:50.897: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 21 12:48:50.897: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 21 12:48:52.901: INFO: Creating deployment "test-rollover-deployment"
Sep 21 12:48:52.909: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 21 12:48:54.923: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 21 12:48:54.927: INFO: Ensure that both replica sets have 1 created replica
Sep 21 12:48:54.932: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 21 12:48:54.943: INFO: Updating deployment test-rollover-deployment
Sep 21 12:48:54.943: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 21 12:48:56.958: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 21 12:48:56.962: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 21 12:48:56.967: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 12:48:56.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:48:58.979: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 12:48:58.979: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:49:00.975: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 12:49:00.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:49:02.976: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 12:49:02.976: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:49:04.989: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 12:49:04.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.September, 21, 12, 48, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.September, 21, 12, 48, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 12:49:06.973: INFO: 
Sep 21 12:49:06.973: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Sep 21 12:49:06.978: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7502  853b7b33-bb5f-4a1d-82ab-8790f477afe3 33510 2 2022-09-21 12:48:52 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-09-21 12:48:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:49:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038ddd38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-09-21 12:48:52 +0000 UTC,LastTransitionTime:2022-09-21 12:48:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-779c67f4f8" has successfully progressed.,LastUpdateTime:2022-09-21 12:49:06 +0000 UTC,LastTransitionTime:2022-09-21 12:48:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 21 12:49:06.981: INFO: New ReplicaSet "test-rollover-deployment-779c67f4f8" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-779c67f4f8  deployment-7502  0b67d980-7b75-4324-8a65-7795d065f703 33500 2 2022-09-21 12:48:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 853b7b33-bb5f-4a1d-82ab-8790f477afe3 0xc0034b1237 0xc0034b1238}] []  [{kube-controller-manager Update apps/v1 2022-09-21 12:48:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"853b7b33-bb5f-4a1d-82ab-8790f477afe3\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:49:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 779c67f4f8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b12e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:49:06.981: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 21 12:49:06.981: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7502  9fe09045-fc79-43db-aacc-540e8133c823 33509 2 2022-09-21 12:48:45 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 853b7b33-bb5f-4a1d-82ab-8790f477afe3 0xc0034b0f97 0xc0034b0f98}] []  [{e2e.test Update apps/v1 2022-09-21 12:48:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:49:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"853b7b33-bb5f-4a1d-82ab-8790f477afe3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:49:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034b11c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:49:06.982: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-87f8f6dcf  deployment-7502  909b9e43-c020-45d4-bb55-bd2b461c00a1 33464 2 2022-09-21 12:48:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 853b7b33-bb5f-4a1d-82ab-8790f477afe3 0xc0034b1350 0xc0034b1351}] []  [{kube-controller-manager Update apps/v1 2022-09-21 12:48:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"853b7b33-bb5f-4a1d-82ab-8790f477afe3\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-09-21 12:48:55 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 87f8f6dcf,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b13f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 12:49:06.984: INFO: Pod "test-rollover-deployment-779c67f4f8-n4gq6" is available:
&Pod{ObjectMeta:{test-rollover-deployment-779c67f4f8-n4gq6 test-rollover-deployment-779c67f4f8- deployment-7502  ee000062-8cda-4de5-99d5-ff23c659870c 33481 0 2022-09-21 12:48:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[cni.projectcalico.org/containerID:794a296610a12967dc552ac23d21cdcfe733e3b4650f1d233a66b5c61c2fb5f4 cni.projectcalico.org/podIP:10.129.34.231/32 cni.projectcalico.org/podIPs:10.129.34.231/32] [{apps/v1 ReplicaSet test-rollover-deployment-779c67f4f8 0b67d980-7b75-4324-8a65-7795d065f703 0xc00353e867 0xc00353e868}] []  [{Go-http-client Update v1 2022-09-21 12:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-09-21 12:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0b67d980-7b75-4324-8a65-7795d065f703\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-09-21 12:48:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.129.34.231\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sdcgl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sdcgl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:general-2-kofawi,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:48:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-09-21 12:48:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.2,PodIP:10.129.34.231,StartTime:2022-09-21 12:48:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-09-21 12:48:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://27e6b1e265153427d5a9194077f6df10f8c75a59c8a8b689b2484920c0730369,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.129.34.231,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Sep 21 12:49:06.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7502" for this suite.

• [SLOW TEST:21.133 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":356,"completed":345,"skipped":6360,"failed":0}
S
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:49:06.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Sep 21 12:49:07.020: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:49:09.029: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.128.0.2 on the node which pod1 resides and expect scheduled
Sep 21 12:49:09.036: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:49:11.042: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.128.0.2 but use UDP protocol on the node which pod2 resides
Sep 21 12:49:11.051: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:49:13.058: INFO: The status of Pod pod3 is Running (Ready = true)
Sep 21 12:49:13.069: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:49:15.082: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Sep 21 12:49:15.084: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.128.0.2 http://127.0.0.1:54323/hostname] Namespace:hostport-2564 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:49:15.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:49:15.085: INFO: ExecWithOptions: Clientset creation
Sep 21 12:49:15.086: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/hostport-2564/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.128.0.2+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.128.0.2, port: 54323
Sep 21 12:49:15.213: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.128.0.2:54323/hostname] Namespace:hostport-2564 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:49:15.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:49:15.214: INFO: ExecWithOptions: Clientset creation
Sep 21 12:49:15.215: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/hostport-2564/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.128.0.2%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.128.0.2, port: 54323 UDP
Sep 21 12:49:15.299: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.128.0.2 54323] Namespace:hostport-2564 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Sep 21 12:49:15.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
Sep 21 12:49:15.300: INFO: ExecWithOptions: Clientset creation
Sep 21 12:49:15.300: INFO: ExecWithOptions: execute(POST https://10.124.0.1:443/api/v1/namespaces/hostport-2564/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+10.128.0.2+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:188
Sep 21 12:49:20.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-2564" for this suite.

• [SLOW TEST:13.396 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":356,"completed":346,"skipped":6361,"failed":0}
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:49:20.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-7843
Sep 21 12:49:20.418: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:49:22.423: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Sep 21 12:49:22.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7843 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Sep 21 12:49:22.605: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Sep 21 12:49:22.605: INFO: stdout: "iptables"
Sep 21 12:49:22.605: INFO: proxyMode: iptables
Sep 21 12:49:22.612: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Sep 21 12:49:22.615: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-7843
STEP: creating replication controller affinity-clusterip-timeout in namespace services-7843
I0921 12:49:22.634033      18 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-7843, replica count: 3
I0921 12:49:25.684920      18 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 12:49:25.700: INFO: Creating new exec pod
Sep 21 12:49:28.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7843 exec execpod-affinityfvfkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Sep 21 12:49:28.891: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Sep 21 12:49:28.891: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:49:28.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7843 exec execpod-affinityfvfkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.124.97.118 80'
Sep 21 12:49:29.050: INFO: stderr: "+ nc -v -t -w 2 10.124.97.118 80\n+ echo hostName\nConnection to 10.124.97.118 80 port [tcp/http] succeeded!\n"
Sep 21 12:49:29.050: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Sep 21 12:49:29.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7843 exec execpod-affinityfvfkk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.124.97.118:80/ ; done'
Sep 21 12:49:29.415: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n"
Sep 21 12:49:29.415: INFO: stdout: "\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq\naffinity-clusterip-timeout-vkkcq"
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.415: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.416: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.416: INFO: Received response from host: affinity-clusterip-timeout-vkkcq
Sep 21 12:49:29.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7843 exec execpod-affinityfvfkk -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.124.97.118:80/'
Sep 21 12:49:29.575: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n"
Sep 21 12:49:29.575: INFO: stdout: "affinity-clusterip-timeout-vkkcq"
Sep 21 12:49:49.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=services-7843 exec execpod-affinityfvfkk -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.124.97.118:80/'
Sep 21 12:49:49.755: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.124.97.118:80/\n"
Sep 21 12:49:49.755: INFO: stdout: "affinity-clusterip-timeout-hfgtb"
Sep 21 12:49:49.755: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-7843, will wait for the garbage collector to delete the pods
Sep 21 12:49:49.825: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 4.846221ms
Sep 21 12:49:49.926: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.076326ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Sep 21 12:49:51.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7843" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:31.357 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":347,"skipped":6361,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:49:51.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-secret-gsg6
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 12:49:51.778: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-gsg6" in namespace "subpath-5798" to be "Succeeded or Failed"
Sep 21 12:49:51.781: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214454ms
Sep 21 12:49:53.787: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008843024s
Sep 21 12:49:55.795: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 4.016297208s
Sep 21 12:49:57.799: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 6.020153142s
Sep 21 12:49:59.806: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 8.027347708s
Sep 21 12:50:01.811: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 10.031879995s
Sep 21 12:50:03.817: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 12.038086222s
Sep 21 12:50:05.829: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 14.050569386s
Sep 21 12:50:07.833: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 16.053992337s
Sep 21 12:50:09.839: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 18.060114129s
Sep 21 12:50:11.847: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=true. Elapsed: 20.067882959s
Sep 21 12:50:13.853: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Running", Reason="", readiness=false. Elapsed: 22.074633146s
Sep 21 12:50:15.865: INFO: Pod "pod-subpath-test-secret-gsg6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.086652516s
STEP: Saw pod success
Sep 21 12:50:15.865: INFO: Pod "pod-subpath-test-secret-gsg6" satisfied condition "Succeeded or Failed"
Sep 21 12:50:15.868: INFO: Trying to get logs from node general-2-kofawi pod pod-subpath-test-secret-gsg6 container test-container-subpath-secret-gsg6: <nil>
STEP: delete the pod
Sep 21 12:50:15.896: INFO: Waiting for pod pod-subpath-test-secret-gsg6 to disappear
Sep 21 12:50:15.898: INFO: Pod pod-subpath-test-secret-gsg6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-gsg6
Sep 21 12:50:15.898: INFO: Deleting pod "pod-subpath-test-secret-gsg6" in namespace "subpath-5798"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Sep 21 12:50:15.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5798" for this suite.

• [SLOW TEST:24.157 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","total":356,"completed":348,"skipped":6379,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:50:15.910: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-066fc445-dda4-44d4-90d1-1d8cb0549686
STEP: Creating configMap with name cm-test-opt-upd-b2ded6e6-9dc0-4458-8502-77c13c2a50d6
STEP: Creating the pod
Sep 21 12:50:15.952: INFO: The status of Pod pod-configmaps-755a4c67-02cb-4c4d-8bf0-06e571f9f956 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:50:17.957: INFO: The status of Pod pod-configmaps-755a4c67-02cb-4c4d-8bf0-06e571f9f956 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-066fc445-dda4-44d4-90d1-1d8cb0549686
STEP: Updating configmap cm-test-opt-upd-b2ded6e6-9dc0-4458-8502-77c13c2a50d6
STEP: Creating configMap with name cm-test-opt-create-dbad4972-ba16-497a-80a8-aaaedf0d60b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Sep 21 12:50:22.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8624" for this suite.

• [SLOW TEST:6.111 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":349,"skipped":6498,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:50:22.022: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Sep 21 12:50:22.055: INFO: The status of Pod busybox-scheduling-e9dcca5c-4df8-468e-b6f1-875bf9fdbd93 is Pending, waiting for it to be Running (with Ready = true)
Sep 21 12:50:24.059: INFO: The status of Pod busybox-scheduling-e9dcca5c-4df8-468e-b6f1-875bf9fdbd93 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Sep 21 12:50:24.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5856" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":356,"completed":350,"skipped":6508,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:50:24.074: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Sep 21 12:52:02.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1562" for this suite.

• [SLOW TEST:98.064 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":356,"completed":351,"skipped":6532,"failed":0}
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:52:02.138: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: reading a file in the container
Sep 21 12:52:04.220: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6624 pod-service-account-19d8b291-abf3-49ae-8a77-951f62742ec0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 21 12:52:04.391: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6624 pod-service-account-19d8b291-abf3-49ae-8a77-951f62742ec0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 21 12:52:04.556: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6624 pod-service-account-19d8b291-abf3-49ae-8a77-951f62742ec0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Sep 21 12:52:04.726: INFO: Got root ca configmap in namespace "svcaccounts-6624"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Sep 21 12:52:04.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6624" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":356,"completed":352,"skipped":6536,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:52:04.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 21 12:52:04.769: INFO: Waiting up to 5m0s for pod "pod-c046c22e-5100-41f9-a9b1-5e473f40067e" in namespace "emptydir-4568" to be "Succeeded or Failed"
Sep 21 12:52:04.772: INFO: Pod "pod-c046c22e-5100-41f9-a9b1-5e473f40067e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.951086ms
Sep 21 12:52:06.782: INFO: Pod "pod-c046c22e-5100-41f9-a9b1-5e473f40067e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012980328s
Sep 21 12:52:08.788: INFO: Pod "pod-c046c22e-5100-41f9-a9b1-5e473f40067e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018745962s
STEP: Saw pod success
Sep 21 12:52:08.789: INFO: Pod "pod-c046c22e-5100-41f9-a9b1-5e473f40067e" satisfied condition "Succeeded or Failed"
Sep 21 12:52:08.792: INFO: Trying to get logs from node general-2-kofawi pod pod-c046c22e-5100-41f9-a9b1-5e473f40067e container test-container: <nil>
STEP: delete the pod
Sep 21 12:52:08.813: INFO: Waiting for pod pod-c046c22e-5100-41f9-a9b1-5e473f40067e to disappear
Sep 21 12:52:08.816: INFO: Pod pod-c046c22e-5100-41f9-a9b1-5e473f40067e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Sep 21 12:52:08.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4568" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":353,"skipped":6536,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:52:08.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3895
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Sep 21 12:52:08.866: INFO: Found 0 stateful pods, waiting for 3
Sep 21 12:52:18.870: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:52:18.871: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:52:18.871: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 12:52:18.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-3895 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:52:19.055: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:52:19.055: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:52:19.055: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Sep 21 12:52:29.093: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 21 12:52:39.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-3895 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:52:39.370: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:52:39.370: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:52:39.370: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 12:52:39.403: INFO: Waiting for StatefulSet statefulset-3895/ss2 to complete update
Sep 21 12:52:39.403: INFO: Waiting for Pod statefulset-3895/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Sep 21 12:52:39.403: INFO: Waiting for Pod statefulset-3895/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Sep 21 12:52:39.403: INFO: Waiting for Pod statefulset-3895/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Rolling back to a previous revision
Sep 21 12:52:49.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-3895 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 12:52:49.591: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 12:52:49.592: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 12:52:49.592: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 12:52:59.620: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 21 12:53:09.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1552228020 --namespace=statefulset-3895 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 12:53:09.776: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 12:53:09.776: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 12:53:09.776: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Sep 21 12:53:19.798: INFO: Deleting all statefulset in ns statefulset-3895
Sep 21 12:53:19.800: INFO: Scaling statefulset ss2 to 0
Sep 21 12:53:29.820: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 12:53:29.822: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Sep 21 12:53:30.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3895" for this suite.

• [SLOW TEST:81.271 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":356,"completed":354,"skipped":6555,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:53:30.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 12:53:30.143: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:53:30.143: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:53:31.151: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:53:31.151: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:53:32.153: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:53:32.153: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 21 12:53:32.180: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:53:32.180: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:53:33.189: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Sep 21 12:53:33.189: INFO: Node general-2-kofawi is running 0 daemon pod, expected 1
Sep 21 12:53:34.190: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Sep 21 12:53:34.190: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9882, will wait for the garbage collector to delete the pods
Sep 21 12:53:34.253: INFO: Deleting DaemonSet.extensions daemon-set took: 4.644408ms
Sep 21 12:53:34.354: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.959856ms
Sep 21 12:53:36.365: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Sep 21 12:53:36.365: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Sep 21 12:53:36.367: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34959"},"items":null}

Sep 21 12:53:36.369: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34959"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Sep 21 12:53:36.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9882" for this suite.

• [SLOW TEST:6.285 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":356,"completed":355,"skipped":6587,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Sep 21 12:53:36.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1552228020
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Sep 21 12:53:56.528: INFO: EndpointSlice for Service endpointslice-7924/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Sep 21 12:54:06.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7924" for this suite.

• [SLOW TEST:30.177 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":356,"completed":356,"skipped":6603,"failed":0}
SSSSSSSSSSSSSep 21 12:54:06.560: INFO: Running AfterSuite actions on all nodes
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func19.2
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Sep 21 12:54:06.560: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Sep 21 12:54:06.560: INFO: Running AfterSuite actions on node 1
Sep 21 12:54:06.560: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":356,"completed":356,"skipped":6615,"failed":0}

Ran 356 of 6971 Specs in 5432.114 seconds
SUCCESS! -- 356 Passed | 0 Failed | 0 Pending | 6615 Skipped
PASS

Ginkgo ran 1 suite in 1h30m33.930140782s
Test Suite Passed
